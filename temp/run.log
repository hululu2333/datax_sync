脚本所在路径：/software/datax/sync/bin
表配置所在路径：/software/datax/sync/bin/../conf
json文件所在路径：/software/datax/sync/bin/../job
jar包所在路径：/software/datax/sync/bin/../jar

数据源表配置文件的储存路径：/software/datax/sync/bin/../conf/jdbc:mysql:192.168.0.124:3306

数据源表配置生成成功
开始执行hive的建库建表语句
建库语句存入临时文件
`id` BIGINT,`device_id` STRING,`device_position` STRING,`org_hcode` STRING
一条建表语句被加入临时文件
`id` BIGINT,`device_id` STRING,`device_position` STRING,`org_hcode` STRING
一条建表语句被加入临时文件
`id` BIGINT,`statistics_date` STRING,`fault_tag_id` BIGINT,`statistics_count` BIGINT,`average_downtime_interval` STRING,`average_downtime_duration` STRING,`average_downtime_interval_value` BIGINT,`average_downtime_duration_value` BIGINT,`andon_tag_id` BIGINT,`org_id` BIGINT,`create_dt` DATE,`update_dt` DATE,`status` STRING,`domain_id` STRING
一条建表语句被加入临时文件
`id` BIGINT,`statistics_date` STRING,`fault_tag_id` BIGINT,`statistics_count` BIGINT,`average_downtime_interval` STRING,`average_downtime_duration` STRING,`average_downtime_interval_value` BIGINT,`average_downtime_duration_value` BIGINT,`andon_tag_id` BIGINT,`org_hcode` STRING,`create_dt` DATE,`update_dt` DATE,`status` STRING
一条建表语句被加入临时文件
`id` BIGINT,`fault_name` STRING,`fault_tag_id` BIGINT,`fault_org_id` BIGINT,`domain_id` STRING,`tombstone` STRING,`create_dt` DATE,`update_dt` DATE
一条建表语句被加入临时文件
`id` BIGINT,`fault_name` STRING,`fault_tag_id` BIGINT,`fault_org_hcode` STRING,`tombstone` STRING,`create_dt` DATE,`update_dt` DATE
一条建表语句被加入临时文件
`id` BIGINT,`andon_deviceid` STRING,`device_name` STRING,`device_type` STRING,`call_tag_id` BIGINT,`call_org_id` BIGINT,`call_follow_status` STRING,`tombstone` STRING,`domain_id` STRING,`call_executor` STRING,`call_date` DATE,`order_executor` STRING,`order_date` DATE,`finish_executor` STRING,`finish_date` DATE,`create_dt` DATE,`update_dt` DATE
一条建表语句被加入临时文件
`id` BIGINT,`andon_deviceid` STRING,`device_name` STRING,`device_type` STRING,`call_tag_id` BIGINT,`call_org_hcode` STRING,`call_follow_status` STRING,`tombstone` STRING,`call_executor` STRING,`call_date` DATE,`order_executor` STRING,`order_date` DATE,`finish_executor` STRING,`finish_date` DATE,`create_dt` DATE,`update_dt` DATE
一条建表语句被加入临时文件
`id` BIGINT,`guide_sso_id` STRING,`guide_org_id` BIGINT,`guide_status` STRING,`tombstone` STRING,`domain_id` STRING,`create_dt` DATE,`update_dt` DATE
一条建表语句被加入临时文件
`id` BIGINT,`guide_sso_id` STRING,`guide_org_hcode` STRING,`guide_status` STRING,`tombstone` STRING,`create_dt` DATE,`update_dt` DATE
一条建表语句被加入临时文件
`tag_id` BIGINT,`org_tag_name` STRING,`org_id` BIGINT,`tombstone` STRING,`domain_id` STRING,`create_sso` STRING,`create_dt` DATE,`update_sso` STRING,`update_dt` DATE
一条建表语句被加入临时文件
`tag_id` BIGINT,`org_tag_name` STRING,`org_hcode` STRING,`tombstone` STRING,`create_sso` STRING,`create_dt` DATE,`update_sso` STRING,`update_dt` DATE
一条建表语句被加入临时文件
`id` BIGINT,`record_id` BIGINT,`fault_id` BIGINT
一条建表语句被加入临时文件
`id` BIGINT,`record_id` BIGINT,`fault_id` BIGINT
一条建表语句被加入临时文件
`id` BIGINT,`andon_ssoid` STRING,`tag_id` BIGINT,`sso_tag_name` STRING,`tombstone` STRING,`domain_id` STRING,`create_dt` DATE,`update_dt` DATE
一条建表语句被加入临时文件
`id` BIGINT,`andon_ssoid` STRING,`tag_id` BIGINT,`sso_tag_name` STRING,`tombstone` STRING,`create_dt` DATE,`update_dt` DATE
一条建表语句被加入临时文件
`id` BIGINT,`tag_name` STRING,`tombstone` STRING,`domain_id` STRING,`create_dt` DATE,`update_dt` DATE,`create_sso` STRING
一条建表语句被加入临时文件
`id` BIGINT,`tag_name` STRING,`tombstone` STRING,`create_dt` DATE,`update_dt` DATE,`create_sso` STRING
一条建表语句被加入临时文件
`id` BIGINT,`statistics_date` STRING,`sso_id` STRING,`tag_id` BIGINT,`average_duration` STRING,`average_duration_value` BIGINT,`link_relative` STRING,`org_id` BIGINT,`create_dt` DATE,`update_dt` DATE,`status` STRING,`domain_id` STRING
一条建表语句被加入临时文件
`id` BIGINT,`statistics_date` STRING,`sso_id` STRING,`tag_id` BIGINT,`average_duration` STRING,`average_duration_value` BIGINT,`link_relative` STRING,`org_hcode` STRING,`create_dt` DATE,`update_dt` DATE,`status` STRING
一条建表语句被加入临时文件
`id` BIGINT,`app_id` STRING,`sso_id` STRING,`open_id` STRING,`whether_open` STRING,`create_dt` DATE,`update_dt` DATE
一条建表语句被加入临时文件
`id` BIGINT,`app_id` STRING,`sso_id` STRING,`open_id` STRING,`whether_open` STRING,`create_dt` DATE,`update_dt` DATE
一条建表语句被加入临时文件
`id` BIGINT,`app_id` STRING,`app_secret` STRING,`sign_mark` STRING,`description` STRING,`state` BIGINT,`create_date` DATE
一条建表语句被加入临时文件
`id` BIGINT,`app_id` STRING,`app_secret` STRING,`sign_mark` STRING,`description` STRING,`state` BIGINT,`create_date` DATE
一条建表语句被加入临时文件
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/hive/apache-hive-3.1.2/lib/log4j-slf4j-impl-2.10.0.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/hadoop/hadoop-3.1.3/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/hadoop/hadoop-3.1.3/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/hive/apache-hive-3.1.2/lib/log4j-slf4j-impl-2.10.0.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Connecting to jdbc:hive2://192.168.0.61:10000
Connected to: Apache Hive (version 3.1.2)
Driver: Hive JDBC (version 3.1.2)
Transaction isolation: TRANSACTION_REPEATABLE_READ
0: jdbc:hive2://192.168.0.61:10000> create database if not exists `mysql_ziyun_andon` location '/user/hive/warehouse/mysql_ziyun_andon';
INFO  : Compiling command(queryId=root_20210329181755_f25cdb27-4372-4e52-a0e2-1ec315c70f56): create database if not exists `mysql_ziyun_andon` location '/user/hive/warehouse/mysql_ziyun_andon'
INFO  : Semantic Analysis Completed (retrial = false)
INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)
INFO  : Completed compiling command(queryId=root_20210329181755_f25cdb27-4372-4e52-a0e2-1ec315c70f56); Time taken: 0.131 seconds
INFO  : Executing command(queryId=root_20210329181755_f25cdb27-4372-4e52-a0e2-1ec315c70f56): create database if not exists `mysql_ziyun_andon` location '/user/hive/warehouse/mysql_ziyun_andon'
INFO  : Starting task [Stage-0:DDL] in serial mode
INFO  : Completed executing command(queryId=root_20210329181755_f25cdb27-4372-4e52-a0e2-1ec315c70f56); Time taken: 0.012 seconds
INFO  : OK
No rows affected (0.269 seconds)
0: jdbc:hive2://192.168.0.61:10000> create table if not exists `mysql_ziyun_andon`.`andon_equipment_position` (`id` BIGINT,`device_id` STRING,`device_position` STR ING,`org_hcode` STRING) row format delimited fields terminated by '\t';
INFO  : Compiling command(queryId=root_20210329181755_a9cbc4cf-c6e4-4aa0-ac41-6d6656865cd7): create table if not exists `mysql_ziyun_andon`.`andon_equipment_position` (`id` BIGINT,`device_id` STRING,`device_position` STRING,`org_hcode` STRING) row format delimited fields terminated by '\t'
INFO  : Semantic Analysis Completed (retrial = false)
INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)
INFO  : Completed compiling command(queryId=root_20210329181755_a9cbc4cf-c6e4-4aa0-ac41-6d6656865cd7); Time taken: 0.086 seconds
INFO  : Executing command(queryId=root_20210329181755_a9cbc4cf-c6e4-4aa0-ac41-6d6656865cd7): create table if not exists `mysql_ziyun_andon`.`andon_equipment_position` (`id` BIGINT,`device_id` STRING,`device_position` STRING,`org_hcode` STRING) row format delimited fields terminated by '\t'
INFO  : Completed executing command(queryId=root_20210329181755_a9cbc4cf-c6e4-4aa0-ac41-6d6656865cd7); Time taken: 0.0 seconds
INFO  : OK
No rows affected (0.107 seconds)
0: jdbc:hive2://192.168.0.61:10000> create table if not exists `mysql_ziyun_andon`.`andon_equipment_position_copy1` (`id` BIGINT,`device_id` STRING,`device_positio n` STRING,`org_hcode` STRING) row format delimited fields terminated by '\t';
INFO  : Compiling command(queryId=root_20210329181756_b0bbb83f-20ad-4b14-985a-170b3056cdf9): create table if not exists `mysql_ziyun_andon`.`andon_equipment_position_copy1` (`id` BIGINT,`device_id` STRING,`device_position` STRING,`org_hcode` STRING) row format delimited fields terminated by '\t'
INFO  : Semantic Analysis Completed (retrial = false)
INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)
INFO  : Completed compiling command(queryId=root_20210329181756_b0bbb83f-20ad-4b14-985a-170b3056cdf9); Time taken: 0.052 seconds
INFO  : Executing command(queryId=root_20210329181756_b0bbb83f-20ad-4b14-985a-170b3056cdf9): create table if not exists `mysql_ziyun_andon`.`andon_equipment_position_copy1` (`id` BIGINT,`device_id` STRING,`device_position` STRING,`org_hcode` STRING) row format delimited fields terminated by '\t'
INFO  : Completed executing command(queryId=root_20210329181756_b0bbb83f-20ad-4b14-985a-170b3056cdf9); Time taken: 0.0 seconds
INFO  : OK
No rows affected (0.072 seconds)
0: jdbc:hive2://192.168.0.61:10000> create table if not exists `mysql_ziyun_andon`.`andon_fault_tag_statistics` (`id` BIGINT,`statistics_date` STRING,`fault_tag_id ` BIGINT,`statistics_count` BIGINT,`average_downtime_interval` STRING,`average_downtime_duration` STRING,`average_downtime_interval_value` BIGINT,`average_downtime _duration_value` BIGINT,`andon_tag_id` BIGINT,`org_id` BIGINT,`create_dt` DATE,`update_dt` DATE,`status` STRING,`domain_id` STRING) row format delimited fields ter minated by '\t';
INFO  : Compiling command(queryId=root_20210329181756_1135be7e-cb3e-4aed-af1a-73c3c1147eb2): create table if not exists `mysql_ziyun_andon`.`andon_fault_tag_statistics` (`id` BIGINT,`statistics_date` STRING,`fault_tag_id` BIGINT,`statistics_count` BIGINT,`average_downtime_interval` STRING,`average_downtime_duration` STRING,`average_downtime_interval_value` BIGINT,`average_downtime_duration_value` BIGINT,`andon_tag_id` BIGINT,`org_id` BIGINT,`create_dt` DATE,`update_dt` DATE,`status` STRING,`domain_id` STRING) row format delimited fields terminated by '\t'
INFO  : Semantic Analysis Completed (retrial = false)
INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)
INFO  : Completed compiling command(queryId=root_20210329181756_1135be7e-cb3e-4aed-af1a-73c3c1147eb2); Time taken: 0.056 seconds
INFO  : Executing command(queryId=root_20210329181756_1135be7e-cb3e-4aed-af1a-73c3c1147eb2): create table if not exists `mysql_ziyun_andon`.`andon_fault_tag_statistics` (`id` BIGINT,`statistics_date` STRING,`fault_tag_id` BIGINT,`statistics_count` BIGINT,`average_downtime_interval` STRING,`average_downtime_duration` STRING,`average_downtime_interval_value` BIGINT,`average_downtime_duration_value` BIGINT,`andon_tag_id` BIGINT,`org_id` BIGINT,`create_dt` DATE,`update_dt` DATE,`status` STRING,`domain_id` STRING) row format delimited fields terminated by '\t'
INFO  : Completed executing command(queryId=root_20210329181756_1135be7e-cb3e-4aed-af1a-73c3c1147eb2); Time taken: 0.0 seconds
INFO  : OK
No rows affected (0.075 seconds)
0: jdbc:hive2://192.168.0.61:10000> create table if not exists `mysql_ziyun_andon`.`andon_fault_tag_statistics_copy1` (`id` BIGINT,`statistics_date` STRING,`fault_ tag_id` BIGINT,`statistics_count` BIGINT,`average_downtime_interval` STRING,`average_downtime_duration` STRING,`average_downtime_interval_value` BIGINT,`average_do wntime_duration_value` BIGINT,`andon_tag_id` BIGINT,`org_hcode` STRING,`create_dt` DATE,`update_dt` DATE,`status` STRING) row format delimited fields terminated by  '\t';
INFO  : Compiling command(queryId=root_20210329181756_2a87c851-d7eb-4f6e-aa56-3b0665bfc05a): create table if not exists `mysql_ziyun_andon`.`andon_fault_tag_statistics_copy1` (`id` BIGINT,`statistics_date` STRING,`fault_tag_id` BIGINT,`statistics_count` BIGINT,`average_downtime_interval` STRING,`average_downtime_duration` STRING,`average_downtime_interval_value` BIGINT,`average_downtime_duration_value` BIGINT,`andon_tag_id` BIGINT,`org_hcode` STRING,`create_dt` DATE,`update_dt` DATE,`status` STRING) row format delimited fields terminated by '\t'
INFO  : Semantic Analysis Completed (retrial = false)
INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)
INFO  : Completed compiling command(queryId=root_20210329181756_2a87c851-d7eb-4f6e-aa56-3b0665bfc05a); Time taken: 0.056 seconds
INFO  : Executing command(queryId=root_20210329181756_2a87c851-d7eb-4f6e-aa56-3b0665bfc05a): create table if not exists `mysql_ziyun_andon`.`andon_fault_tag_statistics_copy1` (`id` BIGINT,`statistics_date` STRING,`fault_tag_id` BIGINT,`statistics_count` BIGINT,`average_downtime_interval` STRING,`average_downtime_duration` STRING,`average_downtime_interval_value` BIGINT,`average_downtime_duration_value` BIGINT,`andon_tag_id` BIGINT,`org_hcode` STRING,`create_dt` DATE,`update_dt` DATE,`status` STRING) row format delimited fields terminated by '\t'
INFO  : Completed executing command(queryId=root_20210329181756_2a87c851-d7eb-4f6e-aa56-3b0665bfc05a); Time taken: 0.0 seconds
INFO  : OK
No rows affected (0.077 seconds)
0: jdbc:hive2://192.168.0.61:10000> create table if not exists `mysql_ziyun_andon`.`andon_fault_type` (`id` BIGINT,`fault_name` STRING,`fault_tag_id` BIGINT,`fault _org_id` BIGINT,`domain_id` STRING,`tombstone` STRING,`create_dt` DATE,`update_dt` DATE) row format delimited fields terminated by '\t';
INFO  : Compiling command(queryId=root_20210329181756_4be282e4-0179-44fd-8361-a80e60f099bc): create table if not exists `mysql_ziyun_andon`.`andon_fault_type` (`id` BIGINT,`fault_name` STRING,`fault_tag_id` BIGINT,`fault_org_id` BIGINT,`domain_id` STRING,`tombstone` STRING,`create_dt` DATE,`update_dt` DATE) row format delimited fields terminated by '\t'
INFO  : Semantic Analysis Completed (retrial = false)
INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)
INFO  : Completed compiling command(queryId=root_20210329181756_4be282e4-0179-44fd-8361-a80e60f099bc); Time taken: 0.054 seconds
INFO  : Executing command(queryId=root_20210329181756_4be282e4-0179-44fd-8361-a80e60f099bc): create table if not exists `mysql_ziyun_andon`.`andon_fault_type` (`id` BIGINT,`fault_name` STRING,`fault_tag_id` BIGINT,`fault_org_id` BIGINT,`domain_id` STRING,`tombstone` STRING,`create_dt` DATE,`update_dt` DATE) row format delimited fields terminated by '\t'
INFO  : Completed executing command(queryId=root_20210329181756_4be282e4-0179-44fd-8361-a80e60f099bc); Time taken: 0.0 seconds
INFO  : OK
No rows affected (0.078 seconds)
0: jdbc:hive2://192.168.0.61:10000> create table if not exists `mysql_ziyun_andon`.`andon_fault_type_copy1` (`id` BIGINT,`fault_name` STRING,`fault_tag_id` BIGINT, `fault_org_hcode` STRING,`tombstone` STRING,`create_dt` DATE,`update_dt` DATE) row format delimited fields terminated by '\t';
INFO  : Compiling command(queryId=root_20210329181756_377ab4f9-104a-488b-b6a2-d31af4a67076): create table if not exists `mysql_ziyun_andon`.`andon_fault_type_copy1` (`id` BIGINT,`fault_name` STRING,`fault_tag_id` BIGINT,`fault_org_hcode` STRING,`tombstone` STRING,`create_dt` DATE,`update_dt` DATE) row format delimited fields terminated by '\t'
INFO  : Semantic Analysis Completed (retrial = false)
INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)
INFO  : Completed compiling command(queryId=root_20210329181756_377ab4f9-104a-488b-b6a2-d31af4a67076); Time taken: 0.051 seconds
INFO  : Executing command(queryId=root_20210329181756_377ab4f9-104a-488b-b6a2-d31af4a67076): create table if not exists `mysql_ziyun_andon`.`andon_fault_type_copy1` (`id` BIGINT,`fault_name` STRING,`fault_tag_id` BIGINT,`fault_org_hcode` STRING,`tombstone` STRING,`create_dt` DATE,`update_dt` DATE) row format delimited fields terminated by '\t'
INFO  : Completed executing command(queryId=root_20210329181756_377ab4f9-104a-488b-b6a2-d31af4a67076); Time taken: 0.0 seconds
INFO  : OK
No rows affected (0.068 seconds)
0: jdbc:hive2://192.168.0.61:10000> create table if not exists `mysql_ziyun_andon`.`andon_follow_record` (`id` BIGINT,`andon_deviceid` STRING,`device_name` STRING, `device_type` STRING,`call_tag_id` BIGINT,`call_org_id` BIGINT,`call_follow_status` STRING,`tombstone` STRING,`domain_id` STRING,`call_executor` STRING,`call_date`  DATE,`order_executor` STRING,`order_date` DATE,`finish_executor` STRING,`finish_date` DATE,`create_dt` DATE,`update_dt` DATE) row format delimited fields terminat ed by '\t';
INFO  : Compiling command(queryId=root_20210329181756_ef28ef25-7640-4767-b5f9-9dac0dff0881): create table if not exists `mysql_ziyun_andon`.`andon_follow_record` (`id` BIGINT,`andon_deviceid` STRING,`device_name` STRING,`device_type` STRING,`call_tag_id` BIGINT,`call_org_id` BIGINT,`call_follow_status` STRING,`tombstone` STRING,`domain_id` STRING,`call_executor` STRING,`call_date` DATE,`order_executor` STRING,`order_date` DATE,`finish_executor` STRING,`finish_date` DATE,`create_dt` DATE,`update_dt` DATE) row format delimited fields terminated by '\t'
INFO  : Semantic Analysis Completed (retrial = false)
INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)
INFO  : Completed compiling command(queryId=root_20210329181756_ef28ef25-7640-4767-b5f9-9dac0dff0881); Time taken: 0.074 seconds
INFO  : Executing command(queryId=root_20210329181756_ef28ef25-7640-4767-b5f9-9dac0dff0881): create table if not exists `mysql_ziyun_andon`.`andon_follow_record` (`id` BIGINT,`andon_deviceid` STRING,`device_name` STRING,`device_type` STRING,`call_tag_id` BIGINT,`call_org_id` BIGINT,`call_follow_status` STRING,`tombstone` STRING,`domain_id` STRING,`call_executor` STRING,`call_date` DATE,`order_executor` STRING,`order_date` DATE,`finish_executor` STRING,`finish_date` DATE,`create_dt` DATE,`update_dt` DATE) row format delimited fields terminated by '\t'
INFO  : Completed executing command(queryId=root_20210329181756_ef28ef25-7640-4767-b5f9-9dac0dff0881); Time taken: 0.0 seconds
INFO  : OK
No rows affected (0.092 seconds)
0: jdbc:hive2://192.168.0.61:10000> create table if not exists `mysql_ziyun_andon`.`andon_follow_record_copy1` (`id` BIGINT,`andon_deviceid` STRING,`device_name` S TRING,`device_type` STRING,`call_tag_id` BIGINT,`call_org_hcode` STRING,`call_follow_status` STRING,`tombstone` STRING,`call_executor` STRING,`call_date` DATE,`ord er_executor` STRING,`order_date` DATE,`finish_executor` STRING,`finish_date` DATE,`create_dt` DATE,`update_dt` DATE) row format delimited fields terminated by '\t' ;
INFO  : Compiling command(queryId=root_20210329181756_e393593d-9698-4af4-a9a7-20dcceeb5d02): create table if not exists `mysql_ziyun_andon`.`andon_follow_record_copy1` (`id` BIGINT,`andon_deviceid` STRING,`device_name` STRING,`device_type` STRING,`call_tag_id` BIGINT,`call_org_hcode` STRING,`call_follow_status` STRING,`tombstone` STRING,`call_executor` STRING,`call_date` DATE,`order_executor` STRING,`order_date` DATE,`finish_executor` STRING,`finish_date` DATE,`create_dt` DATE,`update_dt` DATE) row format delimited fields terminated by '\t'
INFO  : Semantic Analysis Completed (retrial = false)
INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)
INFO  : Completed compiling command(queryId=root_20210329181756_e393593d-9698-4af4-a9a7-20dcceeb5d02); Time taken: 0.068 seconds
INFO  : Executing command(queryId=root_20210329181756_e393593d-9698-4af4-a9a7-20dcceeb5d02): create table if not exists `mysql_ziyun_andon`.`andon_follow_record_copy1` (`id` BIGINT,`andon_deviceid` STRING,`device_name` STRING,`device_type` STRING,`call_tag_id` BIGINT,`call_org_hcode` STRING,`call_follow_status` STRING,`tombstone` STRING,`call_executor` STRING,`call_date` DATE,`order_executor` STRING,`order_date` DATE,`finish_executor` STRING,`finish_date` DATE,`create_dt` DATE,`update_dt` DATE) row format delimited fields terminated by '\t'
INFO  : Completed executing command(queryId=root_20210329181756_e393593d-9698-4af4-a9a7-20dcceeb5d02); Time taken: 0.0 seconds
INFO  : OK
No rows affected (0.085 seconds)
0: jdbc:hive2://192.168.0.61:10000> create table if not exists `mysql_ziyun_andon`.`andon_guide_status` (`id` BIGINT,`guide_sso_id` STRING,`guide_org_id` BIGINT,`g uide_status` STRING,`tombstone` STRING,`domain_id` STRING,`create_dt` DATE,`update_dt` DATE) row format delimited fields terminated by '\t';
INFO  : Compiling command(queryId=root_20210329181756_6b33de43-e009-43a0-b77a-f6c60772eb9e): create table if not exists `mysql_ziyun_andon`.`andon_guide_status` (`id` BIGINT,`guide_sso_id` STRING,`guide_org_id` BIGINT,`guide_status` STRING,`tombstone` STRING,`domain_id` STRING,`create_dt` DATE,`update_dt` DATE) row format delimited fields terminated by '\t'
INFO  : Semantic Analysis Completed (retrial = false)
INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)
INFO  : Completed compiling command(queryId=root_20210329181756_6b33de43-e009-43a0-b77a-f6c60772eb9e); Time taken: 0.054 seconds
INFO  : Executing command(queryId=root_20210329181756_6b33de43-e009-43a0-b77a-f6c60772eb9e): create table if not exists `mysql_ziyun_andon`.`andon_guide_status` (`id` BIGINT,`guide_sso_id` STRING,`guide_org_id` BIGINT,`guide_status` STRING,`tombstone` STRING,`domain_id` STRING,`create_dt` DATE,`update_dt` DATE) row format delimited fields terminated by '\t'
INFO  : Completed executing command(queryId=root_20210329181756_6b33de43-e009-43a0-b77a-f6c60772eb9e); Time taken: 0.0 seconds
INFO  : OK
No rows affected (0.071 seconds)
0: jdbc:hive2://192.168.0.61:10000> create table if not exists `mysql_ziyun_andon`.`andon_guide_status_copy1` (`id` BIGINT,`guide_sso_id` STRING,`guide_org_hcode`  STRING,`guide_status` STRING,`tombstone` STRING,`create_dt` DATE,`update_dt` DATE) row format delimited fields terminated by '\t';
INFO  : Compiling command(queryId=root_20210329181756_7893585b-bca6-4b49-a01c-878d5df2cd80): create table if not exists `mysql_ziyun_andon`.`andon_guide_status_copy1` (`id` BIGINT,`guide_sso_id` STRING,`guide_org_hcode` STRING,`guide_status` STRING,`tombstone` STRING,`create_dt` DATE,`update_dt` DATE) row format delimited fields terminated by '\t'
INFO  : Semantic Analysis Completed (retrial = false)
INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)
INFO  : Completed compiling command(queryId=root_20210329181756_7893585b-bca6-4b49-a01c-878d5df2cd80); Time taken: 0.051 seconds
INFO  : Executing command(queryId=root_20210329181756_7893585b-bca6-4b49-a01c-878d5df2cd80): create table if not exists `mysql_ziyun_andon`.`andon_guide_status_copy1` (`id` BIGINT,`guide_sso_id` STRING,`guide_org_hcode` STRING,`guide_status` STRING,`tombstone` STRING,`create_dt` DATE,`update_dt` DATE) row format delimited fields terminated by '\t'
INFO  : Completed executing command(queryId=root_20210329181756_7893585b-bca6-4b49-a01c-878d5df2cd80); Time taken: 0.0 seconds
INFO  : OK
No rows affected (0.068 seconds)
0: jdbc:hive2://192.168.0.61:10000> create table if not exists `mysql_ziyun_andon`.`andon_org_tag` (`tag_id` BIGINT,`org_tag_name` STRING,`org_id` BIGINT,`tombston e` STRING,`domain_id` STRING,`create_sso` STRING,`create_dt` DATE,`update_sso` STRING,`update_dt` DATE) row format delimited fields terminated by '\t';
INFO  : Compiling command(queryId=root_20210329181756_86571720-4076-4244-abfb-8fc2ce182bb9): create table if not exists `mysql_ziyun_andon`.`andon_org_tag` (`tag_id` BIGINT,`org_tag_name` STRING,`org_id` BIGINT,`tombstone` STRING,`domain_id` STRING,`create_sso` STRING,`create_dt` DATE,`update_sso` STRING,`update_dt` DATE) row format delimited fields terminated by '\t'
INFO  : Semantic Analysis Completed (retrial = false)
INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)
INFO  : Completed compiling command(queryId=root_20210329181756_86571720-4076-4244-abfb-8fc2ce182bb9); Time taken: 0.05 seconds
INFO  : Executing command(queryId=root_20210329181756_86571720-4076-4244-abfb-8fc2ce182bb9): create table if not exists `mysql_ziyun_andon`.`andon_org_tag` (`tag_id` BIGINT,`org_tag_name` STRING,`org_id` BIGINT,`tombstone` STRING,`domain_id` STRING,`create_sso` STRING,`create_dt` DATE,`update_sso` STRING,`update_dt` DATE) row format delimited fields terminated by '\t'
INFO  : Completed executing command(queryId=root_20210329181756_86571720-4076-4244-abfb-8fc2ce182bb9); Time taken: 0.001 seconds
INFO  : OK
No rows affected (0.067 seconds)
0: jdbc:hive2://192.168.0.61:10000> create table if not exists `mysql_ziyun_andon`.`andon_org_tag_copy1` (`tag_id` BIGINT,`org_tag_name` STRING,`org_hcode` STRING, `tombstone` STRING,`create_sso` STRING,`create_dt` DATE,`update_sso` STRING,`update_dt` DATE) row format delimited fields terminated by '\t';
INFO  : Compiling command(queryId=root_20210329181757_be6e7ca4-81a1-4045-b7d7-f7351d33cdff): create table if not exists `mysql_ziyun_andon`.`andon_org_tag_copy1` (`tag_id` BIGINT,`org_tag_name` STRING,`org_hcode` STRING,`tombstone` STRING,`create_sso` STRING,`create_dt` DATE,`update_sso` STRING,`update_dt` DATE) row format delimited fields terminated by '\t'
INFO  : Semantic Analysis Completed (retrial = false)
INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)
INFO  : Completed compiling command(queryId=root_20210329181757_be6e7ca4-81a1-4045-b7d7-f7351d33cdff); Time taken: 0.049 seconds
INFO  : Executing command(queryId=root_20210329181757_be6e7ca4-81a1-4045-b7d7-f7351d33cdff): create table if not exists `mysql_ziyun_andon`.`andon_org_tag_copy1` (`tag_id` BIGINT,`org_tag_name` STRING,`org_hcode` STRING,`tombstone` STRING,`create_sso` STRING,`create_dt` DATE,`update_sso` STRING,`update_dt` DATE) row format delimited fields terminated by '\t'
INFO  : Completed executing command(queryId=root_20210329181757_be6e7ca4-81a1-4045-b7d7-f7351d33cdff); Time taken: 0.0 seconds
INFO  : OK
No rows affected (0.066 seconds)
0: jdbc:hive2://192.168.0.61:10000> create table if not exists `mysql_ziyun_andon`.`andon_record_fault_middle` (`id` BIGINT,`record_id` BIGINT,`fault_id` BIGINT) r ow format delimited fields terminated by '\t';
INFO  : Compiling command(queryId=root_20210329181757_67d1677d-c096-4121-b211-abdbfbc91d8f): create table if not exists `mysql_ziyun_andon`.`andon_record_fault_middle` (`id` BIGINT,`record_id` BIGINT,`fault_id` BIGINT) row format delimited fields terminated by '\t'
INFO  : Semantic Analysis Completed (retrial = false)
INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)
INFO  : Completed compiling command(queryId=root_20210329181757_67d1677d-c096-4121-b211-abdbfbc91d8f); Time taken: 0.049 seconds
INFO  : Executing command(queryId=root_20210329181757_67d1677d-c096-4121-b211-abdbfbc91d8f): create table if not exists `mysql_ziyun_andon`.`andon_record_fault_middle` (`id` BIGINT,`record_id` BIGINT,`fault_id` BIGINT) row format delimited fields terminated by '\t'
INFO  : Completed executing command(queryId=root_20210329181757_67d1677d-c096-4121-b211-abdbfbc91d8f); Time taken: 0.0 seconds
INFO  : OK
No rows affected (0.065 seconds)
0: jdbc:hive2://192.168.0.61:10000> create table if not exists `mysql_ziyun_andon`.`andon_record_fault_middle_copy1` (`id` BIGINT,`record_id` BIGINT,`fault_id` BIG INT) row format delimited fields terminated by '\t';
INFO  : Compiling command(queryId=root_20210329181757_f61bada4-2fdf-40ec-a9d5-5e76abd50fe0): create table if not exists `mysql_ziyun_andon`.`andon_record_fault_middle_copy1` (`id` BIGINT,`record_id` BIGINT,`fault_id` BIGINT) row format delimited fields terminated by '\t'
INFO  : Semantic Analysis Completed (retrial = false)
INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)
INFO  : Completed compiling command(queryId=root_20210329181757_f61bada4-2fdf-40ec-a9d5-5e76abd50fe0); Time taken: 0.052 seconds
INFO  : Executing command(queryId=root_20210329181757_f61bada4-2fdf-40ec-a9d5-5e76abd50fe0): create table if not exists `mysql_ziyun_andon`.`andon_record_fault_middle_copy1` (`id` BIGINT,`record_id` BIGINT,`fault_id` BIGINT) row format delimited fields terminated by '\t'
INFO  : Completed executing command(queryId=root_20210329181757_f61bada4-2fdf-40ec-a9d5-5e76abd50fe0); Time taken: 0.0 seconds
INFO  : OK
No rows affected (0.069 seconds)
0: jdbc:hive2://192.168.0.61:10000> create table if not exists `mysql_ziyun_andon`.`andon_sso_tag` (`id` BIGINT,`andon_ssoid` STRING,`tag_id` BIGINT,`sso_tag_name`  STRING,`tombstone` STRING,`domain_id` STRING,`create_dt` DATE,`update_dt` DATE) row format delimited fields terminated by '\t';
INFO  : Compiling command(queryId=root_20210329181757_a0bd8032-c773-43d6-a481-8c45cc273514): create table if not exists `mysql_ziyun_andon`.`andon_sso_tag` (`id` BIGINT,`andon_ssoid` STRING,`tag_id` BIGINT,`sso_tag_name` STRING,`tombstone` STRING,`domain_id` STRING,`create_dt` DATE,`update_dt` DATE) row format delimited fields terminated by '\t'
INFO  : Semantic Analysis Completed (retrial = false)
INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)
INFO  : Completed compiling command(queryId=root_20210329181757_a0bd8032-c773-43d6-a481-8c45cc273514); Time taken: 0.052 seconds
INFO  : Executing command(queryId=root_20210329181757_a0bd8032-c773-43d6-a481-8c45cc273514): create table if not exists `mysql_ziyun_andon`.`andon_sso_tag` (`id` BIGINT,`andon_ssoid` STRING,`tag_id` BIGINT,`sso_tag_name` STRING,`tombstone` STRING,`domain_id` STRING,`create_dt` DATE,`update_dt` DATE) row format delimited fields terminated by '\t'
INFO  : Completed executing command(queryId=root_20210329181757_a0bd8032-c773-43d6-a481-8c45cc273514); Time taken: 0.0 seconds
INFO  : OK
No rows affected (0.071 seconds)
0: jdbc:hive2://192.168.0.61:10000> create table if not exists `mysql_ziyun_andon`.`andon_sso_tag_copy1` (`id` BIGINT,`andon_ssoid` STRING,`tag_id` BIGINT,`sso_tag _name` STRING,`tombstone` STRING,`create_dt` DATE,`update_dt` DATE) row format delimited fields terminated by '\t';
INFO  : Compiling command(queryId=root_20210329181757_46ce7d7f-3d7e-41d6-96c2-0d807b2ad30c): create table if not exists `mysql_ziyun_andon`.`andon_sso_tag_copy1` (`id` BIGINT,`andon_ssoid` STRING,`tag_id` BIGINT,`sso_tag_name` STRING,`tombstone` STRING,`create_dt` DATE,`update_dt` DATE) row format delimited fields terminated by '\t'
INFO  : Semantic Analysis Completed (retrial = false)
INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)
INFO  : Completed compiling command(queryId=root_20210329181757_46ce7d7f-3d7e-41d6-96c2-0d807b2ad30c); Time taken: 0.054 seconds
INFO  : Executing command(queryId=root_20210329181757_46ce7d7f-3d7e-41d6-96c2-0d807b2ad30c): create table if not exists `mysql_ziyun_andon`.`andon_sso_tag_copy1` (`id` BIGINT,`andon_ssoid` STRING,`tag_id` BIGINT,`sso_tag_name` STRING,`tombstone` STRING,`create_dt` DATE,`update_dt` DATE) row format delimited fields terminated by '\t'
INFO  : Completed executing command(queryId=root_20210329181757_46ce7d7f-3d7e-41d6-96c2-0d807b2ad30c); Time taken: 0.0 seconds
INFO  : OK
No rows affected (0.07 seconds)
0: jdbc:hive2://192.168.0.61:10000> create table if not exists `mysql_ziyun_andon`.`andon_tag` (`id` BIGINT,`tag_name` STRING,`tombstone` STRING,`domain_id` STRING ,`create_dt` DATE,`update_dt` DATE,`create_sso` STRING) row format delimited fields terminated by '\t';
INFO  : Compiling command(queryId=root_20210329181757_2dca7415-f437-4680-9e64-08819221b5f4): create table if not exists `mysql_ziyun_andon`.`andon_tag` (`id` BIGINT,`tag_name` STRING,`tombstone` STRING,`domain_id` STRING,`create_dt` DATE,`update_dt` DATE,`create_sso` STRING) row format delimited fields terminated by '\t'
INFO  : Semantic Analysis Completed (retrial = false)
INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)
INFO  : Completed compiling command(queryId=root_20210329181757_2dca7415-f437-4680-9e64-08819221b5f4); Time taken: 0.053 seconds
INFO  : Executing command(queryId=root_20210329181757_2dca7415-f437-4680-9e64-08819221b5f4): create table if not exists `mysql_ziyun_andon`.`andon_tag` (`id` BIGINT,`tag_name` STRING,`tombstone` STRING,`domain_id` STRING,`create_dt` DATE,`update_dt` DATE,`create_sso` STRING) row format delimited fields terminated by '\t'
INFO  : Completed executing command(queryId=root_20210329181757_2dca7415-f437-4680-9e64-08819221b5f4); Time taken: 0.0 seconds
INFO  : OK
No rows affected (0.07 seconds)
0: jdbc:hive2://192.168.0.61:10000> create table if not exists `mysql_ziyun_andon`.`andon_tag_copy1` (`id` BIGINT,`tag_name` STRING,`tombstone` STRING,`create_dt`  DATE,`update_dt` DATE,`create_sso` STRING) row format delimited fields terminated by '\t';
INFO  : Compiling command(queryId=root_20210329181757_90304189-fe5f-4930-a8b0-e9b8372cd72f): create table if not exists `mysql_ziyun_andon`.`andon_tag_copy1` (`id` BIGINT,`tag_name` STRING,`tombstone` STRING,`create_dt` DATE,`update_dt` DATE,`create_sso` STRING) row format delimited fields terminated by '\t'
INFO  : Semantic Analysis Completed (retrial = false)
INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)
INFO  : Completed compiling command(queryId=root_20210329181757_90304189-fe5f-4930-a8b0-e9b8372cd72f); Time taken: 0.053 seconds
INFO  : Executing command(queryId=root_20210329181757_90304189-fe5f-4930-a8b0-e9b8372cd72f): create table if not exists `mysql_ziyun_andon`.`andon_tag_copy1` (`id` BIGINT,`tag_name` STRING,`tombstone` STRING,`create_dt` DATE,`update_dt` DATE,`create_sso` STRING) row format delimited fields terminated by '\t'
INFO  : Completed executing command(queryId=root_20210329181757_90304189-fe5f-4930-a8b0-e9b8372cd72f); Time taken: 0.0 seconds
INFO  : OK
No rows affected (0.071 seconds)
0: jdbc:hive2://192.168.0.61:10000> create table if not exists `mysql_ziyun_andon`.`andon_user_statistics` (`id` BIGINT,`statistics_date` STRING,`sso_id` STRING,`t ag_id` BIGINT,`average_duration` STRING,`average_duration_value` BIGINT,`link_relative` STRING,`org_id` BIGINT,`create_dt` DATE,`update_dt` DATE,`status` STRING,`d omain_id` STRING) row format delimited fields terminated by '\t';
INFO  : Compiling command(queryId=root_20210329181757_611b1947-cab2-4748-8262-64db4fbe4641): create table if not exists `mysql_ziyun_andon`.`andon_user_statistics` (`id` BIGINT,`statistics_date` STRING,`sso_id` STRING,`tag_id` BIGINT,`average_duration` STRING,`average_duration_value` BIGINT,`link_relative` STRING,`org_id` BIGINT,`create_dt` DATE,`update_dt` DATE,`status` STRING,`domain_id` STRING) row format delimited fields terminated by '\t'
INFO  : Semantic Analysis Completed (retrial = false)
INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)
INFO  : Completed compiling command(queryId=root_20210329181757_611b1947-cab2-4748-8262-64db4fbe4641); Time taken: 0.056 seconds
INFO  : Executing command(queryId=root_20210329181757_611b1947-cab2-4748-8262-64db4fbe4641): create table if not exists `mysql_ziyun_andon`.`andon_user_statistics` (`id` BIGINT,`statistics_date` STRING,`sso_id` STRING,`tag_id` BIGINT,`average_duration` STRING,`average_duration_value` BIGINT,`link_relative` STRING,`org_id` BIGINT,`create_dt` DATE,`update_dt` DATE,`status` STRING,`domain_id` STRING) row format delimited fields terminated by '\t'
INFO  : Completed executing command(queryId=root_20210329181757_611b1947-cab2-4748-8262-64db4fbe4641); Time taken: 0.0 seconds
INFO  : OK
No rows affected (0.074 seconds)
0: jdbc:hive2://192.168.0.61:10000> create table if not exists `mysql_ziyun_andon`.`andon_user_statistics_copy1` (`id` BIGINT,`statistics_date` STRING,`sso_id` STR ING,`tag_id` BIGINT,`average_duration` STRING,`average_duration_value` BIGINT,`link_relative` STRING,`org_hcode` STRING,`create_dt` DATE,`update_dt` DATE,`status`  STRING) row format delimited fields terminated by '\t';
INFO  : Compiling command(queryId=root_20210329181757_00018392-fb95-4b08-8fc2-cc2979ff9bc5): create table if not exists `mysql_ziyun_andon`.`andon_user_statistics_copy1` (`id` BIGINT,`statistics_date` STRING,`sso_id` STRING,`tag_id` BIGINT,`average_duration` STRING,`average_duration_value` BIGINT,`link_relative` STRING,`org_hcode` STRING,`create_dt` DATE,`update_dt` DATE,`status` STRING) row format delimited fields terminated by '\t'
INFO  : Semantic Analysis Completed (retrial = false)
INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)
INFO  : Completed compiling command(queryId=root_20210329181757_00018392-fb95-4b08-8fc2-cc2979ff9bc5); Time taken: 0.053 seconds
INFO  : Executing command(queryId=root_20210329181757_00018392-fb95-4b08-8fc2-cc2979ff9bc5): create table if not exists `mysql_ziyun_andon`.`andon_user_statistics_copy1` (`id` BIGINT,`statistics_date` STRING,`sso_id` STRING,`tag_id` BIGINT,`average_duration` STRING,`average_duration_value` BIGINT,`link_relative` STRING,`org_hcode` STRING,`create_dt` DATE,`update_dt` DATE,`status` STRING) row format delimited fields terminated by '\t'
INFO  : Completed executing command(queryId=root_20210329181757_00018392-fb95-4b08-8fc2-cc2979ff9bc5); Time taken: 0.0 seconds
INFO  : OK
No rows affected (0.072 seconds)
0: jdbc:hive2://192.168.0.61:10000> create table if not exists `mysql_ziyun_andon`.`andon_user_wechat_info` (`id` BIGINT,`app_id` STRING,`sso_id` STRING,`open_id`  STRING,`whether_open` STRING,`create_dt` DATE,`update_dt` DATE) row format delimited fields terminated by '\t';
INFO  : Compiling command(queryId=root_20210329181757_e67a77a3-8105-4240-98de-fb2ed417dbc7): create table if not exists `mysql_ziyun_andon`.`andon_user_wechat_info` (`id` BIGINT,`app_id` STRING,`sso_id` STRING,`open_id` STRING,`whether_open` STRING,`create_dt` DATE,`update_dt` DATE) row format delimited fields terminated by '\t'
INFO  : Semantic Analysis Completed (retrial = false)
INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)
INFO  : Completed compiling command(queryId=root_20210329181757_e67a77a3-8105-4240-98de-fb2ed417dbc7); Time taken: 0.049 seconds
INFO  : Executing command(queryId=root_20210329181757_e67a77a3-8105-4240-98de-fb2ed417dbc7): create table if not exists `mysql_ziyun_andon`.`andon_user_wechat_info` (`id` BIGINT,`app_id` STRING,`sso_id` STRING,`open_id` STRING,`whether_open` STRING,`create_dt` DATE,`update_dt` DATE) row format delimited fields terminated by '\t'
INFO  : Completed executing command(queryId=root_20210329181757_e67a77a3-8105-4240-98de-fb2ed417dbc7); Time taken: 0.0 seconds
INFO  : OK
No rows affected (0.069 seconds)
0: jdbc:hive2://192.168.0.61:10000> create table if not exists `mysql_ziyun_andon`.`andon_user_wechat_info_copy1` (`id` BIGINT,`app_id` STRING,`sso_id` STRING,`ope n_id` STRING,`whether_open` STRING,`create_dt` DATE,`update_dt` DATE) row format delimited fields terminated by '\t';
INFO  : Compiling command(queryId=root_20210329181757_31e7a84f-be0e-4219-847a-eaddc858a247): create table if not exists `mysql_ziyun_andon`.`andon_user_wechat_info_copy1` (`id` BIGINT,`app_id` STRING,`sso_id` STRING,`open_id` STRING,`whether_open` STRING,`create_dt` DATE,`update_dt` DATE) row format delimited fields terminated by '\t'
INFO  : Semantic Analysis Completed (retrial = false)
INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)
INFO  : Completed compiling command(queryId=root_20210329181757_31e7a84f-be0e-4219-847a-eaddc858a247); Time taken: 0.05 seconds
INFO  : Executing command(queryId=root_20210329181757_31e7a84f-be0e-4219-847a-eaddc858a247): create table if not exists `mysql_ziyun_andon`.`andon_user_wechat_info_copy1` (`id` BIGINT,`app_id` STRING,`sso_id` STRING,`open_id` STRING,`whether_open` STRING,`create_dt` DATE,`update_dt` DATE) row format delimited fields terminated by '\t'
INFO  : Completed executing command(queryId=root_20210329181757_31e7a84f-be0e-4219-847a-eaddc858a247); Time taken: 0.0 seconds
INFO  : OK
No rows affected (0.067 seconds)
0: jdbc:hive2://192.168.0.61:10000> create table if not exists `mysql_ziyun_andon`.`andon_wechat_app_info` (`id` BIGINT,`app_id` STRING,`app_secret` STRING,`sign_m ark` STRING,`description` STRING,`state` BIGINT,`create_date` DATE) row format delimited fields terminated by '\t';
INFO  : Compiling command(queryId=root_20210329181758_66f91947-ae0f-43ac-bec2-48988f8b7d88): create table if not exists `mysql_ziyun_andon`.`andon_wechat_app_info` (`id` BIGINT,`app_id` STRING,`app_secret` STRING,`sign_mark` STRING,`description` STRING,`state` BIGINT,`create_date` DATE) row format delimited fields terminated by '\t'
INFO  : Semantic Analysis Completed (retrial = false)
INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)
INFO  : Completed compiling command(queryId=root_20210329181758_66f91947-ae0f-43ac-bec2-48988f8b7d88); Time taken: 0.048 seconds
INFO  : Executing command(queryId=root_20210329181758_66f91947-ae0f-43ac-bec2-48988f8b7d88): create table if not exists `mysql_ziyun_andon`.`andon_wechat_app_info` (`id` BIGINT,`app_id` STRING,`app_secret` STRING,`sign_mark` STRING,`description` STRING,`state` BIGINT,`create_date` DATE) row format delimited fields terminated by '\t'
INFO  : Completed executing command(queryId=root_20210329181758_66f91947-ae0f-43ac-bec2-48988f8b7d88); Time taken: 0.001 seconds
INFO  : OK
No rows affected (0.064 seconds)
0: jdbc:hive2://192.168.0.61:10000> create table if not exists `mysql_ziyun_andon`.`andon_wechat_app_info_copy1` (`id` BIGINT,`app_id` STRING,`app_secret` STRING,` sign_mark` STRING,`description` STRING,`state` BIGINT,`create_date` DATE) row format delimited fields terminated by '\t';
INFO  : Compiling command(queryId=root_20210329181758_24f2721e-e10e-4be3-8675-0c637c2f9aaf): create table if not exists `mysql_ziyun_andon`.`andon_wechat_app_info_copy1` (`id` BIGINT,`app_id` STRING,`app_secret` STRING,`sign_mark` STRING,`description` STRING,`state` BIGINT,`create_date` DATE) row format delimited fields terminated by '\t'
INFO  : Semantic Analysis Completed (retrial = false)
INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)
INFO  : Completed compiling command(queryId=root_20210329181758_24f2721e-e10e-4be3-8675-0c637c2f9aaf); Time taken: 0.049 seconds
INFO  : Executing command(queryId=root_20210329181758_24f2721e-e10e-4be3-8675-0c637c2f9aaf): create table if not exists `mysql_ziyun_andon`.`andon_wechat_app_info_copy1` (`id` BIGINT,`app_id` STRING,`app_secret` STRING,`sign_mark` STRING,`description` STRING,`state` BIGINT,`create_date` DATE) row format delimited fields terminated by '\t'
INFO  : Completed executing command(queryId=root_20210329181758_24f2721e-e10e-4be3-8675-0c637c2f9aaf); Time taken: 0.001 seconds
INFO  : OK
No rows affected (0.065 seconds)
0: jdbc:hive2://192.168.0.61:10000> 
0: jdbc:hive2://192.168.0.61:10000> Closing: 0: jdbc:hive2://192.168.0.61:10000
建库建表语句执行完成
将数据源数据以append模式加载到hdfs
开始同步一张表
增量配置文件：/software/datax/sync/bin/../conf/jdbc:mysql:192.168.0.124:3306/ziyun-andon.increment
/software/datax/sync/bin/../conf/jdbc:mysql:192.168.0.124:3306/ziyun-andon.increment是文件，进入判断#
maybe_results：
开始全量同步表andon_equipment_position

DataX (DATAX-OPENSOURCE-3.0), From Alibaba !
Copyright (C) 2010-2017, Alibaba Group. All Rights Reserved.


2021-03-29 18:17:59.356 [main] INFO  VMInfo - VMInfo# operatingSystem class => sun.management.OperatingSystemImpl
2021-03-29 18:17:59.367 [main] INFO  Engine - the machine info  => 

	osInfo:	Oracle Corporation 1.8 25.201-b09
	jvmInfo:	Linux amd64 3.10.0-957.el7.x86_64
	cpu num:	16

	totalPhysicalMemory:	-0.00G
	freePhysicalMemory:	-0.00G
	maxFileDescriptorCount:	-1
	currentOpenFileDescriptorCount:	-1

	GC Names	[PS MarkSweep, PS Scavenge]

	MEMORY_NAME                    | allocation_size                | init_size                      
	PS Eden Space                  | 256.00MB                       | 256.00MB                       
	Code Cache                     | 240.00MB                       | 2.44MB                         
	Compressed Class Space         | 1,024.00MB                     | 0.00MB                         
	PS Survivor Space              | 42.50MB                        | 42.50MB                        
	PS Old Gen                     | 683.00MB                       | 683.00MB                       
	Metaspace                      | -0.00MB                        | 0.00MB                         


2021-03-29 18:17:59.396 [main] INFO  Engine - 
{
	"content":[
		{
			"reader":{
				"name":"mysqlreader",
				"parameter":{
					"column":[
						"`id`",
						"`device_id`",
						"`device_position`",
						"`org_hcode`"
					],
					"connection":[
						{
							"jdbcUrl":[
								"jdbc:mysql://192.168.0.124:3306/ziyun-andon"
							],
							"table":[
								"andon_equipment_position"
							]
						}
					],
					"password":"********",
					"username":"ziyunIot",
					"where":"1=1"
				}
			},
			"writer":{
				"name":"hdfswriter",
				"parameter":{
					"column":[
						{
							"name":"`id`",
							"type":"BIGINT"
						},
						{
							"name":"`device_id`",
							"type":"STRING"
						},
						{
							"name":"`device_position`",
							"type":"STRING"
						},
						{
							"name":"`org_hcode`",
							"type":"STRING"
						}
					],
					"compress":"gzip",
					"defaultFS":"hdfs://nameservice1",
					"fieldDelimiter":"\t",
					"fileName":"andon_equipment_position",
					"fileType":"text",
					"hadoopConfig":{
						"dfs.client.failover.proxy.provider.nameservice1":"org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider",
						"dfs.ha.namenodes.nameservice1":"nn1,nn2",
						"dfs.namenode.rpc-address.nameservice1.nn1":"ziyunbd01:8020",
						"dfs.namenode.rpc-address.nameservice1.nn2":"ziyunbd02:8020",
						"dfs.nameservices":"nameservice1"
					},
					"path":"/user/hive/warehouse/mysql_ziyun_andon/andon_equipment_position",
					"writeMode":"append"
				}
			}
		}
	],
	"setting":{
		"speed":{
			"channel":"3"
		}
	}
}

2021-03-29 18:17:59.423 [main] WARN  Engine - prioriy set to 0, because NumberFormatException, the value is: null
2021-03-29 18:17:59.425 [main] INFO  PerfTrace - PerfTrace traceId=job_-1, isEnable=false, priority=0
2021-03-29 18:17:59.426 [main] INFO  JobContainer - DataX jobContainer starts job.
2021-03-29 18:17:59.429 [main] INFO  JobContainer - Set jobId = 0
2021-03-29 18:18:00.005 [job-0] INFO  OriginalConfPretreatmentUtil - Available jdbcUrl:jdbc:mysql://192.168.0.124:3306/ziyun-andon?yearIsDateType=false&zeroDateTimeBehavior=convertToNull&tinyInt1isBit=false&rewriteBatchedStatements=true.
2021-03-29 18:18:00.034 [job-0] INFO  OriginalConfPretreatmentUtil - table:[andon_equipment_position] has columns:[id,device_id,device_position,org_hcode].
Mar 29, 2021 6:18:00 PM org.apache.hadoop.util.NativeCodeLoader <clinit>
WARNING: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-03-29 18:18:02.224 [job-0] INFO  JobContainer - jobContainer starts to do prepare ...
2021-03-29 18:18:02.226 [job-0] INFO  JobContainer - DataX Reader.Job [mysqlreader] do prepare work .
2021-03-29 18:18:02.227 [job-0] INFO  JobContainer - DataX Writer.Job [hdfswriter] do prepare work .
2021-03-29 18:18:02.427 [job-0] INFO  HdfsWriter$Job - 由于您配置了writeMode append, 写入前不做清理工作, [/user/hive/warehouse/mysql_ziyun_andon/andon_equipment_position] 目录下写入相应文件名前缀  [andon_equipment_position] 的文件
2021-03-29 18:18:02.428 [job-0] INFO  JobContainer - jobContainer starts to do split ...
2021-03-29 18:18:02.430 [job-0] INFO  JobContainer - Job set Channel-Number to 3 channels.
2021-03-29 18:18:02.438 [job-0] INFO  JobContainer - DataX Reader.Job [mysqlreader] splits to [1] tasks.
2021-03-29 18:18:02.439 [job-0] INFO  HdfsWriter$Job - begin do split...
2021-03-29 18:18:02.447 [job-0] INFO  HdfsWriter$Job - splited write file name:[hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_equipment_position__10965c4b_940c_4605_b605_2615689b2b88/andon_equipment_position__5e95a6a2_6039_4269_8a8b_7d6088692994]
2021-03-29 18:18:02.447 [job-0] INFO  HdfsWriter$Job - end do split.
2021-03-29 18:18:02.447 [job-0] INFO  JobContainer - DataX Writer.Job [hdfswriter] splits to [1] tasks.
2021-03-29 18:18:02.485 [job-0] INFO  JobContainer - jobContainer starts to do schedule ...
2021-03-29 18:18:02.493 [job-0] INFO  JobContainer - Scheduler starts [1] taskGroups.
2021-03-29 18:18:02.497 [job-0] INFO  JobContainer - Running by standalone Mode.
2021-03-29 18:18:02.509 [taskGroup-0] INFO  TaskGroupContainer - taskGroupId=[0] start [1] channels for [1] tasks.
2021-03-29 18:18:02.517 [taskGroup-0] INFO  Channel - Channel set byte_speed_limit to -1, No bps activated.
2021-03-29 18:18:02.518 [taskGroup-0] INFO  Channel - Channel set record_speed_limit to -1, No tps activated.
2021-03-29 18:18:02.536 [taskGroup-0] INFO  TaskGroupContainer - taskGroup[0] taskId[0] attemptCount[1] is started
2021-03-29 18:18:02.544 [0-0-0-reader] INFO  CommonRdbmsReader$Task - Begin to read record by Sql: [select `id`,`device_id`,`device_position`,`org_hcode` from andon_equipment_position where (1=1)
] jdbcUrl:[jdbc:mysql://192.168.0.124:3306/ziyun-andon?yearIsDateType=false&zeroDateTimeBehavior=convertToNull&tinyInt1isBit=false&rewriteBatchedStatements=true].
2021-03-29 18:18:02.584 [0-0-0-reader] INFO  CommonRdbmsReader$Task - Finished read record by Sql: [select `id`,`device_id`,`device_position`,`org_hcode` from andon_equipment_position where (1=1)
] jdbcUrl:[jdbc:mysql://192.168.0.124:3306/ziyun-andon?yearIsDateType=false&zeroDateTimeBehavior=convertToNull&tinyInt1isBit=false&rewriteBatchedStatements=true].
2021-03-29 18:18:02.601 [0-0-0-writer] INFO  HdfsWriter$Task - begin do write...
2021-03-29 18:18:02.603 [0-0-0-writer] INFO  HdfsWriter$Task - write to file : [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_equipment_position__10965c4b_940c_4605_b605_2615689b2b88/andon_equipment_position__5e95a6a2_6039_4269_8a8b_7d6088692994]
2021-03-29 18:18:03.008 [0-0-0-writer] INFO  HdfsWriter$Task - end do write
2021-03-29 18:18:03.038 [taskGroup-0] INFO  TaskGroupContainer - taskGroup[0] taskId[0] is successed, used[504]ms
2021-03-29 18:18:03.039 [taskGroup-0] INFO  TaskGroupContainer - taskGroup[0] completed it's tasks.
2021-03-29 18:18:12.532 [job-0] INFO  StandAloneJobContainerCommunicator - Total 55 records, 2532 bytes | Speed 253B/s, 5 records/s | Error 0 records, 0 bytes |  All Task WaitWriterTime 0.001s |  All Task WaitReaderTime 0.000s | Percentage 100.00%
2021-03-29 18:18:12.532 [job-0] INFO  AbstractScheduler - Scheduler accomplished all tasks.
2021-03-29 18:18:12.533 [job-0] INFO  JobContainer - DataX Writer.Job [hdfswriter] do post work.
2021-03-29 18:18:12.534 [job-0] INFO  HdfsWriter$Job - start rename file [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_equipment_position__10965c4b_940c_4605_b605_2615689b2b88/andon_equipment_position__5e95a6a2_6039_4269_8a8b_7d6088692994.gz] to file [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_equipment_position/andon_equipment_position__5e95a6a2_6039_4269_8a8b_7d6088692994.gz].
2021-03-29 18:18:12.549 [job-0] INFO  HdfsWriter$Job - finish rename file [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_equipment_position__10965c4b_940c_4605_b605_2615689b2b88/andon_equipment_position__5e95a6a2_6039_4269_8a8b_7d6088692994.gz] to file [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_equipment_position/andon_equipment_position__5e95a6a2_6039_4269_8a8b_7d6088692994.gz].
2021-03-29 18:18:12.549 [job-0] INFO  HdfsWriter$Job - start delete tmp dir [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_equipment_position__10965c4b_940c_4605_b605_2615689b2b88] .
2021-03-29 18:18:12.562 [job-0] INFO  HdfsWriter$Job - finish delete tmp dir [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_equipment_position__10965c4b_940c_4605_b605_2615689b2b88] .
2021-03-29 18:18:12.563 [job-0] INFO  JobContainer - DataX Reader.Job [mysqlreader] do post work.
2021-03-29 18:18:12.563 [job-0] INFO  JobContainer - DataX jobId [0] completed successfully.
2021-03-29 18:18:12.565 [job-0] INFO  HookInvoker - No hook invoked, because base dir not exists or is a file: /software/datax/hook
2021-03-29 18:18:12.669 [job-0] INFO  JobContainer - 
	 [total cpu info] => 
		averageCpu                     | maxDeltaCpu                    | minDeltaCpu                    
		-1.00%                         | -1.00%                         | -1.00%
                        

	 [total gc info] => 
		 NAME                 | totalGCCount       | maxDeltaGCCount    | minDeltaGCCount    | totalGCTime        | maxDeltaGCTime     | minDeltaGCTime     
		 PS MarkSweep         | 1                  | 1                  | 1                  | 0.062s             | 0.062s             | 0.062s             
		 PS Scavenge          | 1                  | 1                  | 1                  | 0.045s             | 0.045s             | 0.045s             

2021-03-29 18:18:12.670 [job-0] INFO  JobContainer - PerfTrace not enable!
2021-03-29 18:18:12.670 [job-0] INFO  StandAloneJobContainerCommunicator - Total 55 records, 2532 bytes | Speed 253B/s, 5 records/s | Error 0 records, 0 bytes |  All Task WaitWriterTime 0.001s |  All Task WaitReaderTime 0.000s | Percentage 100.00%
2021-03-29 18:18:12.673 [job-0] INFO  JobContainer - 
任务启动时刻                    : 2021-03-29 18:17:59
任务结束时刻                    : 2021-03-29 18:18:12
任务总计耗时                    :                 13s
任务平均流量                    :              253B/s
记录写入速度                    :              5rec/s
读出记录总数                    :                  55
读写失败总数                    :                   0

andon_equipment_position表全量同步的结果为0
开始同步一张表
增量配置文件：/software/datax/sync/bin/../conf/jdbc:mysql:192.168.0.124:3306/ziyun-andon.increment
/software/datax/sync/bin/../conf/jdbc:mysql:192.168.0.124:3306/ziyun-andon.increment是文件，进入判断#
maybe_results：
开始全量同步表andon_equipment_position_copy1

DataX (DATAX-OPENSOURCE-3.0), From Alibaba !
Copyright (C) 2010-2017, Alibaba Group. All Rights Reserved.


2021-03-29 18:18:13.829 [main] INFO  VMInfo - VMInfo# operatingSystem class => sun.management.OperatingSystemImpl
2021-03-29 18:18:13.843 [main] INFO  Engine - the machine info  => 

	osInfo:	Oracle Corporation 1.8 25.201-b09
	jvmInfo:	Linux amd64 3.10.0-957.el7.x86_64
	cpu num:	16

	totalPhysicalMemory:	-0.00G
	freePhysicalMemory:	-0.00G
	maxFileDescriptorCount:	-1
	currentOpenFileDescriptorCount:	-1

	GC Names	[PS MarkSweep, PS Scavenge]

	MEMORY_NAME                    | allocation_size                | init_size                      
	PS Eden Space                  | 256.00MB                       | 256.00MB                       
	Code Cache                     | 240.00MB                       | 2.44MB                         
	Compressed Class Space         | 1,024.00MB                     | 0.00MB                         
	PS Survivor Space              | 42.50MB                        | 42.50MB                        
	PS Old Gen                     | 683.00MB                       | 683.00MB                       
	Metaspace                      | -0.00MB                        | 0.00MB                         


2021-03-29 18:18:13.884 [main] INFO  Engine - 
{
	"content":[
		{
			"reader":{
				"name":"mysqlreader",
				"parameter":{
					"column":[
						"`id`",
						"`device_id`",
						"`device_position`",
						"`org_hcode`"
					],
					"connection":[
						{
							"jdbcUrl":[
								"jdbc:mysql://192.168.0.124:3306/ziyun-andon"
							],
							"table":[
								"andon_equipment_position_copy1"
							]
						}
					],
					"password":"********",
					"username":"ziyunIot",
					"where":"1=1"
				}
			},
			"writer":{
				"name":"hdfswriter",
				"parameter":{
					"column":[
						{
							"name":"`id`",
							"type":"BIGINT"
						},
						{
							"name":"`device_id`",
							"type":"STRING"
						},
						{
							"name":"`device_position`",
							"type":"STRING"
						},
						{
							"name":"`org_hcode`",
							"type":"STRING"
						}
					],
					"compress":"gzip",
					"defaultFS":"hdfs://nameservice1",
					"fieldDelimiter":"\t",
					"fileName":"andon_equipment_position_copy1",
					"fileType":"text",
					"hadoopConfig":{
						"dfs.client.failover.proxy.provider.nameservice1":"org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider",
						"dfs.ha.namenodes.nameservice1":"nn1,nn2",
						"dfs.namenode.rpc-address.nameservice1.nn1":"ziyunbd01:8020",
						"dfs.namenode.rpc-address.nameservice1.nn2":"ziyunbd02:8020",
						"dfs.nameservices":"nameservice1"
					},
					"path":"/user/hive/warehouse/mysql_ziyun_andon/andon_equipment_position_copy1",
					"writeMode":"append"
				}
			}
		}
	],
	"setting":{
		"speed":{
			"channel":"3"
		}
	}
}

2021-03-29 18:18:13.921 [main] WARN  Engine - prioriy set to 0, because NumberFormatException, the value is: null
2021-03-29 18:18:13.925 [main] INFO  PerfTrace - PerfTrace traceId=job_-1, isEnable=false, priority=0
2021-03-29 18:18:13.926 [main] INFO  JobContainer - DataX jobContainer starts job.
2021-03-29 18:18:13.930 [main] INFO  JobContainer - Set jobId = 0
2021-03-29 18:18:14.540 [job-0] INFO  OriginalConfPretreatmentUtil - Available jdbcUrl:jdbc:mysql://192.168.0.124:3306/ziyun-andon?yearIsDateType=false&zeroDateTimeBehavior=convertToNull&tinyInt1isBit=false&rewriteBatchedStatements=true.
2021-03-29 18:18:14.572 [job-0] INFO  OriginalConfPretreatmentUtil - table:[andon_equipment_position_copy1] has columns:[id,device_id,device_position,org_hcode].
Mar 29, 2021 6:18:15 PM org.apache.hadoop.util.NativeCodeLoader <clinit>
WARNING: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-03-29 18:18:16.496 [job-0] INFO  JobContainer - jobContainer starts to do prepare ...
2021-03-29 18:18:16.498 [job-0] INFO  JobContainer - DataX Reader.Job [mysqlreader] do prepare work .
2021-03-29 18:18:16.499 [job-0] INFO  JobContainer - DataX Writer.Job [hdfswriter] do prepare work .
2021-03-29 18:18:16.679 [job-0] INFO  HdfsWriter$Job - 由于您配置了writeMode append, 写入前不做清理工作, [/user/hive/warehouse/mysql_ziyun_andon/andon_equipment_position_copy1] 目录下写入相应文件名前缀  [andon_equipment_position_copy1] 的文件
2021-03-29 18:18:16.680 [job-0] INFO  JobContainer - jobContainer starts to do split ...
2021-03-29 18:18:16.680 [job-0] INFO  JobContainer - Job set Channel-Number to 3 channels.
2021-03-29 18:18:16.687 [job-0] INFO  JobContainer - DataX Reader.Job [mysqlreader] splits to [1] tasks.
2021-03-29 18:18:16.687 [job-0] INFO  HdfsWriter$Job - begin do split...
2021-03-29 18:18:16.693 [job-0] INFO  HdfsWriter$Job - splited write file name:[hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_equipment_position_copy1__d2a37f85_dd45_4ba5_bcc4_87b4d9c4563b/andon_equipment_position_copy1__8d119a28_c39e_4a3a_95c6_18d40dfdbffa]
2021-03-29 18:18:16.693 [job-0] INFO  HdfsWriter$Job - end do split.
2021-03-29 18:18:16.693 [job-0] INFO  JobContainer - DataX Writer.Job [hdfswriter] splits to [1] tasks.
2021-03-29 18:18:16.720 [job-0] INFO  JobContainer - jobContainer starts to do schedule ...
2021-03-29 18:18:16.728 [job-0] INFO  JobContainer - Scheduler starts [1] taskGroups.
2021-03-29 18:18:16.733 [job-0] INFO  JobContainer - Running by standalone Mode.
2021-03-29 18:18:16.746 [taskGroup-0] INFO  TaskGroupContainer - taskGroupId=[0] start [1] channels for [1] tasks.
2021-03-29 18:18:16.755 [taskGroup-0] INFO  Channel - Channel set byte_speed_limit to -1, No bps activated.
2021-03-29 18:18:16.755 [taskGroup-0] INFO  Channel - Channel set record_speed_limit to -1, No tps activated.
2021-03-29 18:18:16.774 [taskGroup-0] INFO  TaskGroupContainer - taskGroup[0] taskId[0] attemptCount[1] is started
2021-03-29 18:18:16.781 [0-0-0-reader] INFO  CommonRdbmsReader$Task - Begin to read record by Sql: [select `id`,`device_id`,`device_position`,`org_hcode` from andon_equipment_position_copy1 where (1=1)
] jdbcUrl:[jdbc:mysql://192.168.0.124:3306/ziyun-andon?yearIsDateType=false&zeroDateTimeBehavior=convertToNull&tinyInt1isBit=false&rewriteBatchedStatements=true].
2021-03-29 18:18:16.817 [0-0-0-writer] INFO  HdfsWriter$Task - begin do write...
2021-03-29 18:18:16.818 [0-0-0-writer] INFO  HdfsWriter$Task - write to file : [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_equipment_position_copy1__d2a37f85_dd45_4ba5_bcc4_87b4d9c4563b/andon_equipment_position_copy1__8d119a28_c39e_4a3a_95c6_18d40dfdbffa]
2021-03-29 18:18:16.821 [0-0-0-reader] INFO  CommonRdbmsReader$Task - Finished read record by Sql: [select `id`,`device_id`,`device_position`,`org_hcode` from andon_equipment_position_copy1 where (1=1)
] jdbcUrl:[jdbc:mysql://192.168.0.124:3306/ziyun-andon?yearIsDateType=false&zeroDateTimeBehavior=convertToNull&tinyInt1isBit=false&rewriteBatchedStatements=true].
2021-03-29 18:18:17.149 [0-0-0-writer] INFO  HdfsWriter$Task - end do write
2021-03-29 18:18:17.176 [taskGroup-0] INFO  TaskGroupContainer - taskGroup[0] taskId[0] is successed, used[405]ms
2021-03-29 18:18:17.177 [taskGroup-0] INFO  TaskGroupContainer - taskGroup[0] completed it's tasks.
2021-03-29 18:18:26.763 [job-0] INFO  StandAloneJobContainerCommunicator - Total 54 records, 2475 bytes | Speed 247B/s, 5 records/s | Error 0 records, 0 bytes |  All Task WaitWriterTime 0.000s |  All Task WaitReaderTime 0.000s | Percentage 100.00%
2021-03-29 18:18:26.764 [job-0] INFO  AbstractScheduler - Scheduler accomplished all tasks.
2021-03-29 18:18:26.765 [job-0] INFO  JobContainer - DataX Writer.Job [hdfswriter] do post work.
2021-03-29 18:18:26.766 [job-0] INFO  HdfsWriter$Job - start rename file [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_equipment_position_copy1__d2a37f85_dd45_4ba5_bcc4_87b4d9c4563b/andon_equipment_position_copy1__8d119a28_c39e_4a3a_95c6_18d40dfdbffa.gz] to file [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_equipment_position_copy1/andon_equipment_position_copy1__8d119a28_c39e_4a3a_95c6_18d40dfdbffa.gz].
2021-03-29 18:18:26.778 [job-0] INFO  HdfsWriter$Job - finish rename file [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_equipment_position_copy1__d2a37f85_dd45_4ba5_bcc4_87b4d9c4563b/andon_equipment_position_copy1__8d119a28_c39e_4a3a_95c6_18d40dfdbffa.gz] to file [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_equipment_position_copy1/andon_equipment_position_copy1__8d119a28_c39e_4a3a_95c6_18d40dfdbffa.gz].
2021-03-29 18:18:26.778 [job-0] INFO  HdfsWriter$Job - start delete tmp dir [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_equipment_position_copy1__d2a37f85_dd45_4ba5_bcc4_87b4d9c4563b] .
2021-03-29 18:18:26.789 [job-0] INFO  HdfsWriter$Job - finish delete tmp dir [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_equipment_position_copy1__d2a37f85_dd45_4ba5_bcc4_87b4d9c4563b] .
2021-03-29 18:18:26.790 [job-0] INFO  JobContainer - DataX Reader.Job [mysqlreader] do post work.
2021-03-29 18:18:26.790 [job-0] INFO  JobContainer - DataX jobId [0] completed successfully.
2021-03-29 18:18:26.792 [job-0] INFO  HookInvoker - No hook invoked, because base dir not exists or is a file: /software/datax/hook
2021-03-29 18:18:26.895 [job-0] INFO  JobContainer - 
	 [total cpu info] => 
		averageCpu                     | maxDeltaCpu                    | minDeltaCpu                    
		-1.00%                         | -1.00%                         | -1.00%
                        

	 [total gc info] => 
		 NAME                 | totalGCCount       | maxDeltaGCCount    | minDeltaGCCount    | totalGCTime        | maxDeltaGCTime     | minDeltaGCTime     
		 PS MarkSweep         | 1                  | 1                  | 1                  | 0.067s             | 0.067s             | 0.067s             
		 PS Scavenge          | 1                  | 1                  | 1                  | 0.040s             | 0.040s             | 0.040s             

2021-03-29 18:18:26.896 [job-0] INFO  JobContainer - PerfTrace not enable!
2021-03-29 18:18:26.896 [job-0] INFO  StandAloneJobContainerCommunicator - Total 54 records, 2475 bytes | Speed 247B/s, 5 records/s | Error 0 records, 0 bytes |  All Task WaitWriterTime 0.000s |  All Task WaitReaderTime 0.000s | Percentage 100.00%
2021-03-29 18:18:26.898 [job-0] INFO  JobContainer - 
任务启动时刻                    : 2021-03-29 18:18:13
任务结束时刻                    : 2021-03-29 18:18:26
任务总计耗时                    :                 12s
任务平均流量                    :              247B/s
记录写入速度                    :              5rec/s
读出记录总数                    :                  54
读写失败总数                    :                   0

andon_equipment_position_copy1表全量同步的结果为0
开始同步一张表
增量配置文件：/software/datax/sync/bin/../conf/jdbc:mysql:192.168.0.124:3306/ziyun-andon.increment
/software/datax/sync/bin/../conf/jdbc:mysql:192.168.0.124:3306/ziyun-andon.increment是文件，进入判断#
maybe_results：andon_fault_tag_statistics,update_dt andon_fault_tag_statistics_copy1,update_dt
表名：andon_fault_tag_statistics
字段名：update_dt
开始增量同步表andon_fault_tag_statistics
query_sql_info: update_dt 2021-02-04 2021-02-06

DataX (DATAX-OPENSOURCE-3.0), From Alibaba !
Copyright (C) 2010-2017, Alibaba Group. All Rights Reserved.


2021-03-29 18:18:27.906 [main] INFO  VMInfo - VMInfo# operatingSystem class => sun.management.OperatingSystemImpl
2021-03-29 18:18:27.917 [main] INFO  Engine - the machine info  => 

	osInfo:	Oracle Corporation 1.8 25.201-b09
	jvmInfo:	Linux amd64 3.10.0-957.el7.x86_64
	cpu num:	16

	totalPhysicalMemory:	-0.00G
	freePhysicalMemory:	-0.00G
	maxFileDescriptorCount:	-1
	currentOpenFileDescriptorCount:	-1

	GC Names	[PS MarkSweep, PS Scavenge]

	MEMORY_NAME                    | allocation_size                | init_size                      
	PS Eden Space                  | 256.00MB                       | 256.00MB                       
	Code Cache                     | 240.00MB                       | 2.44MB                         
	Compressed Class Space         | 1,024.00MB                     | 0.00MB                         
	PS Survivor Space              | 42.50MB                        | 42.50MB                        
	PS Old Gen                     | 683.00MB                       | 683.00MB                       
	Metaspace                      | -0.00MB                        | 0.00MB                         


2021-03-29 18:18:27.952 [main] INFO  Engine - 
{
	"content":[
		{
			"reader":{
				"name":"mysqlreader",
				"parameter":{
					"column":[
						"`id`",
						"`statistics_date`",
						"`fault_tag_id`",
						"`statistics_count`",
						"`average_downtime_interval`",
						"`average_downtime_duration`",
						"`average_downtime_interval_value`",
						"`average_downtime_duration_value`",
						"`andon_tag_id`",
						"`org_id`",
						"`create_dt`",
						"`update_dt`",
						"`status`",
						"`domain_id`"
					],
					"connection":[
						{
							"jdbcUrl":[
								"jdbc:mysql://192.168.0.124:3306/ziyun-andon"
							],
							"table":[
								"andon_fault_tag_statistics"
							]
						}
					],
					"password":"********",
					"username":"ziyunIot",
					"where":"update_dt > '2021-02-04' and update_dt < '2021-02-06'"
				}
			},
			"writer":{
				"name":"hdfswriter",
				"parameter":{
					"column":[
						{
							"name":"`id`",
							"type":"BIGINT"
						},
						{
							"name":"`statistics_date`",
							"type":"STRING"
						},
						{
							"name":"`fault_tag_id`",
							"type":"BIGINT"
						},
						{
							"name":"`statistics_count`",
							"type":"BIGINT"
						},
						{
							"name":"`average_downtime_interval`",
							"type":"STRING"
						},
						{
							"name":"`average_downtime_duration`",
							"type":"STRING"
						},
						{
							"name":"`average_downtime_interval_value`",
							"type":"BIGINT"
						},
						{
							"name":"`average_downtime_duration_value`",
							"type":"BIGINT"
						},
						{
							"name":"`andon_tag_id`",
							"type":"BIGINT"
						},
						{
							"name":"`org_id`",
							"type":"BIGINT"
						},
						{
							"name":"`create_dt`",
							"type":"DATE"
						},
						{
							"name":"`update_dt`",
							"type":"DATE"
						},
						{
							"name":"`status`",
							"type":"STRING"
						},
						{
							"name":"`domain_id`",
							"type":"STRING"
						}
					],
					"compress":"gzip",
					"defaultFS":"hdfs://nameservice1",
					"fieldDelimiter":"\t",
					"fileName":"andon_fault_tag_statistics",
					"fileType":"text",
					"hadoopConfig":{
						"dfs.client.failover.proxy.provider.nameservice1":"org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider",
						"dfs.ha.namenodes.nameservice1":"nn1,nn2",
						"dfs.namenode.rpc-address.nameservice1.nn1":"ziyunbd01:8020",
						"dfs.namenode.rpc-address.nameservice1.nn2":"ziyunbd02:8020",
						"dfs.nameservices":"nameservice1"
					},
					"path":"/user/hive/warehouse/mysql_ziyun_andon/andon_fault_tag_statistics",
					"writeMode":"append"
				}
			}
		}
	],
	"setting":{
		"speed":{
			"channel":"1"
		}
	}
}

2021-03-29 18:18:27.981 [main] WARN  Engine - prioriy set to 0, because NumberFormatException, the value is: null
2021-03-29 18:18:27.983 [main] INFO  PerfTrace - PerfTrace traceId=job_-1, isEnable=false, priority=0
2021-03-29 18:18:27.983 [main] INFO  JobContainer - DataX jobContainer starts job.
2021-03-29 18:18:27.985 [main] INFO  JobContainer - Set jobId = 0
2021-03-29 18:18:28.428 [job-0] INFO  OriginalConfPretreatmentUtil - Available jdbcUrl:jdbc:mysql://192.168.0.124:3306/ziyun-andon?yearIsDateType=false&zeroDateTimeBehavior=convertToNull&tinyInt1isBit=false&rewriteBatchedStatements=true.
2021-03-29 18:18:28.457 [job-0] INFO  OriginalConfPretreatmentUtil - table:[andon_fault_tag_statistics] has columns:[id,statistics_date,fault_tag_id,statistics_count,average_downtime_interval,average_downtime_duration,average_downtime_interval_value,average_downtime_duration_value,andon_tag_id,org_id,create_dt,update_dt,status,domain_id].
Mar 29, 2021 6:18:29 PM org.apache.hadoop.util.NativeCodeLoader <clinit>
WARNING: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-03-29 18:18:30.220 [job-0] INFO  JobContainer - jobContainer starts to do prepare ...
2021-03-29 18:18:30.223 [job-0] INFO  JobContainer - DataX Reader.Job [mysqlreader] do prepare work .
2021-03-29 18:18:30.224 [job-0] INFO  JobContainer - DataX Writer.Job [hdfswriter] do prepare work .
2021-03-29 18:18:30.452 [job-0] INFO  HdfsWriter$Job - 由于您配置了writeMode append, 写入前不做清理工作, [/user/hive/warehouse/mysql_ziyun_andon/andon_fault_tag_statistics] 目录下写入相应文件名前缀  [andon_fault_tag_statistics] 的文件
2021-03-29 18:18:30.453 [job-0] INFO  JobContainer - jobContainer starts to do split ...
2021-03-29 18:18:30.454 [job-0] INFO  JobContainer - Job set Channel-Number to 1 channels.
2021-03-29 18:18:30.465 [job-0] INFO  JobContainer - DataX Reader.Job [mysqlreader] splits to [1] tasks.
2021-03-29 18:18:30.466 [job-0] INFO  HdfsWriter$Job - begin do split...
2021-03-29 18:18:30.475 [job-0] INFO  HdfsWriter$Job - splited write file name:[hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_fault_tag_statistics__d25d4b9f_d8c2_4228_9104_b72ec3e4e5a7/andon_fault_tag_statistics__9d11b07c_99ad_4417_ba30_9c64719f4e2a]
2021-03-29 18:18:30.476 [job-0] INFO  HdfsWriter$Job - end do split.
2021-03-29 18:18:30.477 [job-0] INFO  JobContainer - DataX Writer.Job [hdfswriter] splits to [1] tasks.
2021-03-29 18:18:30.520 [job-0] INFO  JobContainer - jobContainer starts to do schedule ...
2021-03-29 18:18:30.528 [job-0] INFO  JobContainer - Scheduler starts [1] taskGroups.
2021-03-29 18:18:30.533 [job-0] INFO  JobContainer - Running by standalone Mode.
2021-03-29 18:18:30.545 [taskGroup-0] INFO  TaskGroupContainer - taskGroupId=[0] start [1] channels for [1] tasks.
2021-03-29 18:18:30.553 [taskGroup-0] INFO  Channel - Channel set byte_speed_limit to -1, No bps activated.
2021-03-29 18:18:30.554 [taskGroup-0] INFO  Channel - Channel set record_speed_limit to -1, No tps activated.
2021-03-29 18:18:30.572 [taskGroup-0] INFO  TaskGroupContainer - taskGroup[0] taskId[0] attemptCount[1] is started
2021-03-29 18:18:30.581 [0-0-0-reader] INFO  CommonRdbmsReader$Task - Begin to read record by Sql: [select `id`,`statistics_date`,`fault_tag_id`,`statistics_count`,`average_downtime_interval`,`average_downtime_duration`,`average_downtime_interval_value`,`average_downtime_duration_value`,`andon_tag_id`,`org_id`,`create_dt`,`update_dt`,`status`,`domain_id` from andon_fault_tag_statistics where (update_dt > '2021-02-04' and update_dt < '2021-02-06')
] jdbcUrl:[jdbc:mysql://192.168.0.124:3306/ziyun-andon?yearIsDateType=false&zeroDateTimeBehavior=convertToNull&tinyInt1isBit=false&rewriteBatchedStatements=true].
2021-03-29 18:18:30.637 [0-0-0-writer] INFO  HdfsWriter$Task - begin do write...
2021-03-29 18:18:30.637 [0-0-0-writer] INFO  HdfsWriter$Task - write to file : [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_fault_tag_statistics__d25d4b9f_d8c2_4228_9104_b72ec3e4e5a7/andon_fault_tag_statistics__9d11b07c_99ad_4417_ba30_9c64719f4e2a]
2021-03-29 18:18:30.647 [0-0-0-reader] INFO  CommonRdbmsReader$Task - Finished read record by Sql: [select `id`,`statistics_date`,`fault_tag_id`,`statistics_count`,`average_downtime_interval`,`average_downtime_duration`,`average_downtime_interval_value`,`average_downtime_duration_value`,`andon_tag_id`,`org_id`,`create_dt`,`update_dt`,`status`,`domain_id` from andon_fault_tag_statistics where (update_dt > '2021-02-04' and update_dt < '2021-02-06')
] jdbcUrl:[jdbc:mysql://192.168.0.124:3306/ziyun-andon?yearIsDateType=false&zeroDateTimeBehavior=convertToNull&tinyInt1isBit=false&rewriteBatchedStatements=true].
2021-03-29 18:18:31.071 [0-0-0-writer] INFO  HdfsWriter$Task - end do write
2021-03-29 18:18:31.075 [taskGroup-0] INFO  TaskGroupContainer - taskGroup[0] taskId[0] is successed, used[506]ms
2021-03-29 18:18:31.076 [taskGroup-0] INFO  TaskGroupContainer - taskGroup[0] completed it's tasks.
2021-03-29 18:18:40.568 [job-0] INFO  StandAloneJobContainerCommunicator - Total 87 records, 6304 bytes | Speed 630B/s, 8 records/s | Error 0 records, 0 bytes |  All Task WaitWriterTime 0.001s |  All Task WaitReaderTime 0.000s | Percentage 100.00%
2021-03-29 18:18:40.568 [job-0] INFO  AbstractScheduler - Scheduler accomplished all tasks.
2021-03-29 18:18:40.569 [job-0] INFO  JobContainer - DataX Writer.Job [hdfswriter] do post work.
2021-03-29 18:18:40.570 [job-0] INFO  HdfsWriter$Job - start rename file [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_fault_tag_statistics__d25d4b9f_d8c2_4228_9104_b72ec3e4e5a7/andon_fault_tag_statistics__9d11b07c_99ad_4417_ba30_9c64719f4e2a.gz] to file [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_fault_tag_statistics/andon_fault_tag_statistics__9d11b07c_99ad_4417_ba30_9c64719f4e2a.gz].
2021-03-29 18:18:40.582 [job-0] INFO  HdfsWriter$Job - finish rename file [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_fault_tag_statistics__d25d4b9f_d8c2_4228_9104_b72ec3e4e5a7/andon_fault_tag_statistics__9d11b07c_99ad_4417_ba30_9c64719f4e2a.gz] to file [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_fault_tag_statistics/andon_fault_tag_statistics__9d11b07c_99ad_4417_ba30_9c64719f4e2a.gz].
2021-03-29 18:18:40.582 [job-0] INFO  HdfsWriter$Job - start delete tmp dir [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_fault_tag_statistics__d25d4b9f_d8c2_4228_9104_b72ec3e4e5a7] .
2021-03-29 18:18:40.593 [job-0] INFO  HdfsWriter$Job - finish delete tmp dir [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_fault_tag_statistics__d25d4b9f_d8c2_4228_9104_b72ec3e4e5a7] .
2021-03-29 18:18:40.593 [job-0] INFO  JobContainer - DataX Reader.Job [mysqlreader] do post work.
2021-03-29 18:18:40.594 [job-0] INFO  JobContainer - DataX jobId [0] completed successfully.
2021-03-29 18:18:40.595 [job-0] INFO  HookInvoker - No hook invoked, because base dir not exists or is a file: /software/datax/hook
2021-03-29 18:18:40.698 [job-0] INFO  JobContainer - 
	 [total cpu info] => 
		averageCpu                     | maxDeltaCpu                    | minDeltaCpu                    
		-1.00%                         | -1.00%                         | -1.00%
                        

	 [total gc info] => 
		 NAME                 | totalGCCount       | maxDeltaGCCount    | minDeltaGCCount    | totalGCTime        | maxDeltaGCTime     | minDeltaGCTime     
		 PS MarkSweep         | 1                  | 1                  | 1                  | 0.043s             | 0.043s             | 0.043s             
		 PS Scavenge          | 1                  | 1                  | 1                  | 0.030s             | 0.030s             | 0.030s             

2021-03-29 18:18:40.699 [job-0] INFO  JobContainer - PerfTrace not enable!
2021-03-29 18:18:40.700 [job-0] INFO  StandAloneJobContainerCommunicator - Total 87 records, 6304 bytes | Speed 630B/s, 8 records/s | Error 0 records, 0 bytes |  All Task WaitWriterTime 0.001s |  All Task WaitReaderTime 0.000s | Percentage 100.00%
2021-03-29 18:18:40.702 [job-0] INFO  JobContainer - 
任务启动时刻                    : 2021-03-29 18:18:27
任务结束时刻                    : 2021-03-29 18:18:40
任务总计耗时                    :                 12s
任务平均流量                    :              630B/s
记录写入速度                    :              8rec/s
读出记录总数                    :                  87
读写失败总数                    :                   0

andon_fault_tag_statistics表增量同步的结果为0
开始同步一张表
增量配置文件：/software/datax/sync/bin/../conf/jdbc:mysql:192.168.0.124:3306/ziyun-andon.increment
/software/datax/sync/bin/../conf/jdbc:mysql:192.168.0.124:3306/ziyun-andon.increment是文件，进入判断#
maybe_results：andon_fault_tag_statistics_copy1,update_dt
表名：andon_fault_tag_statistics_copy1
字段名：update_dt
开始增量同步表andon_fault_tag_statistics_copy1
query_sql_info: update_dt 2021-02-04 2021-02-06

DataX (DATAX-OPENSOURCE-3.0), From Alibaba !
Copyright (C) 2010-2017, Alibaba Group. All Rights Reserved.


2021-03-29 18:18:41.848 [main] INFO  VMInfo - VMInfo# operatingSystem class => sun.management.OperatingSystemImpl
2021-03-29 18:18:41.859 [main] INFO  Engine - the machine info  => 

	osInfo:	Oracle Corporation 1.8 25.201-b09
	jvmInfo:	Linux amd64 3.10.0-957.el7.x86_64
	cpu num:	16

	totalPhysicalMemory:	-0.00G
	freePhysicalMemory:	-0.00G
	maxFileDescriptorCount:	-1
	currentOpenFileDescriptorCount:	-1

	GC Names	[PS MarkSweep, PS Scavenge]

	MEMORY_NAME                    | allocation_size                | init_size                      
	PS Eden Space                  | 256.00MB                       | 256.00MB                       
	Code Cache                     | 240.00MB                       | 2.44MB                         
	Compressed Class Space         | 1,024.00MB                     | 0.00MB                         
	PS Survivor Space              | 42.50MB                        | 42.50MB                        
	PS Old Gen                     | 683.00MB                       | 683.00MB                       
	Metaspace                      | -0.00MB                        | 0.00MB                         


2021-03-29 18:18:41.893 [main] INFO  Engine - 
{
	"content":[
		{
			"reader":{
				"name":"mysqlreader",
				"parameter":{
					"column":[
						"`id`",
						"`statistics_date`",
						"`fault_tag_id`",
						"`statistics_count`",
						"`average_downtime_interval`",
						"`average_downtime_duration`",
						"`average_downtime_interval_value`",
						"`average_downtime_duration_value`",
						"`andon_tag_id`",
						"`org_hcode`",
						"`create_dt`",
						"`update_dt`",
						"`status`"
					],
					"connection":[
						{
							"jdbcUrl":[
								"jdbc:mysql://192.168.0.124:3306/ziyun-andon"
							],
							"table":[
								"andon_fault_tag_statistics_copy1"
							]
						}
					],
					"password":"********",
					"username":"ziyunIot",
					"where":"update_dt > '2021-02-04' and update_dt < '2021-02-06'"
				}
			},
			"writer":{
				"name":"hdfswriter",
				"parameter":{
					"column":[
						{
							"name":"`id`",
							"type":"BIGINT"
						},
						{
							"name":"`statistics_date`",
							"type":"STRING"
						},
						{
							"name":"`fault_tag_id`",
							"type":"BIGINT"
						},
						{
							"name":"`statistics_count`",
							"type":"BIGINT"
						},
						{
							"name":"`average_downtime_interval`",
							"type":"STRING"
						},
						{
							"name":"`average_downtime_duration`",
							"type":"STRING"
						},
						{
							"name":"`average_downtime_interval_value`",
							"type":"BIGINT"
						},
						{
							"name":"`average_downtime_duration_value`",
							"type":"BIGINT"
						},
						{
							"name":"`andon_tag_id`",
							"type":"BIGINT"
						},
						{
							"name":"`org_hcode`",
							"type":"STRING"
						},
						{
							"name":"`create_dt`",
							"type":"DATE"
						},
						{
							"name":"`update_dt`",
							"type":"DATE"
						},
						{
							"name":"`status`",
							"type":"STRING"
						}
					],
					"compress":"gzip",
					"defaultFS":"hdfs://nameservice1",
					"fieldDelimiter":"\t",
					"fileName":"andon_fault_tag_statistics_copy1",
					"fileType":"text",
					"hadoopConfig":{
						"dfs.client.failover.proxy.provider.nameservice1":"org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider",
						"dfs.ha.namenodes.nameservice1":"nn1,nn2",
						"dfs.namenode.rpc-address.nameservice1.nn1":"ziyunbd01:8020",
						"dfs.namenode.rpc-address.nameservice1.nn2":"ziyunbd02:8020",
						"dfs.nameservices":"nameservice1"
					},
					"path":"/user/hive/warehouse/mysql_ziyun_andon/andon_fault_tag_statistics_copy1",
					"writeMode":"append"
				}
			}
		}
	],
	"setting":{
		"speed":{
			"channel":"1"
		}
	}
}

2021-03-29 18:18:41.922 [main] WARN  Engine - prioriy set to 0, because NumberFormatException, the value is: null
2021-03-29 18:18:41.925 [main] INFO  PerfTrace - PerfTrace traceId=job_-1, isEnable=false, priority=0
2021-03-29 18:18:41.925 [main] INFO  JobContainer - DataX jobContainer starts job.
2021-03-29 18:18:41.927 [main] INFO  JobContainer - Set jobId = 0
2021-03-29 18:18:42.469 [job-0] INFO  OriginalConfPretreatmentUtil - Available jdbcUrl:jdbc:mysql://192.168.0.124:3306/ziyun-andon?yearIsDateType=false&zeroDateTimeBehavior=convertToNull&tinyInt1isBit=false&rewriteBatchedStatements=true.
2021-03-29 18:18:42.505 [job-0] INFO  OriginalConfPretreatmentUtil - table:[andon_fault_tag_statistics_copy1] has columns:[id,statistics_date,fault_tag_id,statistics_count,average_downtime_interval,average_downtime_duration,average_downtime_interval_value,average_downtime_duration_value,andon_tag_id,org_hcode,create_dt,update_dt,status].
Mar 29, 2021 6:18:43 PM org.apache.hadoop.util.NativeCodeLoader <clinit>
WARNING: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-03-29 18:18:44.431 [job-0] INFO  JobContainer - jobContainer starts to do prepare ...
2021-03-29 18:18:44.433 [job-0] INFO  JobContainer - DataX Reader.Job [mysqlreader] do prepare work .
2021-03-29 18:18:44.434 [job-0] INFO  JobContainer - DataX Writer.Job [hdfswriter] do prepare work .
2021-03-29 18:18:44.615 [job-0] INFO  HdfsWriter$Job - 由于您配置了writeMode append, 写入前不做清理工作, [/user/hive/warehouse/mysql_ziyun_andon/andon_fault_tag_statistics_copy1] 目录下写入相应文件名前缀  [andon_fault_tag_statistics_copy1] 的文件
2021-03-29 18:18:44.616 [job-0] INFO  JobContainer - jobContainer starts to do split ...
2021-03-29 18:18:44.616 [job-0] INFO  JobContainer - Job set Channel-Number to 1 channels.
2021-03-29 18:18:44.624 [job-0] INFO  JobContainer - DataX Reader.Job [mysqlreader] splits to [1] tasks.
2021-03-29 18:18:44.625 [job-0] INFO  HdfsWriter$Job - begin do split...
2021-03-29 18:18:44.632 [job-0] INFO  HdfsWriter$Job - splited write file name:[hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_fault_tag_statistics_copy1__d7f168b1_ffef_460e_a790_caf7c92ee463/andon_fault_tag_statistics_copy1__f572e344_beb7_49d2_8884_1474496101a3]
2021-03-29 18:18:44.633 [job-0] INFO  HdfsWriter$Job - end do split.
2021-03-29 18:18:44.633 [job-0] INFO  JobContainer - DataX Writer.Job [hdfswriter] splits to [1] tasks.
2021-03-29 18:18:44.668 [job-0] INFO  JobContainer - jobContainer starts to do schedule ...
2021-03-29 18:18:44.674 [job-0] INFO  JobContainer - Scheduler starts [1] taskGroups.
2021-03-29 18:18:44.678 [job-0] INFO  JobContainer - Running by standalone Mode.
2021-03-29 18:18:44.688 [taskGroup-0] INFO  TaskGroupContainer - taskGroupId=[0] start [1] channels for [1] tasks.
2021-03-29 18:18:44.694 [taskGroup-0] INFO  Channel - Channel set byte_speed_limit to -1, No bps activated.
2021-03-29 18:18:44.694 [taskGroup-0] INFO  Channel - Channel set record_speed_limit to -1, No tps activated.
2021-03-29 18:18:44.705 [taskGroup-0] INFO  TaskGroupContainer - taskGroup[0] taskId[0] attemptCount[1] is started
2021-03-29 18:18:44.712 [0-0-0-reader] INFO  CommonRdbmsReader$Task - Begin to read record by Sql: [select `id`,`statistics_date`,`fault_tag_id`,`statistics_count`,`average_downtime_interval`,`average_downtime_duration`,`average_downtime_interval_value`,`average_downtime_duration_value`,`andon_tag_id`,`org_hcode`,`create_dt`,`update_dt`,`status` from andon_fault_tag_statistics_copy1 where (update_dt > '2021-02-04' and update_dt < '2021-02-06')
] jdbcUrl:[jdbc:mysql://192.168.0.124:3306/ziyun-andon?yearIsDateType=false&zeroDateTimeBehavior=convertToNull&tinyInt1isBit=false&rewriteBatchedStatements=true].
2021-03-29 18:18:44.763 [0-0-0-writer] INFO  HdfsWriter$Task - begin do write...
2021-03-29 18:18:44.764 [0-0-0-writer] INFO  HdfsWriter$Task - write to file : [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_fault_tag_statistics_copy1__d7f168b1_ffef_460e_a790_caf7c92ee463/andon_fault_tag_statistics_copy1__f572e344_beb7_49d2_8884_1474496101a3]
2021-03-29 18:18:44.771 [0-0-0-reader] INFO  CommonRdbmsReader$Task - Finished read record by Sql: [select `id`,`statistics_date`,`fault_tag_id`,`statistics_count`,`average_downtime_interval`,`average_downtime_duration`,`average_downtime_interval_value`,`average_downtime_duration_value`,`andon_tag_id`,`org_hcode`,`create_dt`,`update_dt`,`status` from andon_fault_tag_statistics_copy1 where (update_dt > '2021-02-04' and update_dt < '2021-02-06')
] jdbcUrl:[jdbc:mysql://192.168.0.124:3306/ziyun-andon?yearIsDateType=false&zeroDateTimeBehavior=convertToNull&tinyInt1isBit=false&rewriteBatchedStatements=true].
2021-03-29 18:18:45.186 [0-0-0-writer] INFO  HdfsWriter$Task - end do write
2021-03-29 18:18:45.206 [taskGroup-0] INFO  TaskGroupContainer - taskGroup[0] taskId[0] is successed, used[503]ms
2021-03-29 18:18:45.207 [taskGroup-0] INFO  TaskGroupContainer - taskGroup[0] completed it's tasks.
2021-03-29 18:18:54.710 [job-0] INFO  StandAloneJobContainerCommunicator - Total 92 records, 3737 bytes | Speed 373B/s, 9 records/s | Error 0 records, 0 bytes |  All Task WaitWriterTime 0.001s |  All Task WaitReaderTime 0.000s | Percentage 100.00%
2021-03-29 18:18:54.711 [job-0] INFO  AbstractScheduler - Scheduler accomplished all tasks.
2021-03-29 18:18:54.711 [job-0] INFO  JobContainer - DataX Writer.Job [hdfswriter] do post work.
2021-03-29 18:18:54.712 [job-0] INFO  HdfsWriter$Job - start rename file [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_fault_tag_statistics_copy1__d7f168b1_ffef_460e_a790_caf7c92ee463/andon_fault_tag_statistics_copy1__f572e344_beb7_49d2_8884_1474496101a3.gz] to file [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_fault_tag_statistics_copy1/andon_fault_tag_statistics_copy1__f572e344_beb7_49d2_8884_1474496101a3.gz].
2021-03-29 18:18:54.724 [job-0] INFO  HdfsWriter$Job - finish rename file [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_fault_tag_statistics_copy1__d7f168b1_ffef_460e_a790_caf7c92ee463/andon_fault_tag_statistics_copy1__f572e344_beb7_49d2_8884_1474496101a3.gz] to file [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_fault_tag_statistics_copy1/andon_fault_tag_statistics_copy1__f572e344_beb7_49d2_8884_1474496101a3.gz].
2021-03-29 18:18:54.725 [job-0] INFO  HdfsWriter$Job - start delete tmp dir [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_fault_tag_statistics_copy1__d7f168b1_ffef_460e_a790_caf7c92ee463] .
2021-03-29 18:18:54.737 [job-0] INFO  HdfsWriter$Job - finish delete tmp dir [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_fault_tag_statistics_copy1__d7f168b1_ffef_460e_a790_caf7c92ee463] .
2021-03-29 18:18:54.738 [job-0] INFO  JobContainer - DataX Reader.Job [mysqlreader] do post work.
2021-03-29 18:18:54.738 [job-0] INFO  JobContainer - DataX jobId [0] completed successfully.
2021-03-29 18:18:54.739 [job-0] INFO  HookInvoker - No hook invoked, because base dir not exists or is a file: /software/datax/hook
2021-03-29 18:18:54.842 [job-0] INFO  JobContainer - 
	 [total cpu info] => 
		averageCpu                     | maxDeltaCpu                    | minDeltaCpu                    
		-1.00%                         | -1.00%                         | -1.00%
                        

	 [total gc info] => 
		 NAME                 | totalGCCount       | maxDeltaGCCount    | minDeltaGCCount    | totalGCTime        | maxDeltaGCTime     | minDeltaGCTime     
		 PS MarkSweep         | 1                  | 1                  | 1                  | 0.064s             | 0.064s             | 0.064s             
		 PS Scavenge          | 1                  | 1                  | 1                  | 0.034s             | 0.034s             | 0.034s             

2021-03-29 18:18:54.843 [job-0] INFO  JobContainer - PerfTrace not enable!
2021-03-29 18:18:54.844 [job-0] INFO  StandAloneJobContainerCommunicator - Total 92 records, 3737 bytes | Speed 373B/s, 9 records/s | Error 0 records, 0 bytes |  All Task WaitWriterTime 0.001s |  All Task WaitReaderTime 0.000s | Percentage 100.00%
2021-03-29 18:18:54.845 [job-0] INFO  JobContainer - 
任务启动时刻                    : 2021-03-29 18:18:41
任务结束时刻                    : 2021-03-29 18:18:54
任务总计耗时                    :                 12s
任务平均流量                    :              373B/s
记录写入速度                    :              9rec/s
读出记录总数                    :                  92
读写失败总数                    :                   0

andon_fault_tag_statistics_copy1表增量同步的结果为0
开始同步一张表
增量配置文件：/software/datax/sync/bin/../conf/jdbc:mysql:192.168.0.124:3306/ziyun-andon.increment
/software/datax/sync/bin/../conf/jdbc:mysql:192.168.0.124:3306/ziyun-andon.increment是文件，进入判断#
maybe_results：
开始全量同步表andon_fault_type

DataX (DATAX-OPENSOURCE-3.0), From Alibaba !
Copyright (C) 2010-2017, Alibaba Group. All Rights Reserved.


2021-03-29 18:18:55.864 [main] INFO  VMInfo - VMInfo# operatingSystem class => sun.management.OperatingSystemImpl
2021-03-29 18:18:55.878 [main] INFO  Engine - the machine info  => 

	osInfo:	Oracle Corporation 1.8 25.201-b09
	jvmInfo:	Linux amd64 3.10.0-957.el7.x86_64
	cpu num:	16

	totalPhysicalMemory:	-0.00G
	freePhysicalMemory:	-0.00G
	maxFileDescriptorCount:	-1
	currentOpenFileDescriptorCount:	-1

	GC Names	[PS MarkSweep, PS Scavenge]

	MEMORY_NAME                    | allocation_size                | init_size                      
	PS Eden Space                  | 256.00MB                       | 256.00MB                       
	Code Cache                     | 240.00MB                       | 2.44MB                         
	Compressed Class Space         | 1,024.00MB                     | 0.00MB                         
	PS Survivor Space              | 42.50MB                        | 42.50MB                        
	PS Old Gen                     | 683.00MB                       | 683.00MB                       
	Metaspace                      | -0.00MB                        | 0.00MB                         


2021-03-29 18:18:55.921 [main] INFO  Engine - 
{
	"content":[
		{
			"reader":{
				"name":"mysqlreader",
				"parameter":{
					"column":[
						"`id`",
						"`fault_name`",
						"`fault_tag_id`",
						"`fault_org_id`",
						"`domain_id`",
						"`tombstone`",
						"`create_dt`",
						"`update_dt`"
					],
					"connection":[
						{
							"jdbcUrl":[
								"jdbc:mysql://192.168.0.124:3306/ziyun-andon"
							],
							"table":[
								"andon_fault_type"
							]
						}
					],
					"password":"********",
					"username":"ziyunIot",
					"where":"1=1"
				}
			},
			"writer":{
				"name":"hdfswriter",
				"parameter":{
					"column":[
						{
							"name":"`id`",
							"type":"BIGINT"
						},
						{
							"name":"`fault_name`",
							"type":"STRING"
						},
						{
							"name":"`fault_tag_id`",
							"type":"BIGINT"
						},
						{
							"name":"`fault_org_id`",
							"type":"BIGINT"
						},
						{
							"name":"`domain_id`",
							"type":"STRING"
						},
						{
							"name":"`tombstone`",
							"type":"STRING"
						},
						{
							"name":"`create_dt`",
							"type":"DATE"
						},
						{
							"name":"`update_dt`",
							"type":"DATE"
						}
					],
					"compress":"gzip",
					"defaultFS":"hdfs://nameservice1",
					"fieldDelimiter":"\t",
					"fileName":"andon_fault_type",
					"fileType":"text",
					"hadoopConfig":{
						"dfs.client.failover.proxy.provider.nameservice1":"org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider",
						"dfs.ha.namenodes.nameservice1":"nn1,nn2",
						"dfs.namenode.rpc-address.nameservice1.nn1":"ziyunbd01:8020",
						"dfs.namenode.rpc-address.nameservice1.nn2":"ziyunbd02:8020",
						"dfs.nameservices":"nameservice1"
					},
					"path":"/user/hive/warehouse/mysql_ziyun_andon/andon_fault_type",
					"writeMode":"append"
				}
			}
		}
	],
	"setting":{
		"speed":{
			"channel":"3"
		}
	}
}

2021-03-29 18:18:55.956 [main] WARN  Engine - prioriy set to 0, because NumberFormatException, the value is: null
2021-03-29 18:18:55.960 [main] INFO  PerfTrace - PerfTrace traceId=job_-1, isEnable=false, priority=0
2021-03-29 18:18:55.960 [main] INFO  JobContainer - DataX jobContainer starts job.
2021-03-29 18:18:55.963 [main] INFO  JobContainer - Set jobId = 0
2021-03-29 18:18:56.626 [job-0] INFO  OriginalConfPretreatmentUtil - Available jdbcUrl:jdbc:mysql://192.168.0.124:3306/ziyun-andon?yearIsDateType=false&zeroDateTimeBehavior=convertToNull&tinyInt1isBit=false&rewriteBatchedStatements=true.
2021-03-29 18:18:56.659 [job-0] INFO  OriginalConfPretreatmentUtil - table:[andon_fault_type] has columns:[id,fault_name,fault_tag_id,fault_org_id,domain_id,tombstone,create_dt,update_dt].
Mar 29, 2021 6:18:57 PM org.apache.hadoop.util.NativeCodeLoader <clinit>
WARNING: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-03-29 18:18:58.879 [job-0] INFO  JobContainer - jobContainer starts to do prepare ...
2021-03-29 18:18:58.880 [job-0] INFO  JobContainer - DataX Reader.Job [mysqlreader] do prepare work .
2021-03-29 18:18:58.881 [job-0] INFO  JobContainer - DataX Writer.Job [hdfswriter] do prepare work .
2021-03-29 18:18:59.078 [job-0] INFO  HdfsWriter$Job - 由于您配置了writeMode append, 写入前不做清理工作, [/user/hive/warehouse/mysql_ziyun_andon/andon_fault_type] 目录下写入相应文件名前缀  [andon_fault_type] 的文件
2021-03-29 18:18:59.078 [job-0] INFO  JobContainer - jobContainer starts to do split ...
2021-03-29 18:18:59.079 [job-0] INFO  JobContainer - Job set Channel-Number to 3 channels.
2021-03-29 18:18:59.088 [job-0] INFO  JobContainer - DataX Reader.Job [mysqlreader] splits to [1] tasks.
2021-03-29 18:18:59.089 [job-0] INFO  HdfsWriter$Job - begin do split...
2021-03-29 18:18:59.096 [job-0] INFO  HdfsWriter$Job - splited write file name:[hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_fault_type__efef0abf_2fd7_452e_9e23_ee3f73081c9a/andon_fault_type__da421f5b_f361_4186_89ec_c1db420dfdfe]
2021-03-29 18:18:59.097 [job-0] INFO  HdfsWriter$Job - end do split.
2021-03-29 18:18:59.098 [job-0] INFO  JobContainer - DataX Writer.Job [hdfswriter] splits to [1] tasks.
2021-03-29 18:18:59.135 [job-0] INFO  JobContainer - jobContainer starts to do schedule ...
2021-03-29 18:18:59.143 [job-0] INFO  JobContainer - Scheduler starts [1] taskGroups.
2021-03-29 18:18:59.148 [job-0] INFO  JobContainer - Running by standalone Mode.
2021-03-29 18:18:59.163 [taskGroup-0] INFO  TaskGroupContainer - taskGroupId=[0] start [1] channels for [1] tasks.
2021-03-29 18:18:59.171 [taskGroup-0] INFO  Channel - Channel set byte_speed_limit to -1, No bps activated.
2021-03-29 18:18:59.171 [taskGroup-0] INFO  Channel - Channel set record_speed_limit to -1, No tps activated.
2021-03-29 18:18:59.192 [taskGroup-0] INFO  TaskGroupContainer - taskGroup[0] taskId[0] attemptCount[1] is started
2021-03-29 18:18:59.200 [0-0-0-reader] INFO  CommonRdbmsReader$Task - Begin to read record by Sql: [select `id`,`fault_name`,`fault_tag_id`,`fault_org_id`,`domain_id`,`tombstone`,`create_dt`,`update_dt` from andon_fault_type where (1=1)
] jdbcUrl:[jdbc:mysql://192.168.0.124:3306/ziyun-andon?yearIsDateType=false&zeroDateTimeBehavior=convertToNull&tinyInt1isBit=false&rewriteBatchedStatements=true].
2021-03-29 18:18:59.254 [0-0-0-writer] INFO  HdfsWriter$Task - begin do write...
2021-03-29 18:18:59.255 [0-0-0-writer] INFO  HdfsWriter$Task - write to file : [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_fault_type__efef0abf_2fd7_452e_9e23_ee3f73081c9a/andon_fault_type__da421f5b_f361_4186_89ec_c1db420dfdfe]
2021-03-29 18:18:59.272 [0-0-0-reader] INFO  CommonRdbmsReader$Task - Finished read record by Sql: [select `id`,`fault_name`,`fault_tag_id`,`fault_org_id`,`domain_id`,`tombstone`,`create_dt`,`update_dt` from andon_fault_type where (1=1)
] jdbcUrl:[jdbc:mysql://192.168.0.124:3306/ziyun-andon?yearIsDateType=false&zeroDateTimeBehavior=convertToNull&tinyInt1isBit=false&rewriteBatchedStatements=true].
2021-03-29 18:18:59.690 [0-0-0-writer] INFO  HdfsWriter$Task - end do write
2021-03-29 18:18:59.695 [taskGroup-0] INFO  TaskGroupContainer - taskGroup[0] taskId[0] is successed, used[505]ms
2021-03-29 18:18:59.696 [taskGroup-0] INFO  TaskGroupContainer - taskGroup[0] completed it's tasks.
2021-03-29 18:19:09.188 [job-0] INFO  StandAloneJobContainerCommunicator - Total 106 records, 6857 bytes | Speed 685B/s, 10 records/s | Error 0 records, 0 bytes |  All Task WaitWriterTime 0.001s |  All Task WaitReaderTime 0.000s | Percentage 100.00%
2021-03-29 18:19:09.188 [job-0] INFO  AbstractScheduler - Scheduler accomplished all tasks.
2021-03-29 18:19:09.189 [job-0] INFO  JobContainer - DataX Writer.Job [hdfswriter] do post work.
2021-03-29 18:19:09.190 [job-0] INFO  HdfsWriter$Job - start rename file [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_fault_type__efef0abf_2fd7_452e_9e23_ee3f73081c9a/andon_fault_type__da421f5b_f361_4186_89ec_c1db420dfdfe.gz] to file [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_fault_type/andon_fault_type__da421f5b_f361_4186_89ec_c1db420dfdfe.gz].
2021-03-29 18:19:09.205 [job-0] INFO  HdfsWriter$Job - finish rename file [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_fault_type__efef0abf_2fd7_452e_9e23_ee3f73081c9a/andon_fault_type__da421f5b_f361_4186_89ec_c1db420dfdfe.gz] to file [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_fault_type/andon_fault_type__da421f5b_f361_4186_89ec_c1db420dfdfe.gz].
2021-03-29 18:19:09.206 [job-0] INFO  HdfsWriter$Job - start delete tmp dir [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_fault_type__efef0abf_2fd7_452e_9e23_ee3f73081c9a] .
2021-03-29 18:19:09.219 [job-0] INFO  HdfsWriter$Job - finish delete tmp dir [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_fault_type__efef0abf_2fd7_452e_9e23_ee3f73081c9a] .
2021-03-29 18:19:09.220 [job-0] INFO  JobContainer - DataX Reader.Job [mysqlreader] do post work.
2021-03-29 18:19:09.221 [job-0] INFO  JobContainer - DataX jobId [0] completed successfully.
2021-03-29 18:19:09.222 [job-0] INFO  HookInvoker - No hook invoked, because base dir not exists or is a file: /software/datax/hook
2021-03-29 18:19:09.327 [job-0] INFO  JobContainer - 
	 [total cpu info] => 
		averageCpu                     | maxDeltaCpu                    | minDeltaCpu                    
		-1.00%                         | -1.00%                         | -1.00%
                        

	 [total gc info] => 
		 NAME                 | totalGCCount       | maxDeltaGCCount    | minDeltaGCCount    | totalGCTime        | maxDeltaGCTime     | minDeltaGCTime     
		 PS MarkSweep         | 1                  | 1                  | 1                  | 0.065s             | 0.065s             | 0.065s             
		 PS Scavenge          | 1                  | 1                  | 1                  | 0.042s             | 0.042s             | 0.042s             

2021-03-29 18:19:09.327 [job-0] INFO  JobContainer - PerfTrace not enable!
2021-03-29 18:19:09.328 [job-0] INFO  StandAloneJobContainerCommunicator - Total 106 records, 6857 bytes | Speed 685B/s, 10 records/s | Error 0 records, 0 bytes |  All Task WaitWriterTime 0.001s |  All Task WaitReaderTime 0.000s | Percentage 100.00%
2021-03-29 18:19:09.331 [job-0] INFO  JobContainer - 
任务启动时刻                    : 2021-03-29 18:18:55
任务结束时刻                    : 2021-03-29 18:19:09
任务总计耗时                    :                 13s
任务平均流量                    :              685B/s
记录写入速度                    :             10rec/s
读出记录总数                    :                 106
读写失败总数                    :                   0

andon_fault_type表全量同步的结果为0
开始同步一张表
增量配置文件：/software/datax/sync/bin/../conf/jdbc:mysql:192.168.0.124:3306/ziyun-andon.increment
/software/datax/sync/bin/../conf/jdbc:mysql:192.168.0.124:3306/ziyun-andon.increment是文件，进入判断#
maybe_results：
开始全量同步表andon_fault_type_copy1

DataX (DATAX-OPENSOURCE-3.0), From Alibaba !
Copyright (C) 2010-2017, Alibaba Group. All Rights Reserved.


2021-03-29 18:19:10.582 [main] INFO  VMInfo - VMInfo# operatingSystem class => sun.management.OperatingSystemImpl
2021-03-29 18:19:10.599 [main] INFO  Engine - the machine info  => 

	osInfo:	Oracle Corporation 1.8 25.201-b09
	jvmInfo:	Linux amd64 3.10.0-957.el7.x86_64
	cpu num:	16

	totalPhysicalMemory:	-0.00G
	freePhysicalMemory:	-0.00G
	maxFileDescriptorCount:	-1
	currentOpenFileDescriptorCount:	-1

	GC Names	[PS MarkSweep, PS Scavenge]

	MEMORY_NAME                    | allocation_size                | init_size                      
	PS Eden Space                  | 256.00MB                       | 256.00MB                       
	Code Cache                     | 240.00MB                       | 2.44MB                         
	Compressed Class Space         | 1,024.00MB                     | 0.00MB                         
	PS Survivor Space              | 42.50MB                        | 42.50MB                        
	PS Old Gen                     | 683.00MB                       | 683.00MB                       
	Metaspace                      | -0.00MB                        | 0.00MB                         


2021-03-29 18:19:10.648 [main] INFO  Engine - 
{
	"content":[
		{
			"reader":{
				"name":"mysqlreader",
				"parameter":{
					"column":[
						"`id`",
						"`fault_name`",
						"`fault_tag_id`",
						"`fault_org_hcode`",
						"`tombstone`",
						"`create_dt`",
						"`update_dt`"
					],
					"connection":[
						{
							"jdbcUrl":[
								"jdbc:mysql://192.168.0.124:3306/ziyun-andon"
							],
							"table":[
								"andon_fault_type_copy1"
							]
						}
					],
					"password":"********",
					"username":"ziyunIot",
					"where":"1=1"
				}
			},
			"writer":{
				"name":"hdfswriter",
				"parameter":{
					"column":[
						{
							"name":"`id`",
							"type":"BIGINT"
						},
						{
							"name":"`fault_name`",
							"type":"STRING"
						},
						{
							"name":"`fault_tag_id`",
							"type":"BIGINT"
						},
						{
							"name":"`fault_org_hcode`",
							"type":"STRING"
						},
						{
							"name":"`tombstone`",
							"type":"STRING"
						},
						{
							"name":"`create_dt`",
							"type":"DATE"
						},
						{
							"name":"`update_dt`",
							"type":"DATE"
						}
					],
					"compress":"gzip",
					"defaultFS":"hdfs://nameservice1",
					"fieldDelimiter":"\t",
					"fileName":"andon_fault_type_copy1",
					"fileType":"text",
					"hadoopConfig":{
						"dfs.client.failover.proxy.provider.nameservice1":"org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider",
						"dfs.ha.namenodes.nameservice1":"nn1,nn2",
						"dfs.namenode.rpc-address.nameservice1.nn1":"ziyunbd01:8020",
						"dfs.namenode.rpc-address.nameservice1.nn2":"ziyunbd02:8020",
						"dfs.nameservices":"nameservice1"
					},
					"path":"/user/hive/warehouse/mysql_ziyun_andon/andon_fault_type_copy1",
					"writeMode":"append"
				}
			}
		}
	],
	"setting":{
		"speed":{
			"channel":"3"
		}
	}
}

2021-03-29 18:19:10.690 [main] WARN  Engine - prioriy set to 0, because NumberFormatException, the value is: null
2021-03-29 18:19:10.694 [main] INFO  PerfTrace - PerfTrace traceId=job_-1, isEnable=false, priority=0
2021-03-29 18:19:10.695 [main] INFO  JobContainer - DataX jobContainer starts job.
2021-03-29 18:19:10.700 [main] INFO  JobContainer - Set jobId = 0
2021-03-29 18:19:11.412 [job-0] INFO  OriginalConfPretreatmentUtil - Available jdbcUrl:jdbc:mysql://192.168.0.124:3306/ziyun-andon?yearIsDateType=false&zeroDateTimeBehavior=convertToNull&tinyInt1isBit=false&rewriteBatchedStatements=true.
2021-03-29 18:19:11.441 [job-0] INFO  OriginalConfPretreatmentUtil - table:[andon_fault_type_copy1] has columns:[id,fault_name,fault_tag_id,fault_org_hcode,tombstone,create_dt,update_dt].
Mar 29, 2021 6:19:12 PM org.apache.hadoop.util.NativeCodeLoader <clinit>
WARNING: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-03-29 18:19:13.622 [job-0] INFO  JobContainer - jobContainer starts to do prepare ...
2021-03-29 18:19:13.623 [job-0] INFO  JobContainer - DataX Reader.Job [mysqlreader] do prepare work .
2021-03-29 18:19:13.624 [job-0] INFO  JobContainer - DataX Writer.Job [hdfswriter] do prepare work .
2021-03-29 18:19:13.808 [job-0] INFO  HdfsWriter$Job - 由于您配置了writeMode append, 写入前不做清理工作, [/user/hive/warehouse/mysql_ziyun_andon/andon_fault_type_copy1] 目录下写入相应文件名前缀  [andon_fault_type_copy1] 的文件
2021-03-29 18:19:13.809 [job-0] INFO  JobContainer - jobContainer starts to do split ...
2021-03-29 18:19:13.811 [job-0] INFO  JobContainer - Job set Channel-Number to 3 channels.
2021-03-29 18:19:13.819 [job-0] INFO  JobContainer - DataX Reader.Job [mysqlreader] splits to [1] tasks.
2021-03-29 18:19:13.819 [job-0] INFO  HdfsWriter$Job - begin do split...
2021-03-29 18:19:13.826 [job-0] INFO  HdfsWriter$Job - splited write file name:[hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_fault_type_copy1__2203be58_361a_4637_9ae0_c296c93e5be8/andon_fault_type_copy1__ba4789ae_8a4a_4468_9b65_624a30e16f07]
2021-03-29 18:19:13.826 [job-0] INFO  HdfsWriter$Job - end do split.
2021-03-29 18:19:13.827 [job-0] INFO  JobContainer - DataX Writer.Job [hdfswriter] splits to [1] tasks.
2021-03-29 18:19:13.863 [job-0] INFO  JobContainer - jobContainer starts to do schedule ...
2021-03-29 18:19:13.871 [job-0] INFO  JobContainer - Scheduler starts [1] taskGroups.
2021-03-29 18:19:13.875 [job-0] INFO  JobContainer - Running by standalone Mode.
2021-03-29 18:19:13.888 [taskGroup-0] INFO  TaskGroupContainer - taskGroupId=[0] start [1] channels for [1] tasks.
2021-03-29 18:19:13.896 [taskGroup-0] INFO  Channel - Channel set byte_speed_limit to -1, No bps activated.
2021-03-29 18:19:13.896 [taskGroup-0] INFO  Channel - Channel set record_speed_limit to -1, No tps activated.
2021-03-29 18:19:13.918 [taskGroup-0] INFO  TaskGroupContainer - taskGroup[0] taskId[0] attemptCount[1] is started
2021-03-29 18:19:13.925 [0-0-0-reader] INFO  CommonRdbmsReader$Task - Begin to read record by Sql: [select `id`,`fault_name`,`fault_tag_id`,`fault_org_hcode`,`tombstone`,`create_dt`,`update_dt` from andon_fault_type_copy1 where (1=1)
] jdbcUrl:[jdbc:mysql://192.168.0.124:3306/ziyun-andon?yearIsDateType=false&zeroDateTimeBehavior=convertToNull&tinyInt1isBit=false&rewriteBatchedStatements=true].
2021-03-29 18:19:13.974 [0-0-0-writer] INFO  HdfsWriter$Task - begin do write...
2021-03-29 18:19:13.974 [0-0-0-writer] INFO  HdfsWriter$Task - write to file : [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_fault_type_copy1__2203be58_361a_4637_9ae0_c296c93e5be8/andon_fault_type_copy1__ba4789ae_8a4a_4468_9b65_624a30e16f07]
2021-03-29 18:19:13.993 [0-0-0-reader] INFO  CommonRdbmsReader$Task - Finished read record by Sql: [select `id`,`fault_name`,`fault_tag_id`,`fault_org_hcode`,`tombstone`,`create_dt`,`update_dt` from andon_fault_type_copy1 where (1=1)
] jdbcUrl:[jdbc:mysql://192.168.0.124:3306/ziyun-andon?yearIsDateType=false&zeroDateTimeBehavior=convertToNull&tinyInt1isBit=false&rewriteBatchedStatements=true].
2021-03-29 18:19:14.396 [0-0-0-writer] INFO  HdfsWriter$Task - end do write
2021-03-29 18:19:14.420 [taskGroup-0] INFO  TaskGroupContainer - taskGroup[0] taskId[0] is successed, used[505]ms
2021-03-29 18:19:14.421 [taskGroup-0] INFO  TaskGroupContainer - taskGroup[0] completed it's tasks.
2021-03-29 18:19:23.910 [job-0] INFO  StandAloneJobContainerCommunicator - Total 97 records, 2830 bytes | Speed 283B/s, 9 records/s | Error 0 records, 0 bytes |  All Task WaitWriterTime 0.000s |  All Task WaitReaderTime 0.000s | Percentage 100.00%
2021-03-29 18:19:23.911 [job-0] INFO  AbstractScheduler - Scheduler accomplished all tasks.
2021-03-29 18:19:23.912 [job-0] INFO  JobContainer - DataX Writer.Job [hdfswriter] do post work.
2021-03-29 18:19:23.912 [job-0] INFO  HdfsWriter$Job - start rename file [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_fault_type_copy1__2203be58_361a_4637_9ae0_c296c93e5be8/andon_fault_type_copy1__ba4789ae_8a4a_4468_9b65_624a30e16f07.gz] to file [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_fault_type_copy1/andon_fault_type_copy1__ba4789ae_8a4a_4468_9b65_624a30e16f07.gz].
2021-03-29 18:19:23.926 [job-0] INFO  HdfsWriter$Job - finish rename file [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_fault_type_copy1__2203be58_361a_4637_9ae0_c296c93e5be8/andon_fault_type_copy1__ba4789ae_8a4a_4468_9b65_624a30e16f07.gz] to file [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_fault_type_copy1/andon_fault_type_copy1__ba4789ae_8a4a_4468_9b65_624a30e16f07.gz].
2021-03-29 18:19:23.926 [job-0] INFO  HdfsWriter$Job - start delete tmp dir [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_fault_type_copy1__2203be58_361a_4637_9ae0_c296c93e5be8] .
2021-03-29 18:19:23.937 [job-0] INFO  HdfsWriter$Job - finish delete tmp dir [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_fault_type_copy1__2203be58_361a_4637_9ae0_c296c93e5be8] .
2021-03-29 18:19:23.938 [job-0] INFO  JobContainer - DataX Reader.Job [mysqlreader] do post work.
2021-03-29 18:19:23.938 [job-0] INFO  JobContainer - DataX jobId [0] completed successfully.
2021-03-29 18:19:23.940 [job-0] INFO  HookInvoker - No hook invoked, because base dir not exists or is a file: /software/datax/hook
2021-03-29 18:19:24.044 [job-0] INFO  JobContainer - 
	 [total cpu info] => 
		averageCpu                     | maxDeltaCpu                    | minDeltaCpu                    
		-1.00%                         | -1.00%                         | -1.00%
                        

	 [total gc info] => 
		 NAME                 | totalGCCount       | maxDeltaGCCount    | minDeltaGCCount    | totalGCTime        | maxDeltaGCTime     | minDeltaGCTime     
		 PS MarkSweep         | 1                  | 1                  | 1                  | 0.059s             | 0.059s             | 0.059s             
		 PS Scavenge          | 1                  | 1                  | 1                  | 0.043s             | 0.043s             | 0.043s             

2021-03-29 18:19:24.044 [job-0] INFO  JobContainer - PerfTrace not enable!
2021-03-29 18:19:24.045 [job-0] INFO  StandAloneJobContainerCommunicator - Total 97 records, 2830 bytes | Speed 283B/s, 9 records/s | Error 0 records, 0 bytes |  All Task WaitWriterTime 0.000s |  All Task WaitReaderTime 0.000s | Percentage 100.00%
2021-03-29 18:19:24.047 [job-0] INFO  JobContainer - 
任务启动时刻                    : 2021-03-29 18:19:10
任务结束时刻                    : 2021-03-29 18:19:24
任务总计耗时                    :                 13s
任务平均流量                    :              283B/s
记录写入速度                    :              9rec/s
读出记录总数                    :                  97
读写失败总数                    :                   0

andon_fault_type_copy1表全量同步的结果为0
开始同步一张表
增量配置文件：/software/datax/sync/bin/../conf/jdbc:mysql:192.168.0.124:3306/ziyun-andon.increment
/software/datax/sync/bin/../conf/jdbc:mysql:192.168.0.124:3306/ziyun-andon.increment是文件，进入判断#
maybe_results：
开始全量同步表andon_follow_record

DataX (DATAX-OPENSOURCE-3.0), From Alibaba !
Copyright (C) 2010-2017, Alibaba Group. All Rights Reserved.


2021-03-29 18:19:25.172 [main] INFO  VMInfo - VMInfo# operatingSystem class => sun.management.OperatingSystemImpl
2021-03-29 18:19:25.187 [main] INFO  Engine - the machine info  => 

	osInfo:	Oracle Corporation 1.8 25.201-b09
	jvmInfo:	Linux amd64 3.10.0-957.el7.x86_64
	cpu num:	16

	totalPhysicalMemory:	-0.00G
	freePhysicalMemory:	-0.00G
	maxFileDescriptorCount:	-1
	currentOpenFileDescriptorCount:	-1

	GC Names	[PS MarkSweep, PS Scavenge]

	MEMORY_NAME                    | allocation_size                | init_size                      
	PS Eden Space                  | 256.00MB                       | 256.00MB                       
	Code Cache                     | 240.00MB                       | 2.44MB                         
	Compressed Class Space         | 1,024.00MB                     | 0.00MB                         
	PS Survivor Space              | 42.50MB                        | 42.50MB                        
	PS Old Gen                     | 683.00MB                       | 683.00MB                       
	Metaspace                      | -0.00MB                        | 0.00MB                         


2021-03-29 18:19:25.232 [main] INFO  Engine - 
{
	"content":[
		{
			"reader":{
				"name":"mysqlreader",
				"parameter":{
					"column":[
						"`id`",
						"`andon_deviceid`",
						"`device_name`",
						"`device_type`",
						"`call_tag_id`",
						"`call_org_id`",
						"`call_follow_status`",
						"`tombstone`",
						"`domain_id`",
						"`call_executor`",
						"`call_date`",
						"`order_executor`",
						"`order_date`",
						"`finish_executor`",
						"`finish_date`",
						"`create_dt`",
						"`update_dt`"
					],
					"connection":[
						{
							"jdbcUrl":[
								"jdbc:mysql://192.168.0.124:3306/ziyun-andon"
							],
							"table":[
								"andon_follow_record"
							]
						}
					],
					"password":"********",
					"username":"ziyunIot",
					"where":"1=1"
				}
			},
			"writer":{
				"name":"hdfswriter",
				"parameter":{
					"column":[
						{
							"name":"`id`",
							"type":"BIGINT"
						},
						{
							"name":"`andon_deviceid`",
							"type":"STRING"
						},
						{
							"name":"`device_name`",
							"type":"STRING"
						},
						{
							"name":"`device_type`",
							"type":"STRING"
						},
						{
							"name":"`call_tag_id`",
							"type":"BIGINT"
						},
						{
							"name":"`call_org_id`",
							"type":"BIGINT"
						},
						{
							"name":"`call_follow_status`",
							"type":"STRING"
						},
						{
							"name":"`tombstone`",
							"type":"STRING"
						},
						{
							"name":"`domain_id`",
							"type":"STRING"
						},
						{
							"name":"`call_executor`",
							"type":"STRING"
						},
						{
							"name":"`call_date`",
							"type":"DATE"
						},
						{
							"name":"`order_executor`",
							"type":"STRING"
						},
						{
							"name":"`order_date`",
							"type":"DATE"
						},
						{
							"name":"`finish_executor`",
							"type":"STRING"
						},
						{
							"name":"`finish_date`",
							"type":"DATE"
						},
						{
							"name":"`create_dt`",
							"type":"DATE"
						},
						{
							"name":"`update_dt`",
							"type":"DATE"
						}
					],
					"compress":"gzip",
					"defaultFS":"hdfs://nameservice1",
					"fieldDelimiter":"\t",
					"fileName":"andon_follow_record",
					"fileType":"text",
					"hadoopConfig":{
						"dfs.client.failover.proxy.provider.nameservice1":"org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider",
						"dfs.ha.namenodes.nameservice1":"nn1,nn2",
						"dfs.namenode.rpc-address.nameservice1.nn1":"ziyunbd01:8020",
						"dfs.namenode.rpc-address.nameservice1.nn2":"ziyunbd02:8020",
						"dfs.nameservices":"nameservice1"
					},
					"path":"/user/hive/warehouse/mysql_ziyun_andon/andon_follow_record",
					"writeMode":"append"
				}
			}
		}
	],
	"setting":{
		"speed":{
			"channel":"3"
		}
	}
}

2021-03-29 18:19:25.267 [main] WARN  Engine - prioriy set to 0, because NumberFormatException, the value is: null
2021-03-29 18:19:25.270 [main] INFO  PerfTrace - PerfTrace traceId=job_-1, isEnable=false, priority=0
2021-03-29 18:19:25.271 [main] INFO  JobContainer - DataX jobContainer starts job.
2021-03-29 18:19:25.274 [main] INFO  JobContainer - Set jobId = 0
2021-03-29 18:19:25.909 [job-0] INFO  OriginalConfPretreatmentUtil - Available jdbcUrl:jdbc:mysql://192.168.0.124:3306/ziyun-andon?yearIsDateType=false&zeroDateTimeBehavior=convertToNull&tinyInt1isBit=false&rewriteBatchedStatements=true.
2021-03-29 18:19:25.937 [job-0] INFO  OriginalConfPretreatmentUtil - table:[andon_follow_record] has columns:[id,andon_deviceid,device_name,device_type,call_tag_id,call_org_id,call_follow_status,tombstone,domain_id,call_executor,call_date,order_executor,order_date,finish_executor,finish_date,create_dt,update_dt].
Mar 29, 2021 6:19:26 PM org.apache.hadoop.util.NativeCodeLoader <clinit>
WARNING: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-03-29 18:19:32.994 [job-0] INFO  JobContainer - jobContainer starts to do prepare ...
2021-03-29 18:19:32.996 [job-0] INFO  JobContainer - DataX Reader.Job [mysqlreader] do prepare work .
2021-03-29 18:19:32.996 [job-0] INFO  JobContainer - DataX Writer.Job [hdfswriter] do prepare work .
2021-03-29 18:19:33.183 [job-0] INFO  HdfsWriter$Job - 由于您配置了writeMode append, 写入前不做清理工作, [/user/hive/warehouse/mysql_ziyun_andon/andon_follow_record] 目录下写入相应文件名前缀  [andon_follow_record] 的文件
2021-03-29 18:19:33.184 [job-0] INFO  JobContainer - jobContainer starts to do split ...
2021-03-29 18:19:33.184 [job-0] INFO  JobContainer - Job set Channel-Number to 3 channels.
2021-03-29 18:19:33.193 [job-0] INFO  JobContainer - DataX Reader.Job [mysqlreader] splits to [1] tasks.
2021-03-29 18:19:33.194 [job-0] INFO  HdfsWriter$Job - begin do split...
2021-03-29 18:19:33.201 [job-0] INFO  HdfsWriter$Job - splited write file name:[hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_follow_record__10223dbc_006e_4852_b2c1_400f7c31ab40/andon_follow_record__6ec818bb_610f_4344_bc8d_0bea495c5bd8]
2021-03-29 18:19:33.202 [job-0] INFO  HdfsWriter$Job - end do split.
2021-03-29 18:19:33.202 [job-0] INFO  JobContainer - DataX Writer.Job [hdfswriter] splits to [1] tasks.
2021-03-29 18:19:33.238 [job-0] INFO  JobContainer - jobContainer starts to do schedule ...
2021-03-29 18:19:33.245 [job-0] INFO  JobContainer - Scheduler starts [1] taskGroups.
2021-03-29 18:19:33.249 [job-0] INFO  JobContainer - Running by standalone Mode.
2021-03-29 18:19:33.261 [taskGroup-0] INFO  TaskGroupContainer - taskGroupId=[0] start [1] channels for [1] tasks.
2021-03-29 18:19:33.268 [taskGroup-0] INFO  Channel - Channel set byte_speed_limit to -1, No bps activated.
2021-03-29 18:19:33.269 [taskGroup-0] INFO  Channel - Channel set record_speed_limit to -1, No tps activated.
2021-03-29 18:19:33.287 [taskGroup-0] INFO  TaskGroupContainer - taskGroup[0] taskId[0] attemptCount[1] is started
2021-03-29 18:19:33.296 [0-0-0-reader] INFO  CommonRdbmsReader$Task - Begin to read record by Sql: [select `id`,`andon_deviceid`,`device_name`,`device_type`,`call_tag_id`,`call_org_id`,`call_follow_status`,`tombstone`,`domain_id`,`call_executor`,`call_date`,`order_executor`,`order_date`,`finish_executor`,`finish_date`,`create_dt`,`update_dt` from andon_follow_record where (1=1)
] jdbcUrl:[jdbc:mysql://192.168.0.124:3306/ziyun-andon?yearIsDateType=false&zeroDateTimeBehavior=convertToNull&tinyInt1isBit=false&rewriteBatchedStatements=true].
2021-03-29 18:19:33.355 [0-0-0-writer] INFO  HdfsWriter$Task - begin do write...
2021-03-29 18:19:33.356 [0-0-0-writer] INFO  HdfsWriter$Task - write to file : [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_follow_record__10223dbc_006e_4852_b2c1_400f7c31ab40/andon_follow_record__6ec818bb_610f_4344_bc8d_0bea495c5bd8]
2021-03-29 18:19:33.420 [0-0-0-reader] INFO  CommonRdbmsReader$Task - Finished read record by Sql: [select `id`,`andon_deviceid`,`device_name`,`device_type`,`call_tag_id`,`call_org_id`,`call_follow_status`,`tombstone`,`domain_id`,`call_executor`,`call_date`,`order_executor`,`order_date`,`finish_executor`,`finish_date`,`create_dt`,`update_dt` from andon_follow_record where (1=1)
] jdbcUrl:[jdbc:mysql://192.168.0.124:3306/ziyun-andon?yearIsDateType=false&zeroDateTimeBehavior=convertToNull&tinyInt1isBit=false&rewriteBatchedStatements=true].
2021-03-29 18:19:33.818 [0-0-0-writer] INFO  HdfsWriter$Task - end do write
2021-03-29 18:19:33.890 [taskGroup-0] INFO  TaskGroupContainer - taskGroup[0] taskId[0] is successed, used[606]ms
2021-03-29 18:19:33.891 [taskGroup-0] INFO  TaskGroupContainer - taskGroup[0] completed it's tasks.
2021-03-29 18:19:43.284 [job-0] INFO  StandAloneJobContainerCommunicator - Total 372 records, 47502 bytes | Speed 4.64KB/s, 37 records/s | Error 0 records, 0 bytes |  All Task WaitWriterTime 0.002s |  All Task WaitReaderTime 0.000s | Percentage 100.00%
2021-03-29 18:19:43.284 [job-0] INFO  AbstractScheduler - Scheduler accomplished all tasks.
2021-03-29 18:19:43.285 [job-0] INFO  JobContainer - DataX Writer.Job [hdfswriter] do post work.
2021-03-29 18:19:43.285 [job-0] INFO  HdfsWriter$Job - start rename file [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_follow_record__10223dbc_006e_4852_b2c1_400f7c31ab40/andon_follow_record__6ec818bb_610f_4344_bc8d_0bea495c5bd8.gz] to file [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_follow_record/andon_follow_record__6ec818bb_610f_4344_bc8d_0bea495c5bd8.gz].
2021-03-29 18:19:43.300 [job-0] INFO  HdfsWriter$Job - finish rename file [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_follow_record__10223dbc_006e_4852_b2c1_400f7c31ab40/andon_follow_record__6ec818bb_610f_4344_bc8d_0bea495c5bd8.gz] to file [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_follow_record/andon_follow_record__6ec818bb_610f_4344_bc8d_0bea495c5bd8.gz].
2021-03-29 18:19:43.301 [job-0] INFO  HdfsWriter$Job - start delete tmp dir [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_follow_record__10223dbc_006e_4852_b2c1_400f7c31ab40] .
2021-03-29 18:19:43.313 [job-0] INFO  HdfsWriter$Job - finish delete tmp dir [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_follow_record__10223dbc_006e_4852_b2c1_400f7c31ab40] .
2021-03-29 18:19:43.314 [job-0] INFO  JobContainer - DataX Reader.Job [mysqlreader] do post work.
2021-03-29 18:19:43.314 [job-0] INFO  JobContainer - DataX jobId [0] completed successfully.
2021-03-29 18:19:43.316 [job-0] INFO  HookInvoker - No hook invoked, because base dir not exists or is a file: /software/datax/hook
2021-03-29 18:19:43.420 [job-0] INFO  JobContainer - 
	 [total cpu info] => 
		averageCpu                     | maxDeltaCpu                    | minDeltaCpu                    
		-1.00%                         | -1.00%                         | -1.00%
                        

	 [total gc info] => 
		 NAME                 | totalGCCount       | maxDeltaGCCount    | minDeltaGCCount    | totalGCTime        | maxDeltaGCTime     | minDeltaGCTime     
		 PS MarkSweep         | 1                  | 1                  | 1                  | 0.060s             | 0.060s             | 0.060s             
		 PS Scavenge          | 1                  | 1                  | 1                  | 0.037s             | 0.037s             | 0.037s             

2021-03-29 18:19:43.421 [job-0] INFO  JobContainer - PerfTrace not enable!
2021-03-29 18:19:43.421 [job-0] INFO  StandAloneJobContainerCommunicator - Total 372 records, 47502 bytes | Speed 4.64KB/s, 37 records/s | Error 0 records, 0 bytes |  All Task WaitWriterTime 0.002s |  All Task WaitReaderTime 0.000s | Percentage 100.00%
2021-03-29 18:19:43.423 [job-0] INFO  JobContainer - 
任务启动时刻                    : 2021-03-29 18:19:25
任务结束时刻                    : 2021-03-29 18:19:43
任务总计耗时                    :                 18s
任务平均流量                    :            4.64KB/s
记录写入速度                    :             37rec/s
读出记录总数                    :                 372
读写失败总数                    :                   0

andon_follow_record表全量同步的结果为0
开始同步一张表
增量配置文件：/software/datax/sync/bin/../conf/jdbc:mysql:192.168.0.124:3306/ziyun-andon.increment
/software/datax/sync/bin/../conf/jdbc:mysql:192.168.0.124:3306/ziyun-andon.increment是文件，进入判断#
maybe_results：
开始全量同步表andon_follow_record_copy1

DataX (DATAX-OPENSOURCE-3.0), From Alibaba !
Copyright (C) 2010-2017, Alibaba Group. All Rights Reserved.


2021-03-29 18:19:44.426 [main] INFO  VMInfo - VMInfo# operatingSystem class => sun.management.OperatingSystemImpl
2021-03-29 18:19:44.437 [main] INFO  Engine - the machine info  => 

	osInfo:	Oracle Corporation 1.8 25.201-b09
	jvmInfo:	Linux amd64 3.10.0-957.el7.x86_64
	cpu num:	16

	totalPhysicalMemory:	-0.00G
	freePhysicalMemory:	-0.00G
	maxFileDescriptorCount:	-1
	currentOpenFileDescriptorCount:	-1

	GC Names	[PS MarkSweep, PS Scavenge]

	MEMORY_NAME                    | allocation_size                | init_size                      
	PS Eden Space                  | 256.00MB                       | 256.00MB                       
	Code Cache                     | 240.00MB                       | 2.44MB                         
	Compressed Class Space         | 1,024.00MB                     | 0.00MB                         
	PS Survivor Space              | 42.50MB                        | 42.50MB                        
	PS Old Gen                     | 683.00MB                       | 683.00MB                       
	Metaspace                      | -0.00MB                        | 0.00MB                         


2021-03-29 18:19:44.484 [main] INFO  Engine - 
{
	"content":[
		{
			"reader":{
				"name":"mysqlreader",
				"parameter":{
					"column":[
						"`id`",
						"`andon_deviceid`",
						"`device_name`",
						"`device_type`",
						"`call_tag_id`",
						"`call_org_hcode`",
						"`call_follow_status`",
						"`tombstone`",
						"`call_executor`",
						"`call_date`",
						"`order_executor`",
						"`order_date`",
						"`finish_executor`",
						"`finish_date`",
						"`create_dt`",
						"`update_dt`"
					],
					"connection":[
						{
							"jdbcUrl":[
								"jdbc:mysql://192.168.0.124:3306/ziyun-andon"
							],
							"table":[
								"andon_follow_record_copy1"
							]
						}
					],
					"password":"********",
					"username":"ziyunIot",
					"where":"1=1"
				}
			},
			"writer":{
				"name":"hdfswriter",
				"parameter":{
					"column":[
						{
							"name":"`id`",
							"type":"BIGINT"
						},
						{
							"name":"`andon_deviceid`",
							"type":"STRING"
						},
						{
							"name":"`device_name`",
							"type":"STRING"
						},
						{
							"name":"`device_type`",
							"type":"STRING"
						},
						{
							"name":"`call_tag_id`",
							"type":"BIGINT"
						},
						{
							"name":"`call_org_hcode`",
							"type":"STRING"
						},
						{
							"name":"`call_follow_status`",
							"type":"STRING"
						},
						{
							"name":"`tombstone`",
							"type":"STRING"
						},
						{
							"name":"`call_executor`",
							"type":"STRING"
						},
						{
							"name":"`call_date`",
							"type":"DATE"
						},
						{
							"name":"`order_executor`",
							"type":"STRING"
						},
						{
							"name":"`order_date`",
							"type":"DATE"
						},
						{
							"name":"`finish_executor`",
							"type":"STRING"
						},
						{
							"name":"`finish_date`",
							"type":"DATE"
						},
						{
							"name":"`create_dt`",
							"type":"DATE"
						},
						{
							"name":"`update_dt`",
							"type":"DATE"
						}
					],
					"compress":"gzip",
					"defaultFS":"hdfs://nameservice1",
					"fieldDelimiter":"\t",
					"fileName":"andon_follow_record_copy1",
					"fileType":"text",
					"hadoopConfig":{
						"dfs.client.failover.proxy.provider.nameservice1":"org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider",
						"dfs.ha.namenodes.nameservice1":"nn1,nn2",
						"dfs.namenode.rpc-address.nameservice1.nn1":"ziyunbd01:8020",
						"dfs.namenode.rpc-address.nameservice1.nn2":"ziyunbd02:8020",
						"dfs.nameservices":"nameservice1"
					},
					"path":"/user/hive/warehouse/mysql_ziyun_andon/andon_follow_record_copy1",
					"writeMode":"append"
				}
			}
		}
	],
	"setting":{
		"speed":{
			"channel":"3"
		}
	}
}

2021-03-29 18:19:44.524 [main] WARN  Engine - prioriy set to 0, because NumberFormatException, the value is: null
2021-03-29 18:19:44.528 [main] INFO  PerfTrace - PerfTrace traceId=job_-1, isEnable=false, priority=0
2021-03-29 18:19:44.529 [main] INFO  JobContainer - DataX jobContainer starts job.
2021-03-29 18:19:44.532 [main] INFO  JobContainer - Set jobId = 0
2021-03-29 18:19:45.235 [job-0] INFO  OriginalConfPretreatmentUtil - Available jdbcUrl:jdbc:mysql://192.168.0.124:3306/ziyun-andon?yearIsDateType=false&zeroDateTimeBehavior=convertToNull&tinyInt1isBit=false&rewriteBatchedStatements=true.
2021-03-29 18:19:45.266 [job-0] INFO  OriginalConfPretreatmentUtil - table:[andon_follow_record_copy1] has columns:[id,andon_deviceid,device_name,device_type,call_tag_id,call_org_hcode,call_follow_status,tombstone,call_executor,call_date,order_executor,order_date,finish_executor,finish_date,create_dt,update_dt].
Mar 29, 2021 6:19:46 PM org.apache.hadoop.util.NativeCodeLoader <clinit>
WARNING: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-03-29 18:19:47.491 [job-0] INFO  JobContainer - jobContainer starts to do prepare ...
2021-03-29 18:19:47.493 [job-0] INFO  JobContainer - DataX Reader.Job [mysqlreader] do prepare work .
2021-03-29 18:19:47.493 [job-0] INFO  JobContainer - DataX Writer.Job [hdfswriter] do prepare work .
2021-03-29 18:19:47.649 [job-0] INFO  HdfsWriter$Job - 由于您配置了writeMode append, 写入前不做清理工作, [/user/hive/warehouse/mysql_ziyun_andon/andon_follow_record_copy1] 目录下写入相应文件名前缀  [andon_follow_record_copy1] 的文件
2021-03-29 18:19:47.650 [job-0] INFO  JobContainer - jobContainer starts to do split ...
2021-03-29 18:19:47.651 [job-0] INFO  JobContainer - Job set Channel-Number to 3 channels.
2021-03-29 18:19:47.660 [job-0] INFO  JobContainer - DataX Reader.Job [mysqlreader] splits to [1] tasks.
2021-03-29 18:19:47.661 [job-0] INFO  HdfsWriter$Job - begin do split...
2021-03-29 18:19:47.670 [job-0] INFO  HdfsWriter$Job - splited write file name:[hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_follow_record_copy1__6df9e04e_96c5_4364_a3d8_da93b06770c0/andon_follow_record_copy1__1774554b_430d_4ebb_88e6_b7ed0274867e]
2021-03-29 18:19:47.670 [job-0] INFO  HdfsWriter$Job - end do split.
2021-03-29 18:19:47.670 [job-0] INFO  JobContainer - DataX Writer.Job [hdfswriter] splits to [1] tasks.
2021-03-29 18:19:47.708 [job-0] INFO  JobContainer - jobContainer starts to do schedule ...
2021-03-29 18:19:47.716 [job-0] INFO  JobContainer - Scheduler starts [1] taskGroups.
2021-03-29 18:19:47.721 [job-0] INFO  JobContainer - Running by standalone Mode.
2021-03-29 18:19:47.734 [taskGroup-0] INFO  TaskGroupContainer - taskGroupId=[0] start [1] channels for [1] tasks.
2021-03-29 18:19:47.742 [taskGroup-0] INFO  Channel - Channel set byte_speed_limit to -1, No bps activated.
2021-03-29 18:19:47.742 [taskGroup-0] INFO  Channel - Channel set record_speed_limit to -1, No tps activated.
2021-03-29 18:19:47.761 [taskGroup-0] INFO  TaskGroupContainer - taskGroup[0] taskId[0] attemptCount[1] is started
2021-03-29 18:19:47.769 [0-0-0-reader] INFO  CommonRdbmsReader$Task - Begin to read record by Sql: [select `id`,`andon_deviceid`,`device_name`,`device_type`,`call_tag_id`,`call_org_hcode`,`call_follow_status`,`tombstone`,`call_executor`,`call_date`,`order_executor`,`order_date`,`finish_executor`,`finish_date`,`create_dt`,`update_dt` from andon_follow_record_copy1 where (1=1)
] jdbcUrl:[jdbc:mysql://192.168.0.124:3306/ziyun-andon?yearIsDateType=false&zeroDateTimeBehavior=convertToNull&tinyInt1isBit=false&rewriteBatchedStatements=true].
2021-03-29 18:19:47.825 [0-0-0-writer] INFO  HdfsWriter$Task - begin do write...
2021-03-29 18:19:47.826 [0-0-0-writer] INFO  HdfsWriter$Task - write to file : [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_follow_record_copy1__6df9e04e_96c5_4364_a3d8_da93b06770c0/andon_follow_record_copy1__1774554b_430d_4ebb_88e6_b7ed0274867e]
2021-03-29 18:19:47.887 [0-0-0-reader] INFO  CommonRdbmsReader$Task - Finished read record by Sql: [select `id`,`andon_deviceid`,`device_name`,`device_type`,`call_tag_id`,`call_org_hcode`,`call_follow_status`,`tombstone`,`call_executor`,`call_date`,`order_executor`,`order_date`,`finish_executor`,`finish_date`,`create_dt`,`update_dt` from andon_follow_record_copy1 where (1=1)
] jdbcUrl:[jdbc:mysql://192.168.0.124:3306/ziyun-andon?yearIsDateType=false&zeroDateTimeBehavior=convertToNull&tinyInt1isBit=false&rewriteBatchedStatements=true].
2021-03-29 18:19:48.292 [0-0-0-writer] INFO  HdfsWriter$Task - end do write
2021-03-29 18:19:48.366 [taskGroup-0] INFO  TaskGroupContainer - taskGroup[0] taskId[0] is successed, used[607]ms
2021-03-29 18:19:48.367 [taskGroup-0] INFO  TaskGroupContainer - taskGroup[0] completed it's tasks.
2021-03-29 18:19:57.757 [job-0] INFO  StandAloneJobContainerCommunicator - Total 326 records, 31183 bytes | Speed 3.04KB/s, 32 records/s | Error 0 records, 0 bytes |  All Task WaitWriterTime 0.001s |  All Task WaitReaderTime 0.000s | Percentage 100.00%
2021-03-29 18:19:57.757 [job-0] INFO  AbstractScheduler - Scheduler accomplished all tasks.
2021-03-29 18:19:57.758 [job-0] INFO  JobContainer - DataX Writer.Job [hdfswriter] do post work.
2021-03-29 18:19:57.759 [job-0] INFO  HdfsWriter$Job - start rename file [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_follow_record_copy1__6df9e04e_96c5_4364_a3d8_da93b06770c0/andon_follow_record_copy1__1774554b_430d_4ebb_88e6_b7ed0274867e.gz] to file [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_follow_record_copy1/andon_follow_record_copy1__1774554b_430d_4ebb_88e6_b7ed0274867e.gz].
2021-03-29 18:19:57.773 [job-0] INFO  HdfsWriter$Job - finish rename file [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_follow_record_copy1__6df9e04e_96c5_4364_a3d8_da93b06770c0/andon_follow_record_copy1__1774554b_430d_4ebb_88e6_b7ed0274867e.gz] to file [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_follow_record_copy1/andon_follow_record_copy1__1774554b_430d_4ebb_88e6_b7ed0274867e.gz].
2021-03-29 18:19:57.773 [job-0] INFO  HdfsWriter$Job - start delete tmp dir [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_follow_record_copy1__6df9e04e_96c5_4364_a3d8_da93b06770c0] .
2021-03-29 18:19:57.785 [job-0] INFO  HdfsWriter$Job - finish delete tmp dir [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_follow_record_copy1__6df9e04e_96c5_4364_a3d8_da93b06770c0] .
2021-03-29 18:19:57.786 [job-0] INFO  JobContainer - DataX Reader.Job [mysqlreader] do post work.
2021-03-29 18:19:57.786 [job-0] INFO  JobContainer - DataX jobId [0] completed successfully.
2021-03-29 18:19:57.788 [job-0] INFO  HookInvoker - No hook invoked, because base dir not exists or is a file: /software/datax/hook
2021-03-29 18:19:57.891 [job-0] INFO  JobContainer - 
	 [total cpu info] => 
		averageCpu                     | maxDeltaCpu                    | minDeltaCpu                    
		-1.00%                         | -1.00%                         | -1.00%
                        

	 [total gc info] => 
		 NAME                 | totalGCCount       | maxDeltaGCCount    | minDeltaGCCount    | totalGCTime        | maxDeltaGCTime     | minDeltaGCTime     
		 PS MarkSweep         | 1                  | 1                  | 1                  | 0.067s             | 0.067s             | 0.067s             
		 PS Scavenge          | 1                  | 1                  | 1                  | 0.040s             | 0.040s             | 0.040s             

2021-03-29 18:19:57.892 [job-0] INFO  JobContainer - PerfTrace not enable!
2021-03-29 18:19:57.893 [job-0] INFO  StandAloneJobContainerCommunicator - Total 326 records, 31183 bytes | Speed 3.04KB/s, 32 records/s | Error 0 records, 0 bytes |  All Task WaitWriterTime 0.001s |  All Task WaitReaderTime 0.000s | Percentage 100.00%
2021-03-29 18:19:57.894 [job-0] INFO  JobContainer - 
任务启动时刻                    : 2021-03-29 18:19:44
任务结束时刻                    : 2021-03-29 18:19:57
任务总计耗时                    :                 13s
任务平均流量                    :            3.04KB/s
记录写入速度                    :             32rec/s
读出记录总数                    :                 326
读写失败总数                    :                   0

andon_follow_record_copy1表全量同步的结果为0
开始同步一张表
增量配置文件：/software/datax/sync/bin/../conf/jdbc:mysql:192.168.0.124:3306/ziyun-andon.increment
/software/datax/sync/bin/../conf/jdbc:mysql:192.168.0.124:3306/ziyun-andon.increment是文件，进入判断#
maybe_results：
开始全量同步表andon_guide_status

DataX (DATAX-OPENSOURCE-3.0), From Alibaba !
Copyright (C) 2010-2017, Alibaba Group. All Rights Reserved.


2021-03-29 18:19:58.904 [main] INFO  VMInfo - VMInfo# operatingSystem class => sun.management.OperatingSystemImpl
2021-03-29 18:19:58.915 [main] INFO  Engine - the machine info  => 

	osInfo:	Oracle Corporation 1.8 25.201-b09
	jvmInfo:	Linux amd64 3.10.0-957.el7.x86_64
	cpu num:	16

	totalPhysicalMemory:	-0.00G
	freePhysicalMemory:	-0.00G
	maxFileDescriptorCount:	-1
	currentOpenFileDescriptorCount:	-1

	GC Names	[PS MarkSweep, PS Scavenge]

	MEMORY_NAME                    | allocation_size                | init_size                      
	PS Eden Space                  | 256.00MB                       | 256.00MB                       
	Code Cache                     | 240.00MB                       | 2.44MB                         
	Compressed Class Space         | 1,024.00MB                     | 0.00MB                         
	PS Survivor Space              | 42.50MB                        | 42.50MB                        
	PS Old Gen                     | 683.00MB                       | 683.00MB                       
	Metaspace                      | -0.00MB                        | 0.00MB                         


2021-03-29 18:19:58.947 [main] INFO  Engine - 
{
	"content":[
		{
			"reader":{
				"name":"mysqlreader",
				"parameter":{
					"column":[
						"`id`",
						"`guide_sso_id`",
						"`guide_org_id`",
						"`guide_status`",
						"`tombstone`",
						"`domain_id`",
						"`create_dt`",
						"`update_dt`"
					],
					"connection":[
						{
							"jdbcUrl":[
								"jdbc:mysql://192.168.0.124:3306/ziyun-andon"
							],
							"table":[
								"andon_guide_status"
							]
						}
					],
					"password":"********",
					"username":"ziyunIot",
					"where":"1=1"
				}
			},
			"writer":{
				"name":"hdfswriter",
				"parameter":{
					"column":[
						{
							"name":"`id`",
							"type":"BIGINT"
						},
						{
							"name":"`guide_sso_id`",
							"type":"STRING"
						},
						{
							"name":"`guide_org_id`",
							"type":"BIGINT"
						},
						{
							"name":"`guide_status`",
							"type":"STRING"
						},
						{
							"name":"`tombstone`",
							"type":"STRING"
						},
						{
							"name":"`domain_id`",
							"type":"STRING"
						},
						{
							"name":"`create_dt`",
							"type":"DATE"
						},
						{
							"name":"`update_dt`",
							"type":"DATE"
						}
					],
					"compress":"gzip",
					"defaultFS":"hdfs://nameservice1",
					"fieldDelimiter":"\t",
					"fileName":"andon_guide_status",
					"fileType":"text",
					"hadoopConfig":{
						"dfs.client.failover.proxy.provider.nameservice1":"org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider",
						"dfs.ha.namenodes.nameservice1":"nn1,nn2",
						"dfs.namenode.rpc-address.nameservice1.nn1":"ziyunbd01:8020",
						"dfs.namenode.rpc-address.nameservice1.nn2":"ziyunbd02:8020",
						"dfs.nameservices":"nameservice1"
					},
					"path":"/user/hive/warehouse/mysql_ziyun_andon/andon_guide_status",
					"writeMode":"append"
				}
			}
		}
	],
	"setting":{
		"speed":{
			"channel":"3"
		}
	}
}

2021-03-29 18:19:58.975 [main] WARN  Engine - prioriy set to 0, because NumberFormatException, the value is: null
2021-03-29 18:19:58.978 [main] INFO  PerfTrace - PerfTrace traceId=job_-1, isEnable=false, priority=0
2021-03-29 18:19:58.978 [main] INFO  JobContainer - DataX jobContainer starts job.
2021-03-29 18:19:58.982 [main] INFO  JobContainer - Set jobId = 0
2021-03-29 18:19:59.488 [job-0] INFO  OriginalConfPretreatmentUtil - Available jdbcUrl:jdbc:mysql://192.168.0.124:3306/ziyun-andon?yearIsDateType=false&zeroDateTimeBehavior=convertToNull&tinyInt1isBit=false&rewriteBatchedStatements=true.
2021-03-29 18:19:59.517 [job-0] INFO  OriginalConfPretreatmentUtil - table:[andon_guide_status] has columns:[id,guide_sso_id,guide_org_id,guide_status,tombstone,domain_id,create_dt,update_dt].
Mar 29, 2021 6:20:00 PM org.apache.hadoop.util.NativeCodeLoader <clinit>
WARNING: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-03-29 18:20:01.565 [job-0] INFO  JobContainer - jobContainer starts to do prepare ...
2021-03-29 18:20:01.567 [job-0] INFO  JobContainer - DataX Reader.Job [mysqlreader] do prepare work .
2021-03-29 18:20:01.568 [job-0] INFO  JobContainer - DataX Writer.Job [hdfswriter] do prepare work .
2021-03-29 18:20:01.773 [job-0] INFO  HdfsWriter$Job - 由于您配置了writeMode append, 写入前不做清理工作, [/user/hive/warehouse/mysql_ziyun_andon/andon_guide_status] 目录下写入相应文件名前缀  [andon_guide_status] 的文件
2021-03-29 18:20:01.773 [job-0] INFO  JobContainer - jobContainer starts to do split ...
2021-03-29 18:20:01.774 [job-0] INFO  JobContainer - Job set Channel-Number to 3 channels.
2021-03-29 18:20:01.784 [job-0] INFO  JobContainer - DataX Reader.Job [mysqlreader] splits to [1] tasks.
2021-03-29 18:20:01.784 [job-0] INFO  HdfsWriter$Job - begin do split...
2021-03-29 18:20:01.792 [job-0] INFO  HdfsWriter$Job - splited write file name:[hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_guide_status__3555f87f_a6cd_483e_af62_2ce6c0268895/andon_guide_status__46c80c45_15d3_4b95_9a11_b6cc4ea28897]
2021-03-29 18:20:01.793 [job-0] INFO  HdfsWriter$Job - end do split.
2021-03-29 18:20:01.793 [job-0] INFO  JobContainer - DataX Writer.Job [hdfswriter] splits to [1] tasks.
2021-03-29 18:20:01.831 [job-0] INFO  JobContainer - jobContainer starts to do schedule ...
2021-03-29 18:20:01.839 [job-0] INFO  JobContainer - Scheduler starts [1] taskGroups.
2021-03-29 18:20:01.844 [job-0] INFO  JobContainer - Running by standalone Mode.
2021-03-29 18:20:01.858 [taskGroup-0] INFO  TaskGroupContainer - taskGroupId=[0] start [1] channels for [1] tasks.
2021-03-29 18:20:01.866 [taskGroup-0] INFO  Channel - Channel set byte_speed_limit to -1, No bps activated.
2021-03-29 18:20:01.867 [taskGroup-0] INFO  Channel - Channel set record_speed_limit to -1, No tps activated.
2021-03-29 18:20:01.885 [taskGroup-0] INFO  TaskGroupContainer - taskGroup[0] taskId[0] attemptCount[1] is started
2021-03-29 18:20:01.892 [0-0-0-reader] INFO  CommonRdbmsReader$Task - Begin to read record by Sql: [select `id`,`guide_sso_id`,`guide_org_id`,`guide_status`,`tombstone`,`domain_id`,`create_dt`,`update_dt` from andon_guide_status where (1=1)
] jdbcUrl:[jdbc:mysql://192.168.0.124:3306/ziyun-andon?yearIsDateType=false&zeroDateTimeBehavior=convertToNull&tinyInt1isBit=false&rewriteBatchedStatements=true].
2021-03-29 18:20:01.949 [0-0-0-reader] INFO  CommonRdbmsReader$Task - Finished read record by Sql: [select `id`,`guide_sso_id`,`guide_org_id`,`guide_status`,`tombstone`,`domain_id`,`create_dt`,`update_dt` from andon_guide_status where (1=1)
] jdbcUrl:[jdbc:mysql://192.168.0.124:3306/ziyun-andon?yearIsDateType=false&zeroDateTimeBehavior=convertToNull&tinyInt1isBit=false&rewriteBatchedStatements=true].
2021-03-29 18:20:01.950 [0-0-0-writer] INFO  HdfsWriter$Task - begin do write...
2021-03-29 18:20:01.950 [0-0-0-writer] INFO  HdfsWriter$Task - write to file : [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_guide_status__3555f87f_a6cd_483e_af62_2ce6c0268895/andon_guide_status__46c80c45_15d3_4b95_9a11_b6cc4ea28897]
2021-03-29 18:20:02.375 [0-0-0-writer] INFO  HdfsWriter$Task - end do write
2021-03-29 18:20:02.387 [taskGroup-0] INFO  TaskGroupContainer - taskGroup[0] taskId[0] is successed, used[505]ms
2021-03-29 18:20:02.388 [taskGroup-0] INFO  TaskGroupContainer - taskGroup[0] completed it's tasks.
2021-03-29 18:20:11.880 [job-0] INFO  StandAloneJobContainerCommunicator - Total 74 records, 5038 bytes | Speed 503B/s, 7 records/s | Error 0 records, 0 bytes |  All Task WaitWriterTime 0.000s |  All Task WaitReaderTime 0.000s | Percentage 100.00%
2021-03-29 18:20:11.881 [job-0] INFO  AbstractScheduler - Scheduler accomplished all tasks.
2021-03-29 18:20:11.882 [job-0] INFO  JobContainer - DataX Writer.Job [hdfswriter] do post work.
2021-03-29 18:20:11.883 [job-0] INFO  HdfsWriter$Job - start rename file [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_guide_status__3555f87f_a6cd_483e_af62_2ce6c0268895/andon_guide_status__46c80c45_15d3_4b95_9a11_b6cc4ea28897.gz] to file [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_guide_status/andon_guide_status__46c80c45_15d3_4b95_9a11_b6cc4ea28897.gz].
2021-03-29 18:20:11.897 [job-0] INFO  HdfsWriter$Job - finish rename file [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_guide_status__3555f87f_a6cd_483e_af62_2ce6c0268895/andon_guide_status__46c80c45_15d3_4b95_9a11_b6cc4ea28897.gz] to file [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_guide_status/andon_guide_status__46c80c45_15d3_4b95_9a11_b6cc4ea28897.gz].
2021-03-29 18:20:11.897 [job-0] INFO  HdfsWriter$Job - start delete tmp dir [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_guide_status__3555f87f_a6cd_483e_af62_2ce6c0268895] .
2021-03-29 18:20:11.909 [job-0] INFO  HdfsWriter$Job - finish delete tmp dir [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_guide_status__3555f87f_a6cd_483e_af62_2ce6c0268895] .
2021-03-29 18:20:11.909 [job-0] INFO  JobContainer - DataX Reader.Job [mysqlreader] do post work.
2021-03-29 18:20:11.910 [job-0] INFO  JobContainer - DataX jobId [0] completed successfully.
2021-03-29 18:20:11.911 [job-0] INFO  HookInvoker - No hook invoked, because base dir not exists or is a file: /software/datax/hook
2021-03-29 18:20:12.014 [job-0] INFO  JobContainer - 
	 [total cpu info] => 
		averageCpu                     | maxDeltaCpu                    | minDeltaCpu                    
		-1.00%                         | -1.00%                         | -1.00%
                        

	 [total gc info] => 
		 NAME                 | totalGCCount       | maxDeltaGCCount    | minDeltaGCCount    | totalGCTime        | maxDeltaGCTime     | minDeltaGCTime     
		 PS MarkSweep         | 1                  | 1                  | 1                  | 0.073s             | 0.073s             | 0.073s             
		 PS Scavenge          | 1                  | 1                  | 1                  | 0.045s             | 0.045s             | 0.045s             

2021-03-29 18:20:12.015 [job-0] INFO  JobContainer - PerfTrace not enable!
2021-03-29 18:20:12.015 [job-0] INFO  StandAloneJobContainerCommunicator - Total 74 records, 5038 bytes | Speed 503B/s, 7 records/s | Error 0 records, 0 bytes |  All Task WaitWriterTime 0.000s |  All Task WaitReaderTime 0.000s | Percentage 100.00%
2021-03-29 18:20:12.017 [job-0] INFO  JobContainer - 
任务启动时刻                    : 2021-03-29 18:19:58
任务结束时刻                    : 2021-03-29 18:20:12
任务总计耗时                    :                 13s
任务平均流量                    :              503B/s
记录写入速度                    :              7rec/s
读出记录总数                    :                  74
读写失败总数                    :                   0

andon_guide_status表全量同步的结果为0
开始同步一张表
增量配置文件：/software/datax/sync/bin/../conf/jdbc:mysql:192.168.0.124:3306/ziyun-andon.increment
/software/datax/sync/bin/../conf/jdbc:mysql:192.168.0.124:3306/ziyun-andon.increment是文件，进入判断#
maybe_results：
开始全量同步表andon_guide_status_copy1

DataX (DATAX-OPENSOURCE-3.0), From Alibaba !
Copyright (C) 2010-2017, Alibaba Group. All Rights Reserved.


2021-03-29 18:20:12.996 [main] INFO  VMInfo - VMInfo# operatingSystem class => sun.management.OperatingSystemImpl
2021-03-29 18:20:13.006 [main] INFO  Engine - the machine info  => 

	osInfo:	Oracle Corporation 1.8 25.201-b09
	jvmInfo:	Linux amd64 3.10.0-957.el7.x86_64
	cpu num:	16

	totalPhysicalMemory:	-0.00G
	freePhysicalMemory:	-0.00G
	maxFileDescriptorCount:	-1
	currentOpenFileDescriptorCount:	-1

	GC Names	[PS MarkSweep, PS Scavenge]

	MEMORY_NAME                    | allocation_size                | init_size                      
	PS Eden Space                  | 256.00MB                       | 256.00MB                       
	Code Cache                     | 240.00MB                       | 2.44MB                         
	Compressed Class Space         | 1,024.00MB                     | 0.00MB                         
	PS Survivor Space              | 42.50MB                        | 42.50MB                        
	PS Old Gen                     | 683.00MB                       | 683.00MB                       
	Metaspace                      | -0.00MB                        | 0.00MB                         


2021-03-29 18:20:13.037 [main] INFO  Engine - 
{
	"content":[
		{
			"reader":{
				"name":"mysqlreader",
				"parameter":{
					"column":[
						"`id`",
						"`guide_sso_id`",
						"`guide_org_hcode`",
						"`guide_status`",
						"`tombstone`",
						"`create_dt`",
						"`update_dt`"
					],
					"connection":[
						{
							"jdbcUrl":[
								"jdbc:mysql://192.168.0.124:3306/ziyun-andon"
							],
							"table":[
								"andon_guide_status_copy1"
							]
						}
					],
					"password":"********",
					"username":"ziyunIot",
					"where":"1=1"
				}
			},
			"writer":{
				"name":"hdfswriter",
				"parameter":{
					"column":[
						{
							"name":"`id`",
							"type":"BIGINT"
						},
						{
							"name":"`guide_sso_id`",
							"type":"STRING"
						},
						{
							"name":"`guide_org_hcode`",
							"type":"STRING"
						},
						{
							"name":"`guide_status`",
							"type":"STRING"
						},
						{
							"name":"`tombstone`",
							"type":"STRING"
						},
						{
							"name":"`create_dt`",
							"type":"DATE"
						},
						{
							"name":"`update_dt`",
							"type":"DATE"
						}
					],
					"compress":"gzip",
					"defaultFS":"hdfs://nameservice1",
					"fieldDelimiter":"\t",
					"fileName":"andon_guide_status_copy1",
					"fileType":"text",
					"hadoopConfig":{
						"dfs.client.failover.proxy.provider.nameservice1":"org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider",
						"dfs.ha.namenodes.nameservice1":"nn1,nn2",
						"dfs.namenode.rpc-address.nameservice1.nn1":"ziyunbd01:8020",
						"dfs.namenode.rpc-address.nameservice1.nn2":"ziyunbd02:8020",
						"dfs.nameservices":"nameservice1"
					},
					"path":"/user/hive/warehouse/mysql_ziyun_andon/andon_guide_status_copy1",
					"writeMode":"append"
				}
			}
		}
	],
	"setting":{
		"speed":{
			"channel":"3"
		}
	}
}

2021-03-29 18:20:13.061 [main] WARN  Engine - prioriy set to 0, because NumberFormatException, the value is: null
2021-03-29 18:20:13.064 [main] INFO  PerfTrace - PerfTrace traceId=job_-1, isEnable=false, priority=0
2021-03-29 18:20:13.064 [main] INFO  JobContainer - DataX jobContainer starts job.
2021-03-29 18:20:13.066 [main] INFO  JobContainer - Set jobId = 0
2021-03-29 18:20:13.591 [job-0] INFO  OriginalConfPretreatmentUtil - Available jdbcUrl:jdbc:mysql://192.168.0.124:3306/ziyun-andon?yearIsDateType=false&zeroDateTimeBehavior=convertToNull&tinyInt1isBit=false&rewriteBatchedStatements=true.
2021-03-29 18:20:13.623 [job-0] INFO  OriginalConfPretreatmentUtil - table:[andon_guide_status_copy1] has columns:[id,guide_sso_id,guide_org_hcode,guide_status,tombstone,create_dt,update_dt].
Mar 29, 2021 6:20:14 PM org.apache.hadoop.util.NativeCodeLoader <clinit>
WARNING: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-03-29 18:20:15.737 [job-0] INFO  JobContainer - jobContainer starts to do prepare ...
2021-03-29 18:20:15.738 [job-0] INFO  JobContainer - DataX Reader.Job [mysqlreader] do prepare work .
2021-03-29 18:20:15.738 [job-0] INFO  JobContainer - DataX Writer.Job [hdfswriter] do prepare work .
2021-03-29 18:20:15.902 [job-0] INFO  HdfsWriter$Job - 由于您配置了writeMode append, 写入前不做清理工作, [/user/hive/warehouse/mysql_ziyun_andon/andon_guide_status_copy1] 目录下写入相应文件名前缀  [andon_guide_status_copy1] 的文件
2021-03-29 18:20:15.903 [job-0] INFO  JobContainer - jobContainer starts to do split ...
2021-03-29 18:20:15.904 [job-0] INFO  JobContainer - Job set Channel-Number to 3 channels.
2021-03-29 18:20:15.912 [job-0] INFO  JobContainer - DataX Reader.Job [mysqlreader] splits to [1] tasks.
2021-03-29 18:20:15.913 [job-0] INFO  HdfsWriter$Job - begin do split...
2021-03-29 18:20:15.920 [job-0] INFO  HdfsWriter$Job - splited write file name:[hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_guide_status_copy1__d3538e43_c098_44b0_876f_f2d257ebb31b/andon_guide_status_copy1__22eeb6a3_16c9_4c72_988b_3b8faa916f91]
2021-03-29 18:20:15.920 [job-0] INFO  HdfsWriter$Job - end do split.
2021-03-29 18:20:15.920 [job-0] INFO  JobContainer - DataX Writer.Job [hdfswriter] splits to [1] tasks.
2021-03-29 18:20:15.956 [job-0] INFO  JobContainer - jobContainer starts to do schedule ...
2021-03-29 18:20:15.963 [job-0] INFO  JobContainer - Scheduler starts [1] taskGroups.
2021-03-29 18:20:15.970 [job-0] INFO  JobContainer - Running by standalone Mode.
2021-03-29 18:20:15.982 [taskGroup-0] INFO  TaskGroupContainer - taskGroupId=[0] start [1] channels for [1] tasks.
2021-03-29 18:20:15.994 [taskGroup-0] INFO  Channel - Channel set byte_speed_limit to -1, No bps activated.
2021-03-29 18:20:15.995 [taskGroup-0] INFO  Channel - Channel set record_speed_limit to -1, No tps activated.
2021-03-29 18:20:16.014 [taskGroup-0] INFO  TaskGroupContainer - taskGroup[0] taskId[0] attemptCount[1] is started
2021-03-29 18:20:16.022 [0-0-0-reader] INFO  CommonRdbmsReader$Task - Begin to read record by Sql: [select `id`,`guide_sso_id`,`guide_org_hcode`,`guide_status`,`tombstone`,`create_dt`,`update_dt` from andon_guide_status_copy1 where (1=1)
] jdbcUrl:[jdbc:mysql://192.168.0.124:3306/ziyun-andon?yearIsDateType=false&zeroDateTimeBehavior=convertToNull&tinyInt1isBit=false&rewriteBatchedStatements=true].
2021-03-29 18:20:16.071 [0-0-0-writer] INFO  HdfsWriter$Task - begin do write...
2021-03-29 18:20:16.071 [0-0-0-writer] INFO  HdfsWriter$Task - write to file : [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_guide_status_copy1__d3538e43_c098_44b0_876f_f2d257ebb31b/andon_guide_status_copy1__22eeb6a3_16c9_4c72_988b_3b8faa916f91]
2021-03-29 18:20:16.080 [0-0-0-reader] INFO  CommonRdbmsReader$Task - Finished read record by Sql: [select `id`,`guide_sso_id`,`guide_org_hcode`,`guide_status`,`tombstone`,`create_dt`,`update_dt` from andon_guide_status_copy1 where (1=1)
] jdbcUrl:[jdbc:mysql://192.168.0.124:3306/ziyun-andon?yearIsDateType=false&zeroDateTimeBehavior=convertToNull&tinyInt1isBit=false&rewriteBatchedStatements=true].
2021-03-29 18:20:16.425 [0-0-0-writer] INFO  HdfsWriter$Task - end do write
2021-03-29 18:20:16.516 [taskGroup-0] INFO  TaskGroupContainer - taskGroup[0] taskId[0] is successed, used[503]ms
2021-03-29 18:20:16.517 [taskGroup-0] INFO  TaskGroupContainer - taskGroup[0] completed it's tasks.
2021-03-29 18:20:26.008 [job-0] INFO  StandAloneJobContainerCommunicator - Total 66 records, 2436 bytes | Speed 243B/s, 6 records/s | Error 0 records, 0 bytes |  All Task WaitWriterTime 0.002s |  All Task WaitReaderTime 0.000s | Percentage 100.00%
2021-03-29 18:20:26.009 [job-0] INFO  AbstractScheduler - Scheduler accomplished all tasks.
2021-03-29 18:20:26.010 [job-0] INFO  JobContainer - DataX Writer.Job [hdfswriter] do post work.
2021-03-29 18:20:26.010 [job-0] INFO  HdfsWriter$Job - start rename file [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_guide_status_copy1__d3538e43_c098_44b0_876f_f2d257ebb31b/andon_guide_status_copy1__22eeb6a3_16c9_4c72_988b_3b8faa916f91.gz] to file [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_guide_status_copy1/andon_guide_status_copy1__22eeb6a3_16c9_4c72_988b_3b8faa916f91.gz].
2021-03-29 18:20:26.048 [job-0] INFO  HdfsWriter$Job - finish rename file [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_guide_status_copy1__d3538e43_c098_44b0_876f_f2d257ebb31b/andon_guide_status_copy1__22eeb6a3_16c9_4c72_988b_3b8faa916f91.gz] to file [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_guide_status_copy1/andon_guide_status_copy1__22eeb6a3_16c9_4c72_988b_3b8faa916f91.gz].
2021-03-29 18:20:26.049 [job-0] INFO  HdfsWriter$Job - start delete tmp dir [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_guide_status_copy1__d3538e43_c098_44b0_876f_f2d257ebb31b] .
2021-03-29 18:20:26.086 [job-0] INFO  HdfsWriter$Job - finish delete tmp dir [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_guide_status_copy1__d3538e43_c098_44b0_876f_f2d257ebb31b] .
2021-03-29 18:20:26.087 [job-0] INFO  JobContainer - DataX Reader.Job [mysqlreader] do post work.
2021-03-29 18:20:26.087 [job-0] INFO  JobContainer - DataX jobId [0] completed successfully.
2021-03-29 18:20:26.089 [job-0] INFO  HookInvoker - No hook invoked, because base dir not exists or is a file: /software/datax/hook
2021-03-29 18:20:26.203 [job-0] INFO  JobContainer - 
	 [total cpu info] => 
		averageCpu                     | maxDeltaCpu                    | minDeltaCpu                    
		-1.00%                         | -1.00%                         | -1.00%
                        

	 [total gc info] => 
		 NAME                 | totalGCCount       | maxDeltaGCCount    | minDeltaGCCount    | totalGCTime        | maxDeltaGCTime     | minDeltaGCTime     
		 PS MarkSweep         | 1                  | 1                  | 1                  | 0.072s             | 0.072s             | 0.072s             
		 PS Scavenge          | 1                  | 1                  | 1                  | 0.045s             | 0.045s             | 0.045s             

2021-03-29 18:20:26.204 [job-0] INFO  JobContainer - PerfTrace not enable!
2021-03-29 18:20:26.204 [job-0] INFO  StandAloneJobContainerCommunicator - Total 66 records, 2436 bytes | Speed 243B/s, 6 records/s | Error 0 records, 0 bytes |  All Task WaitWriterTime 0.002s |  All Task WaitReaderTime 0.000s | Percentage 100.00%
2021-03-29 18:20:26.216 [job-0] INFO  JobContainer - 
任务启动时刻                    : 2021-03-29 18:20:13
任务结束时刻                    : 2021-03-29 18:20:26
任务总计耗时                    :                 13s
任务平均流量                    :              243B/s
记录写入速度                    :              6rec/s
读出记录总数                    :                  66
读写失败总数                    :                   0

andon_guide_status_copy1表全量同步的结果为0
开始同步一张表
增量配置文件：/software/datax/sync/bin/../conf/jdbc:mysql:192.168.0.124:3306/ziyun-andon.increment
/software/datax/sync/bin/../conf/jdbc:mysql:192.168.0.124:3306/ziyun-andon.increment是文件，进入判断#
maybe_results：
开始全量同步表andon_org_tag

DataX (DATAX-OPENSOURCE-3.0), From Alibaba !
Copyright (C) 2010-2017, Alibaba Group. All Rights Reserved.


2021-03-29 18:20:27.660 [main] INFO  VMInfo - VMInfo# operatingSystem class => sun.management.OperatingSystemImpl
2021-03-29 18:20:27.680 [main] INFO  Engine - the machine info  => 

	osInfo:	Oracle Corporation 1.8 25.201-b09
	jvmInfo:	Linux amd64 3.10.0-957.el7.x86_64
	cpu num:	16

	totalPhysicalMemory:	-0.00G
	freePhysicalMemory:	-0.00G
	maxFileDescriptorCount:	-1
	currentOpenFileDescriptorCount:	-1

	GC Names	[PS MarkSweep, PS Scavenge]

	MEMORY_NAME                    | allocation_size                | init_size                      
	PS Eden Space                  | 256.00MB                       | 256.00MB                       
	Code Cache                     | 240.00MB                       | 2.44MB                         
	Compressed Class Space         | 1,024.00MB                     | 0.00MB                         
	PS Survivor Space              | 42.50MB                        | 42.50MB                        
	PS Old Gen                     | 683.00MB                       | 683.00MB                       
	Metaspace                      | -0.00MB                        | 0.00MB                         


2021-03-29 18:20:27.728 [main] INFO  Engine - 
{
	"content":[
		{
			"reader":{
				"name":"mysqlreader",
				"parameter":{
					"column":[
						"`tag_id`",
						"`org_tag_name`",
						"`org_id`",
						"`tombstone`",
						"`domain_id`",
						"`create_sso`",
						"`create_dt`",
						"`update_sso`",
						"`update_dt`"
					],
					"connection":[
						{
							"jdbcUrl":[
								"jdbc:mysql://192.168.0.124:3306/ziyun-andon"
							],
							"table":[
								"andon_org_tag"
							]
						}
					],
					"password":"********",
					"username":"ziyunIot",
					"where":"1=1"
				}
			},
			"writer":{
				"name":"hdfswriter",
				"parameter":{
					"column":[
						{
							"name":"`tag_id`",
							"type":"BIGINT"
						},
						{
							"name":"`org_tag_name`",
							"type":"STRING"
						},
						{
							"name":"`org_id`",
							"type":"BIGINT"
						},
						{
							"name":"`tombstone`",
							"type":"STRING"
						},
						{
							"name":"`domain_id`",
							"type":"STRING"
						},
						{
							"name":"`create_sso`",
							"type":"STRING"
						},
						{
							"name":"`create_dt`",
							"type":"DATE"
						},
						{
							"name":"`update_sso`",
							"type":"STRING"
						},
						{
							"name":"`update_dt`",
							"type":"DATE"
						}
					],
					"compress":"gzip",
					"defaultFS":"hdfs://nameservice1",
					"fieldDelimiter":"\t",
					"fileName":"andon_org_tag",
					"fileType":"text",
					"hadoopConfig":{
						"dfs.client.failover.proxy.provider.nameservice1":"org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider",
						"dfs.ha.namenodes.nameservice1":"nn1,nn2",
						"dfs.namenode.rpc-address.nameservice1.nn1":"ziyunbd01:8020",
						"dfs.namenode.rpc-address.nameservice1.nn2":"ziyunbd02:8020",
						"dfs.nameservices":"nameservice1"
					},
					"path":"/user/hive/warehouse/mysql_ziyun_andon/andon_org_tag",
					"writeMode":"append"
				}
			}
		}
	],
	"setting":{
		"speed":{
			"channel":"3"
		}
	}
}

2021-03-29 18:20:27.768 [main] WARN  Engine - prioriy set to 0, because NumberFormatException, the value is: null
2021-03-29 18:20:27.772 [main] INFO  PerfTrace - PerfTrace traceId=job_-1, isEnable=false, priority=0
2021-03-29 18:20:27.773 [main] INFO  JobContainer - DataX jobContainer starts job.
2021-03-29 18:20:27.778 [main] INFO  JobContainer - Set jobId = 0
2021-03-29 18:20:28.453 [job-0] INFO  OriginalConfPretreatmentUtil - Available jdbcUrl:jdbc:mysql://192.168.0.124:3306/ziyun-andon?yearIsDateType=false&zeroDateTimeBehavior=convertToNull&tinyInt1isBit=false&rewriteBatchedStatements=true.
2021-03-29 18:20:28.496 [job-0] INFO  OriginalConfPretreatmentUtil - table:[andon_org_tag] has columns:[tag_id,org_tag_name,org_id,tombstone,domain_id,create_sso,create_dt,update_sso,update_dt].
Mar 29, 2021 6:20:29 PM org.apache.hadoop.util.NativeCodeLoader <clinit>
WARNING: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-03-29 18:20:30.618 [job-0] INFO  JobContainer - jobContainer starts to do prepare ...
2021-03-29 18:20:30.620 [job-0] INFO  JobContainer - DataX Reader.Job [mysqlreader] do prepare work .
2021-03-29 18:20:30.620 [job-0] INFO  JobContainer - DataX Writer.Job [hdfswriter] do prepare work .
2021-03-29 18:20:30.817 [job-0] INFO  HdfsWriter$Job - 由于您配置了writeMode append, 写入前不做清理工作, [/user/hive/warehouse/mysql_ziyun_andon/andon_org_tag] 目录下写入相应文件名前缀  [andon_org_tag] 的文件
2021-03-29 18:20:30.818 [job-0] INFO  JobContainer - jobContainer starts to do split ...
2021-03-29 18:20:30.818 [job-0] INFO  JobContainer - Job set Channel-Number to 3 channels.
2021-03-29 18:20:30.837 [job-0] INFO  JobContainer - DataX Reader.Job [mysqlreader] splits to [1] tasks.
2021-03-29 18:20:30.841 [job-0] INFO  HdfsWriter$Job - begin do split...
2021-03-29 18:20:30.856 [job-0] INFO  HdfsWriter$Job - splited write file name:[hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_org_tag__b158f0b5_2539_41a9_aab7_94e960ad77f3/andon_org_tag__b0dbac5c_561c_49a5_832f_fd9d90ed02dc]
2021-03-29 18:20:30.857 [job-0] INFO  HdfsWriter$Job - end do split.
2021-03-29 18:20:30.857 [job-0] INFO  JobContainer - DataX Writer.Job [hdfswriter] splits to [1] tasks.
2021-03-29 18:20:30.897 [job-0] INFO  JobContainer - jobContainer starts to do schedule ...
2021-03-29 18:20:30.926 [job-0] INFO  JobContainer - Scheduler starts [1] taskGroups.
2021-03-29 18:20:30.942 [job-0] INFO  JobContainer - Running by standalone Mode.
2021-03-29 18:20:30.968 [taskGroup-0] INFO  TaskGroupContainer - taskGroupId=[0] start [1] channels for [1] tasks.
2021-03-29 18:20:30.973 [taskGroup-0] INFO  Channel - Channel set byte_speed_limit to -1, No bps activated.
2021-03-29 18:20:30.973 [taskGroup-0] INFO  Channel - Channel set record_speed_limit to -1, No tps activated.
2021-03-29 18:20:31.010 [0-0-0-reader] INFO  CommonRdbmsReader$Task - Begin to read record by Sql: [select `tag_id`,`org_tag_name`,`org_id`,`tombstone`,`domain_id`,`create_sso`,`create_dt`,`update_sso`,`update_dt` from andon_org_tag where (1=1)
] jdbcUrl:[jdbc:mysql://192.168.0.124:3306/ziyun-andon?yearIsDateType=false&zeroDateTimeBehavior=convertToNull&tinyInt1isBit=false&rewriteBatchedStatements=true].
2021-03-29 18:20:31.012 [taskGroup-0] INFO  TaskGroupContainer - taskGroup[0] taskId[0] attemptCount[1] is started
2021-03-29 18:20:31.055 [0-0-0-writer] INFO  HdfsWriter$Task - begin do write...
2021-03-29 18:20:31.056 [0-0-0-writer] INFO  HdfsWriter$Task - write to file : [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_org_tag__b158f0b5_2539_41a9_aab7_94e960ad77f3/andon_org_tag__b0dbac5c_561c_49a5_832f_fd9d90ed02dc]
2021-03-29 18:20:31.347 [0-0-0-reader] INFO  CommonRdbmsReader$Task - Finished read record by Sql: [select `tag_id`,`org_tag_name`,`org_id`,`tombstone`,`domain_id`,`create_sso`,`create_dt`,`update_sso`,`update_dt` from andon_org_tag where (1=1)
] jdbcUrl:[jdbc:mysql://192.168.0.124:3306/ziyun-andon?yearIsDateType=false&zeroDateTimeBehavior=convertToNull&tinyInt1isBit=false&rewriteBatchedStatements=true].
2021-03-29 18:20:31.878 [0-0-0-writer] INFO  HdfsWriter$Task - end do write
2021-03-29 18:20:31.939 [taskGroup-0] INFO  TaskGroupContainer - taskGroup[0] taskId[0] is successed, used[953]ms
2021-03-29 18:20:31.939 [taskGroup-0] INFO  TaskGroupContainer - taskGroup[0] completed it's tasks.
2021-03-29 18:20:40.989 [job-0] INFO  StandAloneJobContainerCommunicator - Total 180 records, 15394 bytes | Speed 1.50KB/s, 18 records/s | Error 0 records, 0 bytes |  All Task WaitWriterTime 0.000s |  All Task WaitReaderTime 0.000s | Percentage 100.00%
2021-03-29 18:20:40.990 [job-0] INFO  AbstractScheduler - Scheduler accomplished all tasks.
2021-03-29 18:20:40.991 [job-0] INFO  JobContainer - DataX Writer.Job [hdfswriter] do post work.
2021-03-29 18:20:40.992 [job-0] INFO  HdfsWriter$Job - start rename file [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_org_tag__b158f0b5_2539_41a9_aab7_94e960ad77f3/andon_org_tag__b0dbac5c_561c_49a5_832f_fd9d90ed02dc.gz] to file [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_org_tag/andon_org_tag__b0dbac5c_561c_49a5_832f_fd9d90ed02dc.gz].
2021-03-29 18:20:41.012 [job-0] INFO  HdfsWriter$Job - finish rename file [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_org_tag__b158f0b5_2539_41a9_aab7_94e960ad77f3/andon_org_tag__b0dbac5c_561c_49a5_832f_fd9d90ed02dc.gz] to file [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_org_tag/andon_org_tag__b0dbac5c_561c_49a5_832f_fd9d90ed02dc.gz].
2021-03-29 18:20:41.013 [job-0] INFO  HdfsWriter$Job - start delete tmp dir [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_org_tag__b158f0b5_2539_41a9_aab7_94e960ad77f3] .
2021-03-29 18:20:41.025 [job-0] INFO  HdfsWriter$Job - finish delete tmp dir [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_org_tag__b158f0b5_2539_41a9_aab7_94e960ad77f3] .
2021-03-29 18:20:41.026 [job-0] INFO  JobContainer - DataX Reader.Job [mysqlreader] do post work.
2021-03-29 18:20:41.027 [job-0] INFO  JobContainer - DataX jobId [0] completed successfully.
2021-03-29 18:20:41.028 [job-0] INFO  HookInvoker - No hook invoked, because base dir not exists or is a file: /software/datax/hook
2021-03-29 18:20:41.147 [job-0] INFO  JobContainer - 
	 [total cpu info] => 
		averageCpu                     | maxDeltaCpu                    | minDeltaCpu                    
		-1.00%                         | -1.00%                         | -1.00%
                        

	 [total gc info] => 
		 NAME                 | totalGCCount       | maxDeltaGCCount    | minDeltaGCCount    | totalGCTime        | maxDeltaGCTime     | minDeltaGCTime     
		 PS MarkSweep         | 1                  | 1                  | 1                  | 0.105s             | 0.105s             | 0.105s             
		 PS Scavenge          | 1                  | 1                  | 1                  | 0.063s             | 0.063s             | 0.063s             

2021-03-29 18:20:41.147 [job-0] INFO  JobContainer - PerfTrace not enable!
2021-03-29 18:20:41.148 [job-0] INFO  StandAloneJobContainerCommunicator - Total 180 records, 15394 bytes | Speed 1.50KB/s, 18 records/s | Error 0 records, 0 bytes |  All Task WaitWriterTime 0.000s |  All Task WaitReaderTime 0.000s | Percentage 100.00%
2021-03-29 18:20:41.150 [job-0] INFO  JobContainer - 
任务启动时刻                    : 2021-03-29 18:20:27
任务结束时刻                    : 2021-03-29 18:20:41
任务总计耗时                    :                 13s
任务平均流量                    :            1.50KB/s
记录写入速度                    :             18rec/s
读出记录总数                    :                 180
读写失败总数                    :                   0

andon_org_tag表全量同步的结果为0
开始同步一张表
增量配置文件：/software/datax/sync/bin/../conf/jdbc:mysql:192.168.0.124:3306/ziyun-andon.increment
/software/datax/sync/bin/../conf/jdbc:mysql:192.168.0.124:3306/ziyun-andon.increment是文件，进入判断#
maybe_results：
开始全量同步表andon_org_tag_copy1

DataX (DATAX-OPENSOURCE-3.0), From Alibaba !
Copyright (C) 2010-2017, Alibaba Group. All Rights Reserved.


2021-03-29 18:20:42.173 [main] INFO  VMInfo - VMInfo# operatingSystem class => sun.management.OperatingSystemImpl
2021-03-29 18:20:42.183 [main] INFO  Engine - the machine info  => 

	osInfo:	Oracle Corporation 1.8 25.201-b09
	jvmInfo:	Linux amd64 3.10.0-957.el7.x86_64
	cpu num:	16

	totalPhysicalMemory:	-0.00G
	freePhysicalMemory:	-0.00G
	maxFileDescriptorCount:	-1
	currentOpenFileDescriptorCount:	-1

	GC Names	[PS MarkSweep, PS Scavenge]

	MEMORY_NAME                    | allocation_size                | init_size                      
	PS Eden Space                  | 256.00MB                       | 256.00MB                       
	Code Cache                     | 240.00MB                       | 2.44MB                         
	Compressed Class Space         | 1,024.00MB                     | 0.00MB                         
	PS Survivor Space              | 42.50MB                        | 42.50MB                        
	PS Old Gen                     | 683.00MB                       | 683.00MB                       
	Metaspace                      | -0.00MB                        | 0.00MB                         


2021-03-29 18:20:42.212 [main] INFO  Engine - 
{
	"content":[
		{
			"reader":{
				"name":"mysqlreader",
				"parameter":{
					"column":[
						"`tag_id`",
						"`org_tag_name`",
						"`org_hcode`",
						"`tombstone`",
						"`create_sso`",
						"`create_dt`",
						"`update_sso`",
						"`update_dt`"
					],
					"connection":[
						{
							"jdbcUrl":[
								"jdbc:mysql://192.168.0.124:3306/ziyun-andon"
							],
							"table":[
								"andon_org_tag_copy1"
							]
						}
					],
					"password":"********",
					"username":"ziyunIot",
					"where":"1=1"
				}
			},
			"writer":{
				"name":"hdfswriter",
				"parameter":{
					"column":[
						{
							"name":"`tag_id`",
							"type":"BIGINT"
						},
						{
							"name":"`org_tag_name`",
							"type":"STRING"
						},
						{
							"name":"`org_hcode`",
							"type":"STRING"
						},
						{
							"name":"`tombstone`",
							"type":"STRING"
						},
						{
							"name":"`create_sso`",
							"type":"STRING"
						},
						{
							"name":"`create_dt`",
							"type":"DATE"
						},
						{
							"name":"`update_sso`",
							"type":"STRING"
						},
						{
							"name":"`update_dt`",
							"type":"DATE"
						}
					],
					"compress":"gzip",
					"defaultFS":"hdfs://nameservice1",
					"fieldDelimiter":"\t",
					"fileName":"andon_org_tag_copy1",
					"fileType":"text",
					"hadoopConfig":{
						"dfs.client.failover.proxy.provider.nameservice1":"org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider",
						"dfs.ha.namenodes.nameservice1":"nn1,nn2",
						"dfs.namenode.rpc-address.nameservice1.nn1":"ziyunbd01:8020",
						"dfs.namenode.rpc-address.nameservice1.nn2":"ziyunbd02:8020",
						"dfs.nameservices":"nameservice1"
					},
					"path":"/user/hive/warehouse/mysql_ziyun_andon/andon_org_tag_copy1",
					"writeMode":"append"
				}
			}
		}
	],
	"setting":{
		"speed":{
			"channel":"3"
		}
	}
}

2021-03-29 18:20:42.237 [main] WARN  Engine - prioriy set to 0, because NumberFormatException, the value is: null
2021-03-29 18:20:42.239 [main] INFO  PerfTrace - PerfTrace traceId=job_-1, isEnable=false, priority=0
2021-03-29 18:20:42.240 [main] INFO  JobContainer - DataX jobContainer starts job.
2021-03-29 18:20:42.242 [main] INFO  JobContainer - Set jobId = 0
2021-03-29 18:20:42.711 [job-0] INFO  OriginalConfPretreatmentUtil - Available jdbcUrl:jdbc:mysql://192.168.0.124:3306/ziyun-andon?yearIsDateType=false&zeroDateTimeBehavior=convertToNull&tinyInt1isBit=false&rewriteBatchedStatements=true.
2021-03-29 18:20:42.741 [job-0] INFO  OriginalConfPretreatmentUtil - table:[andon_org_tag_copy1] has columns:[tag_id,org_tag_name,org_hcode,tombstone,create_sso,create_dt,update_sso,update_dt].
Mar 29, 2021 6:20:43 PM org.apache.hadoop.util.NativeCodeLoader <clinit>
WARNING: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-03-29 18:20:44.423 [job-0] INFO  JobContainer - jobContainer starts to do prepare ...
2021-03-29 18:20:44.424 [job-0] INFO  JobContainer - DataX Reader.Job [mysqlreader] do prepare work .
2021-03-29 18:20:44.425 [job-0] INFO  JobContainer - DataX Writer.Job [hdfswriter] do prepare work .
2021-03-29 18:20:44.564 [job-0] INFO  HdfsWriter$Job - 由于您配置了writeMode append, 写入前不做清理工作, [/user/hive/warehouse/mysql_ziyun_andon/andon_org_tag_copy1] 目录下写入相应文件名前缀  [andon_org_tag_copy1] 的文件
2021-03-29 18:20:44.564 [job-0] INFO  JobContainer - jobContainer starts to do split ...
2021-03-29 18:20:44.565 [job-0] INFO  JobContainer - Job set Channel-Number to 3 channels.
2021-03-29 18:20:44.570 [job-0] INFO  JobContainer - DataX Reader.Job [mysqlreader] splits to [1] tasks.
2021-03-29 18:20:44.571 [job-0] INFO  HdfsWriter$Job - begin do split...
2021-03-29 18:20:44.577 [job-0] INFO  HdfsWriter$Job - splited write file name:[hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_org_tag_copy1__87edf8be_2a5e_4172_9ded_a7de701336d1/andon_org_tag_copy1__ea60f162_2347_4c43_81be_4856a857f7c3]
2021-03-29 18:20:44.577 [job-0] INFO  HdfsWriter$Job - end do split.
2021-03-29 18:20:44.577 [job-0] INFO  JobContainer - DataX Writer.Job [hdfswriter] splits to [1] tasks.
2021-03-29 18:20:44.602 [job-0] INFO  JobContainer - jobContainer starts to do schedule ...
2021-03-29 18:20:44.607 [job-0] INFO  JobContainer - Scheduler starts [1] taskGroups.
2021-03-29 18:20:44.610 [job-0] INFO  JobContainer - Running by standalone Mode.
2021-03-29 18:20:44.625 [taskGroup-0] INFO  TaskGroupContainer - taskGroupId=[0] start [1] channels for [1] tasks.
2021-03-29 18:20:44.631 [taskGroup-0] INFO  Channel - Channel set byte_speed_limit to -1, No bps activated.
2021-03-29 18:20:44.631 [taskGroup-0] INFO  Channel - Channel set record_speed_limit to -1, No tps activated.
2021-03-29 18:20:44.648 [taskGroup-0] INFO  TaskGroupContainer - taskGroup[0] taskId[0] attemptCount[1] is started
2021-03-29 18:20:44.660 [0-0-0-reader] INFO  CommonRdbmsReader$Task - Begin to read record by Sql: [select `tag_id`,`org_tag_name`,`org_hcode`,`tombstone`,`create_sso`,`create_dt`,`update_sso`,`update_dt` from andon_org_tag_copy1 where (1=1)
] jdbcUrl:[jdbc:mysql://192.168.0.124:3306/ziyun-andon?yearIsDateType=false&zeroDateTimeBehavior=convertToNull&tinyInt1isBit=false&rewriteBatchedStatements=true].
2021-03-29 18:20:44.697 [0-0-0-writer] INFO  HdfsWriter$Task - begin do write...
2021-03-29 18:20:44.698 [0-0-0-writer] INFO  HdfsWriter$Task - write to file : [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_org_tag_copy1__87edf8be_2a5e_4172_9ded_a7de701336d1/andon_org_tag_copy1__ea60f162_2347_4c43_81be_4856a857f7c3]
2021-03-29 18:20:44.772 [0-0-0-reader] INFO  CommonRdbmsReader$Task - Finished read record by Sql: [select `tag_id`,`org_tag_name`,`org_hcode`,`tombstone`,`create_sso`,`create_dt`,`update_sso`,`update_dt` from andon_org_tag_copy1 where (1=1)
] jdbcUrl:[jdbc:mysql://192.168.0.124:3306/ziyun-andon?yearIsDateType=false&zeroDateTimeBehavior=convertToNull&tinyInt1isBit=false&rewriteBatchedStatements=true].
2021-03-29 18:20:45.062 [0-0-0-writer] INFO  HdfsWriter$Task - end do write
2021-03-29 18:20:45.154 [taskGroup-0] INFO  TaskGroupContainer - taskGroup[0] taskId[0] is successed, used[508]ms
2021-03-29 18:20:45.155 [taskGroup-0] INFO  TaskGroupContainer - taskGroup[0] completed it's tasks.
2021-03-29 18:20:54.668 [job-0] INFO  StandAloneJobContainerCommunicator - Total 168 records, 8973 bytes | Speed 897B/s, 16 records/s | Error 0 records, 0 bytes |  All Task WaitWriterTime 0.001s |  All Task WaitReaderTime 0.000s | Percentage 100.00%
2021-03-29 18:20:54.670 [job-0] INFO  AbstractScheduler - Scheduler accomplished all tasks.
2021-03-29 18:20:54.672 [job-0] INFO  JobContainer - DataX Writer.Job [hdfswriter] do post work.
2021-03-29 18:20:54.673 [job-0] INFO  HdfsWriter$Job - start rename file [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_org_tag_copy1__87edf8be_2a5e_4172_9ded_a7de701336d1/andon_org_tag_copy1__ea60f162_2347_4c43_81be_4856a857f7c3.gz] to file [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_org_tag_copy1/andon_org_tag_copy1__ea60f162_2347_4c43_81be_4856a857f7c3.gz].
2021-03-29 18:20:54.694 [job-0] INFO  HdfsWriter$Job - finish rename file [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_org_tag_copy1__87edf8be_2a5e_4172_9ded_a7de701336d1/andon_org_tag_copy1__ea60f162_2347_4c43_81be_4856a857f7c3.gz] to file [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_org_tag_copy1/andon_org_tag_copy1__ea60f162_2347_4c43_81be_4856a857f7c3.gz].
2021-03-29 18:20:54.695 [job-0] INFO  HdfsWriter$Job - start delete tmp dir [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_org_tag_copy1__87edf8be_2a5e_4172_9ded_a7de701336d1] .
2021-03-29 18:20:54.711 [job-0] INFO  HdfsWriter$Job - finish delete tmp dir [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_org_tag_copy1__87edf8be_2a5e_4172_9ded_a7de701336d1] .
2021-03-29 18:20:54.712 [job-0] INFO  JobContainer - DataX Reader.Job [mysqlreader] do post work.
2021-03-29 18:20:54.713 [job-0] INFO  JobContainer - DataX jobId [0] completed successfully.
2021-03-29 18:20:54.716 [job-0] INFO  HookInvoker - No hook invoked, because base dir not exists or is a file: /software/datax/hook
2021-03-29 18:20:54.822 [job-0] INFO  JobContainer - 
	 [total cpu info] => 
		averageCpu                     | maxDeltaCpu                    | minDeltaCpu                    
		-1.00%                         | -1.00%                         | -1.00%
                        

	 [total gc info] => 
		 NAME                 | totalGCCount       | maxDeltaGCCount    | minDeltaGCCount    | totalGCTime        | maxDeltaGCTime     | minDeltaGCTime     
		 PS MarkSweep         | 1                  | 1                  | 1                  | 0.078s             | 0.078s             | 0.078s             
		 PS Scavenge          | 1                  | 1                  | 1                  | 0.025s             | 0.025s             | 0.025s             

2021-03-29 18:20:54.822 [job-0] INFO  JobContainer - PerfTrace not enable!
2021-03-29 18:20:54.823 [job-0] INFO  StandAloneJobContainerCommunicator - Total 168 records, 8973 bytes | Speed 897B/s, 16 records/s | Error 0 records, 0 bytes |  All Task WaitWriterTime 0.001s |  All Task WaitReaderTime 0.000s | Percentage 100.00%
2021-03-29 18:20:54.827 [job-0] INFO  JobContainer - 
任务启动时刻                    : 2021-03-29 18:20:42
任务结束时刻                    : 2021-03-29 18:20:54
任务总计耗时                    :                 12s
任务平均流量                    :              897B/s
记录写入速度                    :             16rec/s
读出记录总数                    :                 168
读写失败总数                    :                   0

andon_org_tag_copy1表全量同步的结果为0
开始同步一张表
增量配置文件：/software/datax/sync/bin/../conf/jdbc:mysql:192.168.0.124:3306/ziyun-andon.increment
/software/datax/sync/bin/../conf/jdbc:mysql:192.168.0.124:3306/ziyun-andon.increment是文件，进入判断#
maybe_results：
开始全量同步表andon_record_fault_middle

DataX (DATAX-OPENSOURCE-3.0), From Alibaba !
Copyright (C) 2010-2017, Alibaba Group. All Rights Reserved.


2021-03-29 18:20:56.030 [main] INFO  VMInfo - VMInfo# operatingSystem class => sun.management.OperatingSystemImpl
2021-03-29 18:20:56.044 [main] INFO  Engine - the machine info  => 

	osInfo:	Oracle Corporation 1.8 25.201-b09
	jvmInfo:	Linux amd64 3.10.0-957.el7.x86_64
	cpu num:	16

	totalPhysicalMemory:	-0.00G
	freePhysicalMemory:	-0.00G
	maxFileDescriptorCount:	-1
	currentOpenFileDescriptorCount:	-1

	GC Names	[PS MarkSweep, PS Scavenge]

	MEMORY_NAME                    | allocation_size                | init_size                      
	PS Eden Space                  | 256.00MB                       | 256.00MB                       
	Code Cache                     | 240.00MB                       | 2.44MB                         
	Compressed Class Space         | 1,024.00MB                     | 0.00MB                         
	PS Survivor Space              | 42.50MB                        | 42.50MB                        
	PS Old Gen                     | 683.00MB                       | 683.00MB                       
	Metaspace                      | -0.00MB                        | 0.00MB                         


2021-03-29 18:20:56.086 [main] INFO  Engine - 
{
	"content":[
		{
			"reader":{
				"name":"mysqlreader",
				"parameter":{
					"column":[
						"`id`",
						"`record_id`",
						"`fault_id`"
					],
					"connection":[
						{
							"jdbcUrl":[
								"jdbc:mysql://192.168.0.124:3306/ziyun-andon"
							],
							"table":[
								"andon_record_fault_middle"
							]
						}
					],
					"password":"********",
					"username":"ziyunIot",
					"where":"1=1"
				}
			},
			"writer":{
				"name":"hdfswriter",
				"parameter":{
					"column":[
						{
							"name":"`id`",
							"type":"BIGINT"
						},
						{
							"name":"`record_id`",
							"type":"BIGINT"
						},
						{
							"name":"`fault_id`",
							"type":"BIGINT"
						}
					],
					"compress":"gzip",
					"defaultFS":"hdfs://nameservice1",
					"fieldDelimiter":"\t",
					"fileName":"andon_record_fault_middle",
					"fileType":"text",
					"hadoopConfig":{
						"dfs.client.failover.proxy.provider.nameservice1":"org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider",
						"dfs.ha.namenodes.nameservice1":"nn1,nn2",
						"dfs.namenode.rpc-address.nameservice1.nn1":"ziyunbd01:8020",
						"dfs.namenode.rpc-address.nameservice1.nn2":"ziyunbd02:8020",
						"dfs.nameservices":"nameservice1"
					},
					"path":"/user/hive/warehouse/mysql_ziyun_andon/andon_record_fault_middle",
					"writeMode":"append"
				}
			}
		}
	],
	"setting":{
		"speed":{
			"channel":"3"
		}
	}
}

2021-03-29 18:20:56.123 [main] WARN  Engine - prioriy set to 0, because NumberFormatException, the value is: null
2021-03-29 18:20:56.127 [main] INFO  PerfTrace - PerfTrace traceId=job_-1, isEnable=false, priority=0
2021-03-29 18:20:56.127 [main] INFO  JobContainer - DataX jobContainer starts job.
2021-03-29 18:20:56.131 [main] INFO  JobContainer - Set jobId = 0
2021-03-29 18:20:56.690 [job-0] INFO  OriginalConfPretreatmentUtil - Available jdbcUrl:jdbc:mysql://192.168.0.124:3306/ziyun-andon?yearIsDateType=false&zeroDateTimeBehavior=convertToNull&tinyInt1isBit=false&rewriteBatchedStatements=true.
2021-03-29 18:20:56.718 [job-0] INFO  OriginalConfPretreatmentUtil - table:[andon_record_fault_middle] has columns:[id,record_id,fault_id].
Mar 29, 2021 6:20:57 PM org.apache.hadoop.util.NativeCodeLoader <clinit>
WARNING: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-03-29 18:20:58.619 [job-0] INFO  JobContainer - jobContainer starts to do prepare ...
2021-03-29 18:20:58.621 [job-0] INFO  JobContainer - DataX Reader.Job [mysqlreader] do prepare work .
2021-03-29 18:20:58.622 [job-0] INFO  JobContainer - DataX Writer.Job [hdfswriter] do prepare work .
2021-03-29 18:20:58.789 [job-0] INFO  HdfsWriter$Job - 由于您配置了writeMode append, 写入前不做清理工作, [/user/hive/warehouse/mysql_ziyun_andon/andon_record_fault_middle] 目录下写入相应文件名前缀  [andon_record_fault_middle] 的文件
2021-03-29 18:20:58.789 [job-0] INFO  JobContainer - jobContainer starts to do split ...
2021-03-29 18:20:58.790 [job-0] INFO  JobContainer - Job set Channel-Number to 3 channels.
2021-03-29 18:20:58.796 [job-0] INFO  JobContainer - DataX Reader.Job [mysqlreader] splits to [1] tasks.
2021-03-29 18:20:58.797 [job-0] INFO  HdfsWriter$Job - begin do split...
2021-03-29 18:20:58.802 [job-0] INFO  HdfsWriter$Job - splited write file name:[hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_record_fault_middle__02cbec9d_88bc_4f2b_ad06_1f676d18313d/andon_record_fault_middle__8ee7df1c_13a6_48da_bf1f_47dcb5e4932c]
2021-03-29 18:20:58.803 [job-0] INFO  HdfsWriter$Job - end do split.
2021-03-29 18:20:58.803 [job-0] INFO  JobContainer - DataX Writer.Job [hdfswriter] splits to [1] tasks.
2021-03-29 18:20:58.830 [job-0] INFO  JobContainer - jobContainer starts to do schedule ...
2021-03-29 18:20:58.835 [job-0] INFO  JobContainer - Scheduler starts [1] taskGroups.
2021-03-29 18:20:58.839 [job-0] INFO  JobContainer - Running by standalone Mode.
2021-03-29 18:20:58.851 [taskGroup-0] INFO  TaskGroupContainer - taskGroupId=[0] start [1] channels for [1] tasks.
2021-03-29 18:20:58.859 [taskGroup-0] INFO  Channel - Channel set byte_speed_limit to -1, No bps activated.
2021-03-29 18:20:58.860 [taskGroup-0] INFO  Channel - Channel set record_speed_limit to -1, No tps activated.
2021-03-29 18:20:58.875 [taskGroup-0] INFO  TaskGroupContainer - taskGroup[0] taskId[0] attemptCount[1] is started
2021-03-29 18:20:58.881 [0-0-0-reader] INFO  CommonRdbmsReader$Task - Begin to read record by Sql: [select `id`,`record_id`,`fault_id` from andon_record_fault_middle where (1=1)
] jdbcUrl:[jdbc:mysql://192.168.0.124:3306/ziyun-andon?yearIsDateType=false&zeroDateTimeBehavior=convertToNull&tinyInt1isBit=false&rewriteBatchedStatements=true].
2021-03-29 18:20:58.938 [0-0-0-reader] INFO  CommonRdbmsReader$Task - Finished read record by Sql: [select `id`,`record_id`,`fault_id` from andon_record_fault_middle where (1=1)
] jdbcUrl:[jdbc:mysql://192.168.0.124:3306/ziyun-andon?yearIsDateType=false&zeroDateTimeBehavior=convertToNull&tinyInt1isBit=false&rewriteBatchedStatements=true].
2021-03-29 18:20:58.940 [0-0-0-writer] INFO  HdfsWriter$Task - begin do write...
2021-03-29 18:20:58.940 [0-0-0-writer] INFO  HdfsWriter$Task - write to file : [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_record_fault_middle__02cbec9d_88bc_4f2b_ad06_1f676d18313d/andon_record_fault_middle__8ee7df1c_13a6_48da_bf1f_47dcb5e4932c]
2021-03-29 18:20:59.354 [0-0-0-writer] INFO  HdfsWriter$Task - end do write
2021-03-29 18:20:59.381 [taskGroup-0] INFO  TaskGroupContainer - taskGroup[0] taskId[0] is successed, used[508]ms
2021-03-29 18:20:59.382 [taskGroup-0] INFO  TaskGroupContainer - taskGroup[0] completed it's tasks.
2021-03-29 18:21:08.873 [job-0] INFO  StandAloneJobContainerCommunicator - Total 354 records, 2573 bytes | Speed 257B/s, 35 records/s | Error 0 records, 0 bytes |  All Task WaitWriterTime 0.001s |  All Task WaitReaderTime 0.000s | Percentage 100.00%
2021-03-29 18:21:08.874 [job-0] INFO  AbstractScheduler - Scheduler accomplished all tasks.
2021-03-29 18:21:08.874 [job-0] INFO  JobContainer - DataX Writer.Job [hdfswriter] do post work.
2021-03-29 18:21:08.875 [job-0] INFO  HdfsWriter$Job - start rename file [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_record_fault_middle__02cbec9d_88bc_4f2b_ad06_1f676d18313d/andon_record_fault_middle__8ee7df1c_13a6_48da_bf1f_47dcb5e4932c.gz] to file [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_record_fault_middle/andon_record_fault_middle__8ee7df1c_13a6_48da_bf1f_47dcb5e4932c.gz].
2021-03-29 18:21:08.888 [job-0] INFO  HdfsWriter$Job - finish rename file [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_record_fault_middle__02cbec9d_88bc_4f2b_ad06_1f676d18313d/andon_record_fault_middle__8ee7df1c_13a6_48da_bf1f_47dcb5e4932c.gz] to file [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_record_fault_middle/andon_record_fault_middle__8ee7df1c_13a6_48da_bf1f_47dcb5e4932c.gz].
2021-03-29 18:21:08.889 [job-0] INFO  HdfsWriter$Job - start delete tmp dir [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_record_fault_middle__02cbec9d_88bc_4f2b_ad06_1f676d18313d] .
2021-03-29 18:21:08.900 [job-0] INFO  HdfsWriter$Job - finish delete tmp dir [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_record_fault_middle__02cbec9d_88bc_4f2b_ad06_1f676d18313d] .
2021-03-29 18:21:08.901 [job-0] INFO  JobContainer - DataX Reader.Job [mysqlreader] do post work.
2021-03-29 18:21:08.901 [job-0] INFO  JobContainer - DataX jobId [0] completed successfully.
2021-03-29 18:21:08.903 [job-0] INFO  HookInvoker - No hook invoked, because base dir not exists or is a file: /software/datax/hook
2021-03-29 18:21:09.007 [job-0] INFO  JobContainer - 
	 [total cpu info] => 
		averageCpu                     | maxDeltaCpu                    | minDeltaCpu                    
		-1.00%                         | -1.00%                         | -1.00%
                        

	 [total gc info] => 
		 NAME                 | totalGCCount       | maxDeltaGCCount    | minDeltaGCCount    | totalGCTime        | maxDeltaGCTime     | minDeltaGCTime     
		 PS MarkSweep         | 1                  | 1                  | 1                  | 0.053s             | 0.053s             | 0.053s             
		 PS Scavenge          | 1                  | 1                  | 1                  | 0.031s             | 0.031s             | 0.031s             

2021-03-29 18:21:09.007 [job-0] INFO  JobContainer - PerfTrace not enable!
2021-03-29 18:21:09.008 [job-0] INFO  StandAloneJobContainerCommunicator - Total 354 records, 2573 bytes | Speed 257B/s, 35 records/s | Error 0 records, 0 bytes |  All Task WaitWriterTime 0.001s |  All Task WaitReaderTime 0.000s | Percentage 100.00%
2021-03-29 18:21:09.011 [job-0] INFO  JobContainer - 
任务启动时刻                    : 2021-03-29 18:20:56
任务结束时刻                    : 2021-03-29 18:21:09
任务总计耗时                    :                 12s
任务平均流量                    :              257B/s
记录写入速度                    :             35rec/s
读出记录总数                    :                 354
读写失败总数                    :                   0

andon_record_fault_middle表全量同步的结果为0
开始同步一张表
增量配置文件：/software/datax/sync/bin/../conf/jdbc:mysql:192.168.0.124:3306/ziyun-andon.increment
/software/datax/sync/bin/../conf/jdbc:mysql:192.168.0.124:3306/ziyun-andon.increment是文件，进入判断#
maybe_results：
开始全量同步表andon_record_fault_middle_copy1

DataX (DATAX-OPENSOURCE-3.0), From Alibaba !
Copyright (C) 2010-2017, Alibaba Group. All Rights Reserved.


2021-03-29 18:21:09.933 [main] INFO  VMInfo - VMInfo# operatingSystem class => sun.management.OperatingSystemImpl
2021-03-29 18:21:09.947 [main] INFO  Engine - the machine info  => 

	osInfo:	Oracle Corporation 1.8 25.201-b09
	jvmInfo:	Linux amd64 3.10.0-957.el7.x86_64
	cpu num:	16

	totalPhysicalMemory:	-0.00G
	freePhysicalMemory:	-0.00G
	maxFileDescriptorCount:	-1
	currentOpenFileDescriptorCount:	-1

	GC Names	[PS MarkSweep, PS Scavenge]

	MEMORY_NAME                    | allocation_size                | init_size                      
	PS Eden Space                  | 256.00MB                       | 256.00MB                       
	Code Cache                     | 240.00MB                       | 2.44MB                         
	Compressed Class Space         | 1,024.00MB                     | 0.00MB                         
	PS Survivor Space              | 42.50MB                        | 42.50MB                        
	PS Old Gen                     | 683.00MB                       | 683.00MB                       
	Metaspace                      | -0.00MB                        | 0.00MB                         


2021-03-29 18:21:09.987 [main] INFO  Engine - 
{
	"content":[
		{
			"reader":{
				"name":"mysqlreader",
				"parameter":{
					"column":[
						"`id`",
						"`record_id`",
						"`fault_id`"
					],
					"connection":[
						{
							"jdbcUrl":[
								"jdbc:mysql://192.168.0.124:3306/ziyun-andon"
							],
							"table":[
								"andon_record_fault_middle_copy1"
							]
						}
					],
					"password":"********",
					"username":"ziyunIot",
					"where":"1=1"
				}
			},
			"writer":{
				"name":"hdfswriter",
				"parameter":{
					"column":[
						{
							"name":"`id`",
							"type":"BIGINT"
						},
						{
							"name":"`record_id`",
							"type":"BIGINT"
						},
						{
							"name":"`fault_id`",
							"type":"BIGINT"
						}
					],
					"compress":"gzip",
					"defaultFS":"hdfs://nameservice1",
					"fieldDelimiter":"\t",
					"fileName":"andon_record_fault_middle_copy1",
					"fileType":"text",
					"hadoopConfig":{
						"dfs.client.failover.proxy.provider.nameservice1":"org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider",
						"dfs.ha.namenodes.nameservice1":"nn1,nn2",
						"dfs.namenode.rpc-address.nameservice1.nn1":"ziyunbd01:8020",
						"dfs.namenode.rpc-address.nameservice1.nn2":"ziyunbd02:8020",
						"dfs.nameservices":"nameservice1"
					},
					"path":"/user/hive/warehouse/mysql_ziyun_andon/andon_record_fault_middle_copy1",
					"writeMode":"append"
				}
			}
		}
	],
	"setting":{
		"speed":{
			"channel":"3"
		}
	}
}

2021-03-29 18:21:10.027 [main] WARN  Engine - prioriy set to 0, because NumberFormatException, the value is: null
2021-03-29 18:21:10.031 [main] INFO  PerfTrace - PerfTrace traceId=job_-1, isEnable=false, priority=0
2021-03-29 18:21:10.031 [main] INFO  JobContainer - DataX jobContainer starts job.
2021-03-29 18:21:10.035 [main] INFO  JobContainer - Set jobId = 0
2021-03-29 18:21:10.749 [job-0] INFO  OriginalConfPretreatmentUtil - Available jdbcUrl:jdbc:mysql://192.168.0.124:3306/ziyun-andon?yearIsDateType=false&zeroDateTimeBehavior=convertToNull&tinyInt1isBit=false&rewriteBatchedStatements=true.
2021-03-29 18:21:10.772 [job-0] INFO  OriginalConfPretreatmentUtil - table:[andon_record_fault_middle_copy1] has columns:[id,record_id,fault_id].
Mar 29, 2021 6:21:11 PM org.apache.hadoop.util.NativeCodeLoader <clinit>
WARNING: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-03-29 18:21:12.618 [job-0] INFO  JobContainer - jobContainer starts to do prepare ...
2021-03-29 18:21:12.620 [job-0] INFO  JobContainer - DataX Reader.Job [mysqlreader] do prepare work .
2021-03-29 18:21:12.621 [job-0] INFO  JobContainer - DataX Writer.Job [hdfswriter] do prepare work .
2021-03-29 18:21:12.803 [job-0] INFO  HdfsWriter$Job - 由于您配置了writeMode append, 写入前不做清理工作, [/user/hive/warehouse/mysql_ziyun_andon/andon_record_fault_middle_copy1] 目录下写入相应文件名前缀  [andon_record_fault_middle_copy1] 的文件
2021-03-29 18:21:12.803 [job-0] INFO  JobContainer - jobContainer starts to do split ...
2021-03-29 18:21:12.804 [job-0] INFO  JobContainer - Job set Channel-Number to 3 channels.
2021-03-29 18:21:12.812 [job-0] INFO  JobContainer - DataX Reader.Job [mysqlreader] splits to [1] tasks.
2021-03-29 18:21:12.813 [job-0] INFO  HdfsWriter$Job - begin do split...
2021-03-29 18:21:12.820 [job-0] INFO  HdfsWriter$Job - splited write file name:[hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_record_fault_middle_copy1__7e0fb15c_4286_4de1_8e9c_0ff6459a5b9b/andon_record_fault_middle_copy1__ed3d79a4_dc1d_4d32_a4ad_651f3ebb0058]
2021-03-29 18:21:12.820 [job-0] INFO  HdfsWriter$Job - end do split.
2021-03-29 18:21:12.821 [job-0] INFO  JobContainer - DataX Writer.Job [hdfswriter] splits to [1] tasks.
2021-03-29 18:21:12.858 [job-0] INFO  JobContainer - jobContainer starts to do schedule ...
2021-03-29 18:21:12.870 [job-0] INFO  JobContainer - Scheduler starts [1] taskGroups.
2021-03-29 18:21:12.875 [job-0] INFO  JobContainer - Running by standalone Mode.
2021-03-29 18:21:12.886 [taskGroup-0] INFO  TaskGroupContainer - taskGroupId=[0] start [1] channels for [1] tasks.
2021-03-29 18:21:12.893 [taskGroup-0] INFO  Channel - Channel set byte_speed_limit to -1, No bps activated.
2021-03-29 18:21:12.893 [taskGroup-0] INFO  Channel - Channel set record_speed_limit to -1, No tps activated.
2021-03-29 18:21:12.909 [taskGroup-0] INFO  TaskGroupContainer - taskGroup[0] taskId[0] attemptCount[1] is started
2021-03-29 18:21:12.916 [0-0-0-reader] INFO  CommonRdbmsReader$Task - Begin to read record by Sql: [select `id`,`record_id`,`fault_id` from andon_record_fault_middle_copy1 where (1=1)
] jdbcUrl:[jdbc:mysql://192.168.0.124:3306/ziyun-andon?yearIsDateType=false&zeroDateTimeBehavior=convertToNull&tinyInt1isBit=false&rewriteBatchedStatements=true].
2021-03-29 18:21:12.956 [0-0-0-writer] INFO  HdfsWriter$Task - begin do write...
2021-03-29 18:21:12.956 [0-0-0-writer] INFO  HdfsWriter$Task - write to file : [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_record_fault_middle_copy1__7e0fb15c_4286_4de1_8e9c_0ff6459a5b9b/andon_record_fault_middle_copy1__ed3d79a4_dc1d_4d32_a4ad_651f3ebb0058]
2021-03-29 18:21:12.969 [0-0-0-reader] INFO  CommonRdbmsReader$Task - Finished read record by Sql: [select `id`,`record_id`,`fault_id` from andon_record_fault_middle_copy1 where (1=1)
] jdbcUrl:[jdbc:mysql://192.168.0.124:3306/ziyun-andon?yearIsDateType=false&zeroDateTimeBehavior=convertToNull&tinyInt1isBit=false&rewriteBatchedStatements=true].
2021-03-29 18:21:13.365 [0-0-0-writer] INFO  HdfsWriter$Task - end do write
2021-03-29 18:21:13.412 [taskGroup-0] INFO  TaskGroupContainer - taskGroup[0] taskId[0] is successed, used[505]ms
2021-03-29 18:21:13.413 [taskGroup-0] INFO  TaskGroupContainer - taskGroup[0] completed it's tasks.
2021-03-29 18:21:22.909 [job-0] INFO  StandAloneJobContainerCommunicator - Total 326 records, 2338 bytes | Speed 233B/s, 32 records/s | Error 0 records, 0 bytes |  All Task WaitWriterTime 0.001s |  All Task WaitReaderTime 0.000s | Percentage 100.00%
2021-03-29 18:21:22.909 [job-0] INFO  AbstractScheduler - Scheduler accomplished all tasks.
2021-03-29 18:21:22.910 [job-0] INFO  JobContainer - DataX Writer.Job [hdfswriter] do post work.
2021-03-29 18:21:22.911 [job-0] INFO  HdfsWriter$Job - start rename file [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_record_fault_middle_copy1__7e0fb15c_4286_4de1_8e9c_0ff6459a5b9b/andon_record_fault_middle_copy1__ed3d79a4_dc1d_4d32_a4ad_651f3ebb0058.gz] to file [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_record_fault_middle_copy1/andon_record_fault_middle_copy1__ed3d79a4_dc1d_4d32_a4ad_651f3ebb0058.gz].
2021-03-29 18:21:22.923 [job-0] INFO  HdfsWriter$Job - finish rename file [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_record_fault_middle_copy1__7e0fb15c_4286_4de1_8e9c_0ff6459a5b9b/andon_record_fault_middle_copy1__ed3d79a4_dc1d_4d32_a4ad_651f3ebb0058.gz] to file [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_record_fault_middle_copy1/andon_record_fault_middle_copy1__ed3d79a4_dc1d_4d32_a4ad_651f3ebb0058.gz].
2021-03-29 18:21:22.923 [job-0] INFO  HdfsWriter$Job - start delete tmp dir [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_record_fault_middle_copy1__7e0fb15c_4286_4de1_8e9c_0ff6459a5b9b] .
2021-03-29 18:21:22.935 [job-0] INFO  HdfsWriter$Job - finish delete tmp dir [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_record_fault_middle_copy1__7e0fb15c_4286_4de1_8e9c_0ff6459a5b9b] .
2021-03-29 18:21:22.935 [job-0] INFO  JobContainer - DataX Reader.Job [mysqlreader] do post work.
2021-03-29 18:21:22.935 [job-0] INFO  JobContainer - DataX jobId [0] completed successfully.
2021-03-29 18:21:22.937 [job-0] INFO  HookInvoker - No hook invoked, because base dir not exists or is a file: /software/datax/hook
2021-03-29 18:21:23.040 [job-0] INFO  JobContainer - 
	 [total cpu info] => 
		averageCpu                     | maxDeltaCpu                    | minDeltaCpu                    
		-1.00%                         | -1.00%                         | -1.00%
                        

	 [total gc info] => 
		 NAME                 | totalGCCount       | maxDeltaGCCount    | minDeltaGCCount    | totalGCTime        | maxDeltaGCTime     | minDeltaGCTime     
		 PS MarkSweep         | 1                  | 1                  | 1                  | 0.050s             | 0.050s             | 0.050s             
		 PS Scavenge          | 1                  | 1                  | 1                  | 0.038s             | 0.038s             | 0.038s             

2021-03-29 18:21:23.041 [job-0] INFO  JobContainer - PerfTrace not enable!
2021-03-29 18:21:23.043 [job-0] INFO  StandAloneJobContainerCommunicator - Total 326 records, 2338 bytes | Speed 233B/s, 32 records/s | Error 0 records, 0 bytes |  All Task WaitWriterTime 0.001s |  All Task WaitReaderTime 0.000s | Percentage 100.00%
2021-03-29 18:21:23.046 [job-0] INFO  JobContainer - 
任务启动时刻                    : 2021-03-29 18:21:10
任务结束时刻                    : 2021-03-29 18:21:23
任务总计耗时                    :                 13s
任务平均流量                    :              233B/s
记录写入速度                    :             32rec/s
读出记录总数                    :                 326
读写失败总数                    :                   0

andon_record_fault_middle_copy1表全量同步的结果为0
开始同步一张表
增量配置文件：/software/datax/sync/bin/../conf/jdbc:mysql:192.168.0.124:3306/ziyun-andon.increment
/software/datax/sync/bin/../conf/jdbc:mysql:192.168.0.124:3306/ziyun-andon.increment是文件，进入判断#
maybe_results：
开始全量同步表andon_sso_tag

DataX (DATAX-OPENSOURCE-3.0), From Alibaba !
Copyright (C) 2010-2017, Alibaba Group. All Rights Reserved.


2021-03-29 18:21:23.976 [main] INFO  VMInfo - VMInfo# operatingSystem class => sun.management.OperatingSystemImpl
2021-03-29 18:21:23.990 [main] INFO  Engine - the machine info  => 

	osInfo:	Oracle Corporation 1.8 25.201-b09
	jvmInfo:	Linux amd64 3.10.0-957.el7.x86_64
	cpu num:	16

	totalPhysicalMemory:	-0.00G
	freePhysicalMemory:	-0.00G
	maxFileDescriptorCount:	-1
	currentOpenFileDescriptorCount:	-1

	GC Names	[PS MarkSweep, PS Scavenge]

	MEMORY_NAME                    | allocation_size                | init_size                      
	PS Eden Space                  | 256.00MB                       | 256.00MB                       
	Code Cache                     | 240.00MB                       | 2.44MB                         
	Compressed Class Space         | 1,024.00MB                     | 0.00MB                         
	PS Survivor Space              | 42.50MB                        | 42.50MB                        
	PS Old Gen                     | 683.00MB                       | 683.00MB                       
	Metaspace                      | -0.00MB                        | 0.00MB                         


2021-03-29 18:21:24.035 [main] INFO  Engine - 
{
	"content":[
		{
			"reader":{
				"name":"mysqlreader",
				"parameter":{
					"column":[
						"`id`",
						"`andon_ssoid`",
						"`tag_id`",
						"`sso_tag_name`",
						"`tombstone`",
						"`domain_id`",
						"`create_dt`",
						"`update_dt`"
					],
					"connection":[
						{
							"jdbcUrl":[
								"jdbc:mysql://192.168.0.124:3306/ziyun-andon"
							],
							"table":[
								"andon_sso_tag"
							]
						}
					],
					"password":"********",
					"username":"ziyunIot",
					"where":"1=1"
				}
			},
			"writer":{
				"name":"hdfswriter",
				"parameter":{
					"column":[
						{
							"name":"`id`",
							"type":"BIGINT"
						},
						{
							"name":"`andon_ssoid`",
							"type":"STRING"
						},
						{
							"name":"`tag_id`",
							"type":"BIGINT"
						},
						{
							"name":"`sso_tag_name`",
							"type":"STRING"
						},
						{
							"name":"`tombstone`",
							"type":"STRING"
						},
						{
							"name":"`domain_id`",
							"type":"STRING"
						},
						{
							"name":"`create_dt`",
							"type":"DATE"
						},
						{
							"name":"`update_dt`",
							"type":"DATE"
						}
					],
					"compress":"gzip",
					"defaultFS":"hdfs://nameservice1",
					"fieldDelimiter":"\t",
					"fileName":"andon_sso_tag",
					"fileType":"text",
					"hadoopConfig":{
						"dfs.client.failover.proxy.provider.nameservice1":"org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider",
						"dfs.ha.namenodes.nameservice1":"nn1,nn2",
						"dfs.namenode.rpc-address.nameservice1.nn1":"ziyunbd01:8020",
						"dfs.namenode.rpc-address.nameservice1.nn2":"ziyunbd02:8020",
						"dfs.nameservices":"nameservice1"
					},
					"path":"/user/hive/warehouse/mysql_ziyun_andon/andon_sso_tag",
					"writeMode":"append"
				}
			}
		}
	],
	"setting":{
		"speed":{
			"channel":"3"
		}
	}
}

2021-03-29 18:21:24.074 [main] WARN  Engine - prioriy set to 0, because NumberFormatException, the value is: null
2021-03-29 18:21:24.078 [main] INFO  PerfTrace - PerfTrace traceId=job_-1, isEnable=false, priority=0
2021-03-29 18:21:24.078 [main] INFO  JobContainer - DataX jobContainer starts job.
2021-03-29 18:21:24.082 [main] INFO  JobContainer - Set jobId = 0
2021-03-29 18:21:24.624 [job-0] INFO  OriginalConfPretreatmentUtil - Available jdbcUrl:jdbc:mysql://192.168.0.124:3306/ziyun-andon?yearIsDateType=false&zeroDateTimeBehavior=convertToNull&tinyInt1isBit=false&rewriteBatchedStatements=true.
2021-03-29 18:21:24.654 [job-0] INFO  OriginalConfPretreatmentUtil - table:[andon_sso_tag] has columns:[id,andon_ssoid,tag_id,sso_tag_name,tombstone,domain_id,create_dt,update_dt].
Mar 29, 2021 6:21:25 PM org.apache.hadoop.util.NativeCodeLoader <clinit>
WARNING: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-03-29 18:21:26.204 [job-0] INFO  JobContainer - jobContainer starts to do prepare ...
2021-03-29 18:21:26.205 [job-0] INFO  JobContainer - DataX Reader.Job [mysqlreader] do prepare work .
2021-03-29 18:21:26.206 [job-0] INFO  JobContainer - DataX Writer.Job [hdfswriter] do prepare work .
2021-03-29 18:21:26.397 [job-0] INFO  HdfsWriter$Job - 由于您配置了writeMode append, 写入前不做清理工作, [/user/hive/warehouse/mysql_ziyun_andon/andon_sso_tag] 目录下写入相应文件名前缀  [andon_sso_tag] 的文件
2021-03-29 18:21:26.398 [job-0] INFO  JobContainer - jobContainer starts to do split ...
2021-03-29 18:21:26.399 [job-0] INFO  JobContainer - Job set Channel-Number to 3 channels.
2021-03-29 18:21:26.408 [job-0] INFO  JobContainer - DataX Reader.Job [mysqlreader] splits to [1] tasks.
2021-03-29 18:21:26.409 [job-0] INFO  HdfsWriter$Job - begin do split...
2021-03-29 18:21:26.417 [job-0] INFO  HdfsWriter$Job - splited write file name:[hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_sso_tag__ab6b7bcc_280c_425e_920a_bc023bed044f/andon_sso_tag__bc1a5cac_2bd7_4ce6_9ca4_e97b508eb8ca]
2021-03-29 18:21:26.417 [job-0] INFO  HdfsWriter$Job - end do split.
2021-03-29 18:21:26.417 [job-0] INFO  JobContainer - DataX Writer.Job [hdfswriter] splits to [1] tasks.
2021-03-29 18:21:26.455 [job-0] INFO  JobContainer - jobContainer starts to do schedule ...
2021-03-29 18:21:26.463 [job-0] INFO  JobContainer - Scheduler starts [1] taskGroups.
2021-03-29 18:21:26.479 [job-0] INFO  JobContainer - Running by standalone Mode.
2021-03-29 18:21:26.501 [taskGroup-0] INFO  TaskGroupContainer - taskGroupId=[0] start [1] channels for [1] tasks.
2021-03-29 18:21:26.517 [taskGroup-0] INFO  Channel - Channel set byte_speed_limit to -1, No bps activated.
2021-03-29 18:21:26.518 [taskGroup-0] INFO  Channel - Channel set record_speed_limit to -1, No tps activated.
2021-03-29 18:21:26.538 [taskGroup-0] INFO  TaskGroupContainer - taskGroup[0] taskId[0] attemptCount[1] is started
2021-03-29 18:21:26.548 [0-0-0-reader] INFO  CommonRdbmsReader$Task - Begin to read record by Sql: [select `id`,`andon_ssoid`,`tag_id`,`sso_tag_name`,`tombstone`,`domain_id`,`create_dt`,`update_dt` from andon_sso_tag where (1=1)
] jdbcUrl:[jdbc:mysql://192.168.0.124:3306/ziyun-andon?yearIsDateType=false&zeroDateTimeBehavior=convertToNull&tinyInt1isBit=false&rewriteBatchedStatements=true].
2021-03-29 18:21:26.613 [0-0-0-writer] INFO  HdfsWriter$Task - begin do write...
2021-03-29 18:21:26.613 [0-0-0-writer] INFO  HdfsWriter$Task - write to file : [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_sso_tag__ab6b7bcc_280c_425e_920a_bc023bed044f/andon_sso_tag__bc1a5cac_2bd7_4ce6_9ca4_e97b508eb8ca]
2021-03-29 18:21:26.634 [0-0-0-reader] INFO  CommonRdbmsReader$Task - Finished read record by Sql: [select `id`,`andon_ssoid`,`tag_id`,`sso_tag_name`,`tombstone`,`domain_id`,`create_dt`,`update_dt` from andon_sso_tag where (1=1)
] jdbcUrl:[jdbc:mysql://192.168.0.124:3306/ziyun-andon?yearIsDateType=false&zeroDateTimeBehavior=convertToNull&tinyInt1isBit=false&rewriteBatchedStatements=true].
2021-03-29 18:21:26.984 [0-0-0-writer] INFO  HdfsWriter$Task - end do write
2021-03-29 18:21:27.041 [taskGroup-0] INFO  TaskGroupContainer - taskGroup[0] taskId[0] is successed, used[504]ms
2021-03-29 18:21:27.042 [taskGroup-0] INFO  TaskGroupContainer - taskGroup[0] completed it's tasks.
2021-03-29 18:21:36.541 [job-0] INFO  StandAloneJobContainerCommunicator - Total 169 records, 11994 bytes | Speed 1.17KB/s, 16 records/s | Error 0 records, 0 bytes |  All Task WaitWriterTime 0.001s |  All Task WaitReaderTime 0.000s | Percentage 100.00%
2021-03-29 18:21:36.541 [job-0] INFO  AbstractScheduler - Scheduler accomplished all tasks.
2021-03-29 18:21:36.542 [job-0] INFO  JobContainer - DataX Writer.Job [hdfswriter] do post work.
2021-03-29 18:21:36.543 [job-0] INFO  HdfsWriter$Job - start rename file [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_sso_tag__ab6b7bcc_280c_425e_920a_bc023bed044f/andon_sso_tag__bc1a5cac_2bd7_4ce6_9ca4_e97b508eb8ca.gz] to file [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_sso_tag/andon_sso_tag__bc1a5cac_2bd7_4ce6_9ca4_e97b508eb8ca.gz].
2021-03-29 18:21:36.555 [job-0] INFO  HdfsWriter$Job - finish rename file [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_sso_tag__ab6b7bcc_280c_425e_920a_bc023bed044f/andon_sso_tag__bc1a5cac_2bd7_4ce6_9ca4_e97b508eb8ca.gz] to file [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_sso_tag/andon_sso_tag__bc1a5cac_2bd7_4ce6_9ca4_e97b508eb8ca.gz].
2021-03-29 18:21:36.555 [job-0] INFO  HdfsWriter$Job - start delete tmp dir [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_sso_tag__ab6b7bcc_280c_425e_920a_bc023bed044f] .
2021-03-29 18:21:36.567 [job-0] INFO  HdfsWriter$Job - finish delete tmp dir [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_sso_tag__ab6b7bcc_280c_425e_920a_bc023bed044f] .
2021-03-29 18:21:36.567 [job-0] INFO  JobContainer - DataX Reader.Job [mysqlreader] do post work.
2021-03-29 18:21:36.568 [job-0] INFO  JobContainer - DataX jobId [0] completed successfully.
2021-03-29 18:21:36.569 [job-0] INFO  HookInvoker - No hook invoked, because base dir not exists or is a file: /software/datax/hook
2021-03-29 18:21:36.673 [job-0] INFO  JobContainer - 
	 [total cpu info] => 
		averageCpu                     | maxDeltaCpu                    | minDeltaCpu                    
		-1.00%                         | -1.00%                         | -1.00%
                        

	 [total gc info] => 
		 NAME                 | totalGCCount       | maxDeltaGCCount    | minDeltaGCCount    | totalGCTime        | maxDeltaGCTime     | minDeltaGCTime     
		 PS MarkSweep         | 1                  | 1                  | 1                  | 0.060s             | 0.060s             | 0.060s             
		 PS Scavenge          | 1                  | 1                  | 1                  | 0.040s             | 0.040s             | 0.040s             

2021-03-29 18:21:36.674 [job-0] INFO  JobContainer - PerfTrace not enable!
2021-03-29 18:21:36.675 [job-0] INFO  StandAloneJobContainerCommunicator - Total 169 records, 11994 bytes | Speed 1.17KB/s, 16 records/s | Error 0 records, 0 bytes |  All Task WaitWriterTime 0.001s |  All Task WaitReaderTime 0.000s | Percentage 100.00%
2021-03-29 18:21:36.678 [job-0] INFO  JobContainer - 
任务启动时刻                    : 2021-03-29 18:21:24
任务结束时刻                    : 2021-03-29 18:21:36
任务总计耗时                    :                 12s
任务平均流量                    :            1.17KB/s
记录写入速度                    :             16rec/s
读出记录总数                    :                 169
读写失败总数                    :                   0

andon_sso_tag表全量同步的结果为0
开始同步一张表
增量配置文件：/software/datax/sync/bin/../conf/jdbc:mysql:192.168.0.124:3306/ziyun-andon.increment
/software/datax/sync/bin/../conf/jdbc:mysql:192.168.0.124:3306/ziyun-andon.increment是文件，进入判断#
maybe_results：
开始全量同步表andon_sso_tag_copy1

DataX (DATAX-OPENSOURCE-3.0), From Alibaba !
Copyright (C) 2010-2017, Alibaba Group. All Rights Reserved.


2021-03-29 18:21:37.707 [main] INFO  VMInfo - VMInfo# operatingSystem class => sun.management.OperatingSystemImpl
2021-03-29 18:21:37.723 [main] INFO  Engine - the machine info  => 

	osInfo:	Oracle Corporation 1.8 25.201-b09
	jvmInfo:	Linux amd64 3.10.0-957.el7.x86_64
	cpu num:	16

	totalPhysicalMemory:	-0.00G
	freePhysicalMemory:	-0.00G
	maxFileDescriptorCount:	-1
	currentOpenFileDescriptorCount:	-1

	GC Names	[PS MarkSweep, PS Scavenge]

	MEMORY_NAME                    | allocation_size                | init_size                      
	PS Eden Space                  | 256.00MB                       | 256.00MB                       
	Code Cache                     | 240.00MB                       | 2.44MB                         
	Compressed Class Space         | 1,024.00MB                     | 0.00MB                         
	PS Survivor Space              | 42.50MB                        | 42.50MB                        
	PS Old Gen                     | 683.00MB                       | 683.00MB                       
	Metaspace                      | -0.00MB                        | 0.00MB                         


2021-03-29 18:21:37.766 [main] INFO  Engine - 
{
	"content":[
		{
			"reader":{
				"name":"mysqlreader",
				"parameter":{
					"column":[
						"`id`",
						"`andon_ssoid`",
						"`tag_id`",
						"`sso_tag_name`",
						"`tombstone`",
						"`create_dt`",
						"`update_dt`"
					],
					"connection":[
						{
							"jdbcUrl":[
								"jdbc:mysql://192.168.0.124:3306/ziyun-andon"
							],
							"table":[
								"andon_sso_tag_copy1"
							]
						}
					],
					"password":"********",
					"username":"ziyunIot",
					"where":"1=1"
				}
			},
			"writer":{
				"name":"hdfswriter",
				"parameter":{
					"column":[
						{
							"name":"`id`",
							"type":"BIGINT"
						},
						{
							"name":"`andon_ssoid`",
							"type":"STRING"
						},
						{
							"name":"`tag_id`",
							"type":"BIGINT"
						},
						{
							"name":"`sso_tag_name`",
							"type":"STRING"
						},
						{
							"name":"`tombstone`",
							"type":"STRING"
						},
						{
							"name":"`create_dt`",
							"type":"DATE"
						},
						{
							"name":"`update_dt`",
							"type":"DATE"
						}
					],
					"compress":"gzip",
					"defaultFS":"hdfs://nameservice1",
					"fieldDelimiter":"\t",
					"fileName":"andon_sso_tag_copy1",
					"fileType":"text",
					"hadoopConfig":{
						"dfs.client.failover.proxy.provider.nameservice1":"org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider",
						"dfs.ha.namenodes.nameservice1":"nn1,nn2",
						"dfs.namenode.rpc-address.nameservice1.nn1":"ziyunbd01:8020",
						"dfs.namenode.rpc-address.nameservice1.nn2":"ziyunbd02:8020",
						"dfs.nameservices":"nameservice1"
					},
					"path":"/user/hive/warehouse/mysql_ziyun_andon/andon_sso_tag_copy1",
					"writeMode":"append"
				}
			}
		}
	],
	"setting":{
		"speed":{
			"channel":"3"
		}
	}
}

2021-03-29 18:21:37.803 [main] WARN  Engine - prioriy set to 0, because NumberFormatException, the value is: null
2021-03-29 18:21:37.807 [main] INFO  PerfTrace - PerfTrace traceId=job_-1, isEnable=false, priority=0
2021-03-29 18:21:37.808 [main] INFO  JobContainer - DataX jobContainer starts job.
2021-03-29 18:21:37.812 [main] INFO  JobContainer - Set jobId = 0
2021-03-29 18:21:38.326 [job-0] INFO  OriginalConfPretreatmentUtil - Available jdbcUrl:jdbc:mysql://192.168.0.124:3306/ziyun-andon?yearIsDateType=false&zeroDateTimeBehavior=convertToNull&tinyInt1isBit=false&rewriteBatchedStatements=true.
2021-03-29 18:21:38.350 [job-0] INFO  OriginalConfPretreatmentUtil - table:[andon_sso_tag_copy1] has columns:[id,andon_ssoid,tag_id,sso_tag_name,tombstone,create_dt,update_dt].
Mar 29, 2021 6:21:39 PM org.apache.hadoop.util.NativeCodeLoader <clinit>
WARNING: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-03-29 18:21:40.298 [job-0] INFO  JobContainer - jobContainer starts to do prepare ...
2021-03-29 18:21:40.300 [job-0] INFO  JobContainer - DataX Reader.Job [mysqlreader] do prepare work .
2021-03-29 18:21:40.300 [job-0] INFO  JobContainer - DataX Writer.Job [hdfswriter] do prepare work .
2021-03-29 18:21:40.468 [job-0] INFO  HdfsWriter$Job - 由于您配置了writeMode append, 写入前不做清理工作, [/user/hive/warehouse/mysql_ziyun_andon/andon_sso_tag_copy1] 目录下写入相应文件名前缀  [andon_sso_tag_copy1] 的文件
2021-03-29 18:21:40.468 [job-0] INFO  JobContainer - jobContainer starts to do split ...
2021-03-29 18:21:40.469 [job-0] INFO  JobContainer - Job set Channel-Number to 3 channels.
2021-03-29 18:21:40.476 [job-0] INFO  JobContainer - DataX Reader.Job [mysqlreader] splits to [1] tasks.
2021-03-29 18:21:40.477 [job-0] INFO  HdfsWriter$Job - begin do split...
2021-03-29 18:21:40.485 [job-0] INFO  HdfsWriter$Job - splited write file name:[hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_sso_tag_copy1__4ea01ccc_5346_4b85_8f0e_69fb8546ca35/andon_sso_tag_copy1__97e9663a_f8c8_4518_8f18_816c8bdd9fbe]
2021-03-29 18:21:40.486 [job-0] INFO  HdfsWriter$Job - end do split.
2021-03-29 18:21:40.486 [job-0] INFO  JobContainer - DataX Writer.Job [hdfswriter] splits to [1] tasks.
2021-03-29 18:21:40.520 [job-0] INFO  JobContainer - jobContainer starts to do schedule ...
2021-03-29 18:21:40.527 [job-0] INFO  JobContainer - Scheduler starts [1] taskGroups.
2021-03-29 18:21:40.531 [job-0] INFO  JobContainer - Running by standalone Mode.
2021-03-29 18:21:40.541 [taskGroup-0] INFO  TaskGroupContainer - taskGroupId=[0] start [1] channels for [1] tasks.
2021-03-29 18:21:40.549 [taskGroup-0] INFO  Channel - Channel set byte_speed_limit to -1, No bps activated.
2021-03-29 18:21:40.549 [taskGroup-0] INFO  Channel - Channel set record_speed_limit to -1, No tps activated.
2021-03-29 18:21:40.565 [taskGroup-0] INFO  TaskGroupContainer - taskGroup[0] taskId[0] attemptCount[1] is started
2021-03-29 18:21:40.572 [0-0-0-reader] INFO  CommonRdbmsReader$Task - Begin to read record by Sql: [select `id`,`andon_ssoid`,`tag_id`,`sso_tag_name`,`tombstone`,`create_dt`,`update_dt` from andon_sso_tag_copy1 where (1=1)
] jdbcUrl:[jdbc:mysql://192.168.0.124:3306/ziyun-andon?yearIsDateType=false&zeroDateTimeBehavior=convertToNull&tinyInt1isBit=false&rewriteBatchedStatements=true].
2021-03-29 18:21:40.623 [0-0-0-writer] INFO  HdfsWriter$Task - begin do write...
2021-03-29 18:21:40.624 [0-0-0-writer] INFO  HdfsWriter$Task - write to file : [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_sso_tag_copy1__4ea01ccc_5346_4b85_8f0e_69fb8546ca35/andon_sso_tag_copy1__97e9663a_f8c8_4518_8f18_816c8bdd9fbe]
2021-03-29 18:21:40.639 [0-0-0-reader] INFO  CommonRdbmsReader$Task - Finished read record by Sql: [select `id`,`andon_ssoid`,`tag_id`,`sso_tag_name`,`tombstone`,`create_dt`,`update_dt` from andon_sso_tag_copy1 where (1=1)
] jdbcUrl:[jdbc:mysql://192.168.0.124:3306/ziyun-andon?yearIsDateType=false&zeroDateTimeBehavior=convertToNull&tinyInt1isBit=false&rewriteBatchedStatements=true].
2021-03-29 18:21:41.012 [0-0-0-writer] INFO  HdfsWriter$Task - end do write
2021-03-29 18:21:41.069 [taskGroup-0] INFO  TaskGroupContainer - taskGroup[0] taskId[0] is successed, used[506]ms
2021-03-29 18:21:41.070 [taskGroup-0] INFO  TaskGroupContainer - taskGroup[0] completed it's tasks.
2021-03-29 18:21:50.561 [job-0] INFO  StandAloneJobContainerCommunicator - Total 128 records, 4944 bytes | Speed 494B/s, 12 records/s | Error 0 records, 0 bytes |  All Task WaitWriterTime 0.001s |  All Task WaitReaderTime 0.000s | Percentage 100.00%
2021-03-29 18:21:50.562 [job-0] INFO  AbstractScheduler - Scheduler accomplished all tasks.
2021-03-29 18:21:50.562 [job-0] INFO  JobContainer - DataX Writer.Job [hdfswriter] do post work.
2021-03-29 18:21:50.563 [job-0] INFO  HdfsWriter$Job - start rename file [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_sso_tag_copy1__4ea01ccc_5346_4b85_8f0e_69fb8546ca35/andon_sso_tag_copy1__97e9663a_f8c8_4518_8f18_816c8bdd9fbe.gz] to file [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_sso_tag_copy1/andon_sso_tag_copy1__97e9663a_f8c8_4518_8f18_816c8bdd9fbe.gz].
2021-03-29 18:21:50.578 [job-0] INFO  HdfsWriter$Job - finish rename file [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_sso_tag_copy1__4ea01ccc_5346_4b85_8f0e_69fb8546ca35/andon_sso_tag_copy1__97e9663a_f8c8_4518_8f18_816c8bdd9fbe.gz] to file [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_sso_tag_copy1/andon_sso_tag_copy1__97e9663a_f8c8_4518_8f18_816c8bdd9fbe.gz].
2021-03-29 18:21:50.579 [job-0] INFO  HdfsWriter$Job - start delete tmp dir [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_sso_tag_copy1__4ea01ccc_5346_4b85_8f0e_69fb8546ca35] .
2021-03-29 18:21:50.590 [job-0] INFO  HdfsWriter$Job - finish delete tmp dir [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_sso_tag_copy1__4ea01ccc_5346_4b85_8f0e_69fb8546ca35] .
2021-03-29 18:21:50.590 [job-0] INFO  JobContainer - DataX Reader.Job [mysqlreader] do post work.
2021-03-29 18:21:50.590 [job-0] INFO  JobContainer - DataX jobId [0] completed successfully.
2021-03-29 18:21:50.591 [job-0] INFO  HookInvoker - No hook invoked, because base dir not exists or is a file: /software/datax/hook
2021-03-29 18:21:50.695 [job-0] INFO  JobContainer - 
	 [total cpu info] => 
		averageCpu                     | maxDeltaCpu                    | minDeltaCpu                    
		-1.00%                         | -1.00%                         | -1.00%
                        

	 [total gc info] => 
		 NAME                 | totalGCCount       | maxDeltaGCCount    | minDeltaGCCount    | totalGCTime        | maxDeltaGCTime     | minDeltaGCTime     
		 PS MarkSweep         | 1                  | 1                  | 1                  | 0.057s             | 0.057s             | 0.057s             
		 PS Scavenge          | 1                  | 1                  | 1                  | 0.039s             | 0.039s             | 0.039s             

2021-03-29 18:21:50.695 [job-0] INFO  JobContainer - PerfTrace not enable!
2021-03-29 18:21:50.696 [job-0] INFO  StandAloneJobContainerCommunicator - Total 128 records, 4944 bytes | Speed 494B/s, 12 records/s | Error 0 records, 0 bytes |  All Task WaitWriterTime 0.001s |  All Task WaitReaderTime 0.000s | Percentage 100.00%
2021-03-29 18:21:50.698 [job-0] INFO  JobContainer - 
任务启动时刻                    : 2021-03-29 18:21:37
任务结束时刻                    : 2021-03-29 18:21:50
任务总计耗时                    :                 12s
任务平均流量                    :              494B/s
记录写入速度                    :             12rec/s
读出记录总数                    :                 128
读写失败总数                    :                   0

andon_sso_tag_copy1表全量同步的结果为0
开始同步一张表
增量配置文件：/software/datax/sync/bin/../conf/jdbc:mysql:192.168.0.124:3306/ziyun-andon.increment
/software/datax/sync/bin/../conf/jdbc:mysql:192.168.0.124:3306/ziyun-andon.increment是文件，进入判断#
maybe_results：
开始全量同步表andon_tag

DataX (DATAX-OPENSOURCE-3.0), From Alibaba !
Copyright (C) 2010-2017, Alibaba Group. All Rights Reserved.


2021-03-29 18:21:51.790 [main] INFO  VMInfo - VMInfo# operatingSystem class => sun.management.OperatingSystemImpl
2021-03-29 18:21:51.806 [main] INFO  Engine - the machine info  => 

	osInfo:	Oracle Corporation 1.8 25.201-b09
	jvmInfo:	Linux amd64 3.10.0-957.el7.x86_64
	cpu num:	16

	totalPhysicalMemory:	-0.00G
	freePhysicalMemory:	-0.00G
	maxFileDescriptorCount:	-1
	currentOpenFileDescriptorCount:	-1

	GC Names	[PS MarkSweep, PS Scavenge]

	MEMORY_NAME                    | allocation_size                | init_size                      
	PS Eden Space                  | 256.00MB                       | 256.00MB                       
	Code Cache                     | 240.00MB                       | 2.44MB                         
	Compressed Class Space         | 1,024.00MB                     | 0.00MB                         
	PS Survivor Space              | 42.50MB                        | 42.50MB                        
	PS Old Gen                     | 683.00MB                       | 683.00MB                       
	Metaspace                      | -0.00MB                        | 0.00MB                         


2021-03-29 18:21:51.850 [main] INFO  Engine - 
{
	"content":[
		{
			"reader":{
				"name":"mysqlreader",
				"parameter":{
					"column":[
						"`id`",
						"`tag_name`",
						"`tombstone`",
						"`domain_id`",
						"`create_dt`",
						"`update_dt`",
						"`create_sso`"
					],
					"connection":[
						{
							"jdbcUrl":[
								"jdbc:mysql://192.168.0.124:3306/ziyun-andon"
							],
							"table":[
								"andon_tag"
							]
						}
					],
					"password":"********",
					"username":"ziyunIot",
					"where":"1=1"
				}
			},
			"writer":{
				"name":"hdfswriter",
				"parameter":{
					"column":[
						{
							"name":"`id`",
							"type":"BIGINT"
						},
						{
							"name":"`tag_name`",
							"type":"STRING"
						},
						{
							"name":"`tombstone`",
							"type":"STRING"
						},
						{
							"name":"`domain_id`",
							"type":"STRING"
						},
						{
							"name":"`create_dt`",
							"type":"DATE"
						},
						{
							"name":"`update_dt`",
							"type":"DATE"
						},
						{
							"name":"`create_sso`",
							"type":"STRING"
						}
					],
					"compress":"gzip",
					"defaultFS":"hdfs://nameservice1",
					"fieldDelimiter":"\t",
					"fileName":"andon_tag",
					"fileType":"text",
					"hadoopConfig":{
						"dfs.client.failover.proxy.provider.nameservice1":"org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider",
						"dfs.ha.namenodes.nameservice1":"nn1,nn2",
						"dfs.namenode.rpc-address.nameservice1.nn1":"ziyunbd01:8020",
						"dfs.namenode.rpc-address.nameservice1.nn2":"ziyunbd02:8020",
						"dfs.nameservices":"nameservice1"
					},
					"path":"/user/hive/warehouse/mysql_ziyun_andon/andon_tag",
					"writeMode":"append"
				}
			}
		}
	],
	"setting":{
		"speed":{
			"channel":"3"
		}
	}
}

2021-03-29 18:21:51.888 [main] WARN  Engine - prioriy set to 0, because NumberFormatException, the value is: null
2021-03-29 18:21:51.892 [main] INFO  PerfTrace - PerfTrace traceId=job_-1, isEnable=false, priority=0
2021-03-29 18:21:51.892 [main] INFO  JobContainer - DataX jobContainer starts job.
2021-03-29 18:21:51.899 [main] INFO  JobContainer - Set jobId = 0
2021-03-29 18:21:52.450 [job-0] INFO  OriginalConfPretreatmentUtil - Available jdbcUrl:jdbc:mysql://192.168.0.124:3306/ziyun-andon?yearIsDateType=false&zeroDateTimeBehavior=convertToNull&tinyInt1isBit=false&rewriteBatchedStatements=true.
2021-03-29 18:21:52.483 [job-0] INFO  OriginalConfPretreatmentUtil - table:[andon_tag] has columns:[id,tag_name,tombstone,domain_id,create_dt,update_dt,create_sso].
Mar 29, 2021 6:21:53 PM org.apache.hadoop.util.NativeCodeLoader <clinit>
WARNING: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-03-29 18:21:54.413 [job-0] INFO  JobContainer - jobContainer starts to do prepare ...
2021-03-29 18:21:54.415 [job-0] INFO  JobContainer - DataX Reader.Job [mysqlreader] do prepare work .
2021-03-29 18:21:54.416 [job-0] INFO  JobContainer - DataX Writer.Job [hdfswriter] do prepare work .
2021-03-29 18:21:54.607 [job-0] INFO  HdfsWriter$Job - 由于您配置了writeMode append, 写入前不做清理工作, [/user/hive/warehouse/mysql_ziyun_andon/andon_tag] 目录下写入相应文件名前缀  [andon_tag] 的文件
2021-03-29 18:21:54.607 [job-0] INFO  JobContainer - jobContainer starts to do split ...
2021-03-29 18:21:54.608 [job-0] INFO  JobContainer - Job set Channel-Number to 3 channels.
2021-03-29 18:21:54.616 [job-0] INFO  JobContainer - DataX Reader.Job [mysqlreader] splits to [1] tasks.
2021-03-29 18:21:54.617 [job-0] INFO  HdfsWriter$Job - begin do split...
2021-03-29 18:21:54.624 [job-0] INFO  HdfsWriter$Job - splited write file name:[hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_tag__cc3b0b31_9a4d_4c27_8be7_8b3dbf23fb2e/andon_tag__5576bcdf_bb9a_46a3_9086_72da1f1edee8]
2021-03-29 18:21:54.624 [job-0] INFO  HdfsWriter$Job - end do split.
2021-03-29 18:21:54.625 [job-0] INFO  JobContainer - DataX Writer.Job [hdfswriter] splits to [1] tasks.
2021-03-29 18:21:54.660 [job-0] INFO  JobContainer - jobContainer starts to do schedule ...
2021-03-29 18:21:54.667 [job-0] INFO  JobContainer - Scheduler starts [1] taskGroups.
2021-03-29 18:21:54.672 [job-0] INFO  JobContainer - Running by standalone Mode.
2021-03-29 18:21:54.684 [taskGroup-0] INFO  TaskGroupContainer - taskGroupId=[0] start [1] channels for [1] tasks.
2021-03-29 18:21:54.692 [taskGroup-0] INFO  Channel - Channel set byte_speed_limit to -1, No bps activated.
2021-03-29 18:21:54.693 [taskGroup-0] INFO  Channel - Channel set record_speed_limit to -1, No tps activated.
2021-03-29 18:21:54.712 [taskGroup-0] INFO  TaskGroupContainer - taskGroup[0] taskId[0] attemptCount[1] is started
2021-03-29 18:21:54.722 [0-0-0-reader] INFO  CommonRdbmsReader$Task - Begin to read record by Sql: [select `id`,`tag_name`,`tombstone`,`domain_id`,`create_dt`,`update_dt`,`create_sso` from andon_tag where (1=1)
] jdbcUrl:[jdbc:mysql://192.168.0.124:3306/ziyun-andon?yearIsDateType=false&zeroDateTimeBehavior=convertToNull&tinyInt1isBit=false&rewriteBatchedStatements=true].
2021-03-29 18:21:54.758 [0-0-0-reader] INFO  CommonRdbmsReader$Task - Finished read record by Sql: [select `id`,`tag_name`,`tombstone`,`domain_id`,`create_dt`,`update_dt`,`create_sso` from andon_tag where (1=1)
] jdbcUrl:[jdbc:mysql://192.168.0.124:3306/ziyun-andon?yearIsDateType=false&zeroDateTimeBehavior=convertToNull&tinyInt1isBit=false&rewriteBatchedStatements=true].
2021-03-29 18:21:54.776 [0-0-0-writer] INFO  HdfsWriter$Task - begin do write...
2021-03-29 18:21:54.776 [0-0-0-writer] INFO  HdfsWriter$Task - write to file : [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_tag__cc3b0b31_9a4d_4c27_8be7_8b3dbf23fb2e/andon_tag__5576bcdf_bb9a_46a3_9086_72da1f1edee8]
2021-03-29 18:21:55.178 [0-0-0-writer] INFO  HdfsWriter$Task - end do write
2021-03-29 18:21:55.214 [taskGroup-0] INFO  TaskGroupContainer - taskGroup[0] taskId[0] is successed, used[504]ms
2021-03-29 18:21:55.215 [taskGroup-0] INFO  TaskGroupContainer - taskGroup[0] completed it's tasks.
2021-03-29 18:22:04.705 [job-0] INFO  StandAloneJobContainerCommunicator - Total 18 records, 963 bytes | Speed 96B/s, 1 records/s | Error 0 records, 0 bytes |  All Task WaitWriterTime 0.000s |  All Task WaitReaderTime 0.000s | Percentage 100.00%
2021-03-29 18:22:04.706 [job-0] INFO  AbstractScheduler - Scheduler accomplished all tasks.
2021-03-29 18:22:04.706 [job-0] INFO  JobContainer - DataX Writer.Job [hdfswriter] do post work.
2021-03-29 18:22:04.707 [job-0] INFO  HdfsWriter$Job - start rename file [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_tag__cc3b0b31_9a4d_4c27_8be7_8b3dbf23fb2e/andon_tag__5576bcdf_bb9a_46a3_9086_72da1f1edee8.gz] to file [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_tag/andon_tag__5576bcdf_bb9a_46a3_9086_72da1f1edee8.gz].
2021-03-29 18:22:04.719 [job-0] INFO  HdfsWriter$Job - finish rename file [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_tag__cc3b0b31_9a4d_4c27_8be7_8b3dbf23fb2e/andon_tag__5576bcdf_bb9a_46a3_9086_72da1f1edee8.gz] to file [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_tag/andon_tag__5576bcdf_bb9a_46a3_9086_72da1f1edee8.gz].
2021-03-29 18:22:04.720 [job-0] INFO  HdfsWriter$Job - start delete tmp dir [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_tag__cc3b0b31_9a4d_4c27_8be7_8b3dbf23fb2e] .
2021-03-29 18:22:04.731 [job-0] INFO  HdfsWriter$Job - finish delete tmp dir [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_tag__cc3b0b31_9a4d_4c27_8be7_8b3dbf23fb2e] .
2021-03-29 18:22:04.732 [job-0] INFO  JobContainer - DataX Reader.Job [mysqlreader] do post work.
2021-03-29 18:22:04.732 [job-0] INFO  JobContainer - DataX jobId [0] completed successfully.
2021-03-29 18:22:04.733 [job-0] INFO  HookInvoker - No hook invoked, because base dir not exists or is a file: /software/datax/hook
2021-03-29 18:22:04.837 [job-0] INFO  JobContainer - 
	 [total cpu info] => 
		averageCpu                     | maxDeltaCpu                    | minDeltaCpu                    
		-1.00%                         | -1.00%                         | -1.00%
                        

	 [total gc info] => 
		 NAME                 | totalGCCount       | maxDeltaGCCount    | minDeltaGCCount    | totalGCTime        | maxDeltaGCTime     | minDeltaGCTime     
		 PS MarkSweep         | 1                  | 1                  | 1                  | 0.070s             | 0.070s             | 0.070s             
		 PS Scavenge          | 1                  | 1                  | 1                  | 0.043s             | 0.043s             | 0.043s             

2021-03-29 18:22:04.838 [job-0] INFO  JobContainer - PerfTrace not enable!
2021-03-29 18:22:04.839 [job-0] INFO  StandAloneJobContainerCommunicator - Total 18 records, 963 bytes | Speed 96B/s, 1 records/s | Error 0 records, 0 bytes |  All Task WaitWriterTime 0.000s |  All Task WaitReaderTime 0.000s | Percentage 100.00%
2021-03-29 18:22:04.841 [job-0] INFO  JobContainer - 
任务启动时刻                    : 2021-03-29 18:21:51
任务结束时刻                    : 2021-03-29 18:22:04
任务总计耗时                    :                 12s
任务平均流量                    :               96B/s
记录写入速度                    :              1rec/s
读出记录总数                    :                  18
读写失败总数                    :                   0

andon_tag表全量同步的结果为0
开始同步一张表
增量配置文件：/software/datax/sync/bin/../conf/jdbc:mysql:192.168.0.124:3306/ziyun-andon.increment
/software/datax/sync/bin/../conf/jdbc:mysql:192.168.0.124:3306/ziyun-andon.increment是文件，进入判断#
maybe_results：
开始全量同步表andon_tag_copy1

DataX (DATAX-OPENSOURCE-3.0), From Alibaba !
Copyright (C) 2010-2017, Alibaba Group. All Rights Reserved.


2021-03-29 18:22:05.919 [main] INFO  VMInfo - VMInfo# operatingSystem class => sun.management.OperatingSystemImpl
2021-03-29 18:22:05.933 [main] INFO  Engine - the machine info  => 

	osInfo:	Oracle Corporation 1.8 25.201-b09
	jvmInfo:	Linux amd64 3.10.0-957.el7.x86_64
	cpu num:	16

	totalPhysicalMemory:	-0.00G
	freePhysicalMemory:	-0.00G
	maxFileDescriptorCount:	-1
	currentOpenFileDescriptorCount:	-1

	GC Names	[PS MarkSweep, PS Scavenge]

	MEMORY_NAME                    | allocation_size                | init_size                      
	PS Eden Space                  | 256.00MB                       | 256.00MB                       
	Code Cache                     | 240.00MB                       | 2.44MB                         
	Compressed Class Space         | 1,024.00MB                     | 0.00MB                         
	PS Survivor Space              | 42.50MB                        | 42.50MB                        
	PS Old Gen                     | 683.00MB                       | 683.00MB                       
	Metaspace                      | -0.00MB                        | 0.00MB                         


2021-03-29 18:22:05.984 [main] INFO  Engine - 
{
	"content":[
		{
			"reader":{
				"name":"mysqlreader",
				"parameter":{
					"column":[
						"`id`",
						"`tag_name`",
						"`tombstone`",
						"`create_dt`",
						"`update_dt`",
						"`create_sso`"
					],
					"connection":[
						{
							"jdbcUrl":[
								"jdbc:mysql://192.168.0.124:3306/ziyun-andon"
							],
							"table":[
								"andon_tag_copy1"
							]
						}
					],
					"password":"********",
					"username":"ziyunIot",
					"where":"1=1"
				}
			},
			"writer":{
				"name":"hdfswriter",
				"parameter":{
					"column":[
						{
							"name":"`id`",
							"type":"BIGINT"
						},
						{
							"name":"`tag_name`",
							"type":"STRING"
						},
						{
							"name":"`tombstone`",
							"type":"STRING"
						},
						{
							"name":"`create_dt`",
							"type":"DATE"
						},
						{
							"name":"`update_dt`",
							"type":"DATE"
						},
						{
							"name":"`create_sso`",
							"type":"STRING"
						}
					],
					"compress":"gzip",
					"defaultFS":"hdfs://nameservice1",
					"fieldDelimiter":"\t",
					"fileName":"andon_tag_copy1",
					"fileType":"text",
					"hadoopConfig":{
						"dfs.client.failover.proxy.provider.nameservice1":"org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider",
						"dfs.ha.namenodes.nameservice1":"nn1,nn2",
						"dfs.namenode.rpc-address.nameservice1.nn1":"ziyunbd01:8020",
						"dfs.namenode.rpc-address.nameservice1.nn2":"ziyunbd02:8020",
						"dfs.nameservices":"nameservice1"
					},
					"path":"/user/hive/warehouse/mysql_ziyun_andon/andon_tag_copy1",
					"writeMode":"append"
				}
			}
		}
	],
	"setting":{
		"speed":{
			"channel":"3"
		}
	}
}

2021-03-29 18:22:06.024 [main] WARN  Engine - prioriy set to 0, because NumberFormatException, the value is: null
2021-03-29 18:22:06.028 [main] INFO  PerfTrace - PerfTrace traceId=job_-1, isEnable=false, priority=0
2021-03-29 18:22:06.029 [main] INFO  JobContainer - DataX jobContainer starts job.
2021-03-29 18:22:06.033 [main] INFO  JobContainer - Set jobId = 0
2021-03-29 18:22:06.744 [job-0] INFO  OriginalConfPretreatmentUtil - Available jdbcUrl:jdbc:mysql://192.168.0.124:3306/ziyun-andon?yearIsDateType=false&zeroDateTimeBehavior=convertToNull&tinyInt1isBit=false&rewriteBatchedStatements=true.
2021-03-29 18:22:06.777 [job-0] INFO  OriginalConfPretreatmentUtil - table:[andon_tag_copy1] has columns:[id,tag_name,tombstone,create_dt,update_dt,create_sso].
Mar 29, 2021 6:22:07 PM org.apache.hadoop.util.NativeCodeLoader <clinit>
WARNING: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-03-29 18:22:08.476 [job-0] INFO  JobContainer - jobContainer starts to do prepare ...
2021-03-29 18:22:08.478 [job-0] INFO  JobContainer - DataX Reader.Job [mysqlreader] do prepare work .
2021-03-29 18:22:08.478 [job-0] INFO  JobContainer - DataX Writer.Job [hdfswriter] do prepare work .
2021-03-29 18:22:08.663 [job-0] INFO  HdfsWriter$Job - 由于您配置了writeMode append, 写入前不做清理工作, [/user/hive/warehouse/mysql_ziyun_andon/andon_tag_copy1] 目录下写入相应文件名前缀  [andon_tag_copy1] 的文件
2021-03-29 18:22:08.664 [job-0] INFO  JobContainer - jobContainer starts to do split ...
2021-03-29 18:22:08.665 [job-0] INFO  JobContainer - Job set Channel-Number to 3 channels.
2021-03-29 18:22:08.673 [job-0] INFO  JobContainer - DataX Reader.Job [mysqlreader] splits to [1] tasks.
2021-03-29 18:22:08.674 [job-0] INFO  HdfsWriter$Job - begin do split...
2021-03-29 18:22:08.681 [job-0] INFO  HdfsWriter$Job - splited write file name:[hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_tag_copy1__32eed903_796b_4393_b7d8_144781d06ea1/andon_tag_copy1__d599e3cb_e3ed_4533_ae50_17deccaf38d8]
2021-03-29 18:22:08.681 [job-0] INFO  HdfsWriter$Job - end do split.
2021-03-29 18:22:08.681 [job-0] INFO  JobContainer - DataX Writer.Job [hdfswriter] splits to [1] tasks.
2021-03-29 18:22:08.716 [job-0] INFO  JobContainer - jobContainer starts to do schedule ...
2021-03-29 18:22:08.725 [job-0] INFO  JobContainer - Scheduler starts [1] taskGroups.
2021-03-29 18:22:08.729 [job-0] INFO  JobContainer - Running by standalone Mode.
2021-03-29 18:22:08.740 [taskGroup-0] INFO  TaskGroupContainer - taskGroupId=[0] start [1] channels for [1] tasks.
2021-03-29 18:22:08.746 [taskGroup-0] INFO  Channel - Channel set byte_speed_limit to -1, No bps activated.
2021-03-29 18:22:08.746 [taskGroup-0] INFO  Channel - Channel set record_speed_limit to -1, No tps activated.
2021-03-29 18:22:08.759 [taskGroup-0] INFO  TaskGroupContainer - taskGroup[0] taskId[0] attemptCount[1] is started
2021-03-29 18:22:08.767 [0-0-0-reader] INFO  CommonRdbmsReader$Task - Begin to read record by Sql: [select `id`,`tag_name`,`tombstone`,`create_dt`,`update_dt`,`create_sso` from andon_tag_copy1 where (1=1)
] jdbcUrl:[jdbc:mysql://192.168.0.124:3306/ziyun-andon?yearIsDateType=false&zeroDateTimeBehavior=convertToNull&tinyInt1isBit=false&rewriteBatchedStatements=true].
2021-03-29 18:22:08.794 [0-0-0-reader] INFO  CommonRdbmsReader$Task - Finished read record by Sql: [select `id`,`tag_name`,`tombstone`,`create_dt`,`update_dt`,`create_sso` from andon_tag_copy1 where (1=1)
] jdbcUrl:[jdbc:mysql://192.168.0.124:3306/ziyun-andon?yearIsDateType=false&zeroDateTimeBehavior=convertToNull&tinyInt1isBit=false&rewriteBatchedStatements=true].
2021-03-29 18:22:08.817 [0-0-0-writer] INFO  HdfsWriter$Task - begin do write...
2021-03-29 18:22:08.817 [0-0-0-writer] INFO  HdfsWriter$Task - write to file : [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_tag_copy1__32eed903_796b_4393_b7d8_144781d06ea1/andon_tag_copy1__d599e3cb_e3ed_4533_ae50_17deccaf38d8]
2021-03-29 18:22:09.173 [0-0-0-writer] INFO  HdfsWriter$Task - end do write
2021-03-29 18:22:09.261 [taskGroup-0] INFO  TaskGroupContainer - taskGroup[0] taskId[0] is successed, used[503]ms
2021-03-29 18:22:09.262 [taskGroup-0] INFO  TaskGroupContainer - taskGroup[0] completed it's tasks.
2021-03-29 18:22:18.763 [job-0] INFO  StandAloneJobContainerCommunicator - Total 6 records, 126 bytes | Speed 12B/s, 0 records/s | Error 0 records, 0 bytes |  All Task WaitWriterTime 0.000s |  All Task WaitReaderTime 0.000s | Percentage 100.00%
2021-03-29 18:22:18.764 [job-0] INFO  AbstractScheduler - Scheduler accomplished all tasks.
2021-03-29 18:22:18.764 [job-0] INFO  JobContainer - DataX Writer.Job [hdfswriter] do post work.
2021-03-29 18:22:18.765 [job-0] INFO  HdfsWriter$Job - start rename file [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_tag_copy1__32eed903_796b_4393_b7d8_144781d06ea1/andon_tag_copy1__d599e3cb_e3ed_4533_ae50_17deccaf38d8.gz] to file [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_tag_copy1/andon_tag_copy1__d599e3cb_e3ed_4533_ae50_17deccaf38d8.gz].
2021-03-29 18:22:18.778 [job-0] INFO  HdfsWriter$Job - finish rename file [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_tag_copy1__32eed903_796b_4393_b7d8_144781d06ea1/andon_tag_copy1__d599e3cb_e3ed_4533_ae50_17deccaf38d8.gz] to file [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_tag_copy1/andon_tag_copy1__d599e3cb_e3ed_4533_ae50_17deccaf38d8.gz].
2021-03-29 18:22:18.778 [job-0] INFO  HdfsWriter$Job - start delete tmp dir [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_tag_copy1__32eed903_796b_4393_b7d8_144781d06ea1] .
2021-03-29 18:22:18.791 [job-0] INFO  HdfsWriter$Job - finish delete tmp dir [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_tag_copy1__32eed903_796b_4393_b7d8_144781d06ea1] .
2021-03-29 18:22:18.792 [job-0] INFO  JobContainer - DataX Reader.Job [mysqlreader] do post work.
2021-03-29 18:22:18.793 [job-0] INFO  JobContainer - DataX jobId [0] completed successfully.
2021-03-29 18:22:18.794 [job-0] INFO  HookInvoker - No hook invoked, because base dir not exists or is a file: /software/datax/hook
2021-03-29 18:22:18.898 [job-0] INFO  JobContainer - 
	 [total cpu info] => 
		averageCpu                     | maxDeltaCpu                    | minDeltaCpu                    
		-1.00%                         | -1.00%                         | -1.00%
                        

	 [total gc info] => 
		 NAME                 | totalGCCount       | maxDeltaGCCount    | minDeltaGCCount    | totalGCTime        | maxDeltaGCTime     | minDeltaGCTime     
		 PS MarkSweep         | 1                  | 1                  | 1                  | 0.061s             | 0.061s             | 0.061s             
		 PS Scavenge          | 1                  | 1                  | 1                  | 0.039s             | 0.039s             | 0.039s             

2021-03-29 18:22:18.898 [job-0] INFO  JobContainer - PerfTrace not enable!
2021-03-29 18:22:18.899 [job-0] INFO  StandAloneJobContainerCommunicator - Total 6 records, 126 bytes | Speed 12B/s, 0 records/s | Error 0 records, 0 bytes |  All Task WaitWriterTime 0.000s |  All Task WaitReaderTime 0.000s | Percentage 100.00%
2021-03-29 18:22:18.901 [job-0] INFO  JobContainer - 
任务启动时刻                    : 2021-03-29 18:22:06
任务结束时刻                    : 2021-03-29 18:22:18
任务总计耗时                    :                 12s
任务平均流量                    :               12B/s
记录写入速度                    :              0rec/s
读出记录总数                    :                   6
读写失败总数                    :                   0

andon_tag_copy1表全量同步的结果为0
开始同步一张表
增量配置文件：/software/datax/sync/bin/../conf/jdbc:mysql:192.168.0.124:3306/ziyun-andon.increment
/software/datax/sync/bin/../conf/jdbc:mysql:192.168.0.124:3306/ziyun-andon.increment是文件，进入判断#
maybe_results：
开始全量同步表andon_user_statistics

DataX (DATAX-OPENSOURCE-3.0), From Alibaba !
Copyright (C) 2010-2017, Alibaba Group. All Rights Reserved.


2021-03-29 18:22:19.900 [main] INFO  VMInfo - VMInfo# operatingSystem class => sun.management.OperatingSystemImpl
2021-03-29 18:22:19.911 [main] INFO  Engine - the machine info  => 

	osInfo:	Oracle Corporation 1.8 25.201-b09
	jvmInfo:	Linux amd64 3.10.0-957.el7.x86_64
	cpu num:	16

	totalPhysicalMemory:	-0.00G
	freePhysicalMemory:	-0.00G
	maxFileDescriptorCount:	-1
	currentOpenFileDescriptorCount:	-1

	GC Names	[PS MarkSweep, PS Scavenge]

	MEMORY_NAME                    | allocation_size                | init_size                      
	PS Eden Space                  | 256.00MB                       | 256.00MB                       
	Code Cache                     | 240.00MB                       | 2.44MB                         
	Compressed Class Space         | 1,024.00MB                     | 0.00MB                         
	PS Survivor Space              | 42.50MB                        | 42.50MB                        
	PS Old Gen                     | 683.00MB                       | 683.00MB                       
	Metaspace                      | -0.00MB                        | 0.00MB                         


2021-03-29 18:22:19.946 [main] INFO  Engine - 
{
	"content":[
		{
			"reader":{
				"name":"mysqlreader",
				"parameter":{
					"column":[
						"`id`",
						"`statistics_date`",
						"`sso_id`",
						"`tag_id`",
						"`average_duration`",
						"`average_duration_value`",
						"`link_relative`",
						"`org_id`",
						"`create_dt`",
						"`update_dt`",
						"`status`",
						"`domain_id`"
					],
					"connection":[
						{
							"jdbcUrl":[
								"jdbc:mysql://192.168.0.124:3306/ziyun-andon"
							],
							"table":[
								"andon_user_statistics"
							]
						}
					],
					"password":"********",
					"username":"ziyunIot",
					"where":"1=1"
				}
			},
			"writer":{
				"name":"hdfswriter",
				"parameter":{
					"column":[
						{
							"name":"`id`",
							"type":"BIGINT"
						},
						{
							"name":"`statistics_date`",
							"type":"STRING"
						},
						{
							"name":"`sso_id`",
							"type":"STRING"
						},
						{
							"name":"`tag_id`",
							"type":"BIGINT"
						},
						{
							"name":"`average_duration`",
							"type":"STRING"
						},
						{
							"name":"`average_duration_value`",
							"type":"BIGINT"
						},
						{
							"name":"`link_relative`",
							"type":"STRING"
						},
						{
							"name":"`org_id`",
							"type":"BIGINT"
						},
						{
							"name":"`create_dt`",
							"type":"DATE"
						},
						{
							"name":"`update_dt`",
							"type":"DATE"
						},
						{
							"name":"`status`",
							"type":"STRING"
						},
						{
							"name":"`domain_id`",
							"type":"STRING"
						}
					],
					"compress":"gzip",
					"defaultFS":"hdfs://nameservice1",
					"fieldDelimiter":"\t",
					"fileName":"andon_user_statistics",
					"fileType":"text",
					"hadoopConfig":{
						"dfs.client.failover.proxy.provider.nameservice1":"org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider",
						"dfs.ha.namenodes.nameservice1":"nn1,nn2",
						"dfs.namenode.rpc-address.nameservice1.nn1":"ziyunbd01:8020",
						"dfs.namenode.rpc-address.nameservice1.nn2":"ziyunbd02:8020",
						"dfs.nameservices":"nameservice1"
					},
					"path":"/user/hive/warehouse/mysql_ziyun_andon/andon_user_statistics",
					"writeMode":"append"
				}
			}
		}
	],
	"setting":{
		"speed":{
			"channel":"3"
		}
	}
}

2021-03-29 18:22:19.977 [main] WARN  Engine - prioriy set to 0, because NumberFormatException, the value is: null
2021-03-29 18:22:19.979 [main] INFO  PerfTrace - PerfTrace traceId=job_-1, isEnable=false, priority=0
2021-03-29 18:22:19.980 [main] INFO  JobContainer - DataX jobContainer starts job.
2021-03-29 18:22:19.983 [main] INFO  JobContainer - Set jobId = 0
2021-03-29 18:22:20.503 [job-0] INFO  OriginalConfPretreatmentUtil - Available jdbcUrl:jdbc:mysql://192.168.0.124:3306/ziyun-andon?yearIsDateType=false&zeroDateTimeBehavior=convertToNull&tinyInt1isBit=false&rewriteBatchedStatements=true.
2021-03-29 18:22:20.534 [job-0] INFO  OriginalConfPretreatmentUtil - table:[andon_user_statistics] has columns:[id,statistics_date,sso_id,tag_id,average_duration,average_duration_value,link_relative,org_id,create_dt,update_dt,status,domain_id].
Mar 29, 2021 6:22:21 PM org.apache.hadoop.util.NativeCodeLoader <clinit>
WARNING: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-03-29 18:22:22.484 [job-0] INFO  JobContainer - jobContainer starts to do prepare ...
2021-03-29 18:22:22.485 [job-0] INFO  JobContainer - DataX Reader.Job [mysqlreader] do prepare work .
2021-03-29 18:22:22.486 [job-0] INFO  JobContainer - DataX Writer.Job [hdfswriter] do prepare work .
2021-03-29 18:22:22.677 [job-0] INFO  HdfsWriter$Job - 由于您配置了writeMode append, 写入前不做清理工作, [/user/hive/warehouse/mysql_ziyun_andon/andon_user_statistics] 目录下写入相应文件名前缀  [andon_user_statistics] 的文件
2021-03-29 18:22:22.678 [job-0] INFO  JobContainer - jobContainer starts to do split ...
2021-03-29 18:22:22.678 [job-0] INFO  JobContainer - Job set Channel-Number to 3 channels.
2021-03-29 18:22:22.688 [job-0] INFO  JobContainer - DataX Reader.Job [mysqlreader] splits to [1] tasks.
2021-03-29 18:22:22.689 [job-0] INFO  HdfsWriter$Job - begin do split...
2021-03-29 18:22:22.696 [job-0] INFO  HdfsWriter$Job - splited write file name:[hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_user_statistics__7d5e1137_f466_4967_b94f_2d4744976f5b/andon_user_statistics__b5c829b4_2983_40ca_9077_adf004ce7e18]
2021-03-29 18:22:22.696 [job-0] INFO  HdfsWriter$Job - end do split.
2021-03-29 18:22:22.696 [job-0] INFO  JobContainer - DataX Writer.Job [hdfswriter] splits to [1] tasks.
2021-03-29 18:22:22.733 [job-0] INFO  JobContainer - jobContainer starts to do schedule ...
2021-03-29 18:22:22.741 [job-0] INFO  JobContainer - Scheduler starts [1] taskGroups.
2021-03-29 18:22:22.745 [job-0] INFO  JobContainer - Running by standalone Mode.
2021-03-29 18:22:22.756 [taskGroup-0] INFO  TaskGroupContainer - taskGroupId=[0] start [1] channels for [1] tasks.
2021-03-29 18:22:22.763 [taskGroup-0] INFO  Channel - Channel set byte_speed_limit to -1, No bps activated.
2021-03-29 18:22:22.764 [taskGroup-0] INFO  Channel - Channel set record_speed_limit to -1, No tps activated.
2021-03-29 18:22:22.779 [taskGroup-0] INFO  TaskGroupContainer - taskGroup[0] taskId[0] attemptCount[1] is started
2021-03-29 18:22:22.785 [0-0-0-reader] INFO  CommonRdbmsReader$Task - Begin to read record by Sql: [select `id`,`statistics_date`,`sso_id`,`tag_id`,`average_duration`,`average_duration_value`,`link_relative`,`org_id`,`create_dt`,`update_dt`,`status`,`domain_id` from andon_user_statistics where (1=1)
] jdbcUrl:[jdbc:mysql://192.168.0.124:3306/ziyun-andon?yearIsDateType=false&zeroDateTimeBehavior=convertToNull&tinyInt1isBit=false&rewriteBatchedStatements=true].
2021-03-29 18:22:22.839 [0-0-0-reader] INFO  CommonRdbmsReader$Task - Finished read record by Sql: [select `id`,`statistics_date`,`sso_id`,`tag_id`,`average_duration`,`average_duration_value`,`link_relative`,`org_id`,`create_dt`,`update_dt`,`status`,`domain_id` from andon_user_statistics where (1=1)
] jdbcUrl:[jdbc:mysql://192.168.0.124:3306/ziyun-andon?yearIsDateType=false&zeroDateTimeBehavior=convertToNull&tinyInt1isBit=false&rewriteBatchedStatements=true].
2021-03-29 18:22:22.839 [0-0-0-writer] INFO  HdfsWriter$Task - begin do write...
2021-03-29 18:22:22.839 [0-0-0-writer] INFO  HdfsWriter$Task - write to file : [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_user_statistics__7d5e1137_f466_4967_b94f_2d4744976f5b/andon_user_statistics__b5c829b4_2983_40ca_9077_adf004ce7e18]
2021-03-29 18:22:23.213 [0-0-0-writer] INFO  HdfsWriter$Task - end do write
2021-03-29 18:22:23.281 [taskGroup-0] INFO  TaskGroupContainer - taskGroup[0] taskId[0] is successed, used[504]ms
2021-03-29 18:22:23.283 [taskGroup-0] INFO  TaskGroupContainer - taskGroup[0] completed it's tasks.
2021-03-29 18:22:32.777 [job-0] INFO  StandAloneJobContainerCommunicator - Total 61 records, 5362 bytes | Speed 536B/s, 6 records/s | Error 0 records, 0 bytes |  All Task WaitWriterTime 0.000s |  All Task WaitReaderTime 0.000s | Percentage 100.00%
2021-03-29 18:22:32.778 [job-0] INFO  AbstractScheduler - Scheduler accomplished all tasks.
2021-03-29 18:22:32.778 [job-0] INFO  JobContainer - DataX Writer.Job [hdfswriter] do post work.
2021-03-29 18:22:32.779 [job-0] INFO  HdfsWriter$Job - start rename file [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_user_statistics__7d5e1137_f466_4967_b94f_2d4744976f5b/andon_user_statistics__b5c829b4_2983_40ca_9077_adf004ce7e18.gz] to file [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_user_statistics/andon_user_statistics__b5c829b4_2983_40ca_9077_adf004ce7e18.gz].
2021-03-29 18:22:32.790 [job-0] INFO  HdfsWriter$Job - finish rename file [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_user_statistics__7d5e1137_f466_4967_b94f_2d4744976f5b/andon_user_statistics__b5c829b4_2983_40ca_9077_adf004ce7e18.gz] to file [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_user_statistics/andon_user_statistics__b5c829b4_2983_40ca_9077_adf004ce7e18.gz].
2021-03-29 18:22:32.790 [job-0] INFO  HdfsWriter$Job - start delete tmp dir [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_user_statistics__7d5e1137_f466_4967_b94f_2d4744976f5b] .
2021-03-29 18:22:32.798 [job-0] INFO  HdfsWriter$Job - finish delete tmp dir [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_user_statistics__7d5e1137_f466_4967_b94f_2d4744976f5b] .
2021-03-29 18:22:32.798 [job-0] INFO  JobContainer - DataX Reader.Job [mysqlreader] do post work.
2021-03-29 18:22:32.799 [job-0] INFO  JobContainer - DataX jobId [0] completed successfully.
2021-03-29 18:22:32.800 [job-0] INFO  HookInvoker - No hook invoked, because base dir not exists or is a file: /software/datax/hook
2021-03-29 18:22:32.903 [job-0] INFO  JobContainer - 
	 [total cpu info] => 
		averageCpu                     | maxDeltaCpu                    | minDeltaCpu                    
		-1.00%                         | -1.00%                         | -1.00%
                        

	 [total gc info] => 
		 NAME                 | totalGCCount       | maxDeltaGCCount    | minDeltaGCCount    | totalGCTime        | maxDeltaGCTime     | minDeltaGCTime     
		 PS MarkSweep         | 1                  | 1                  | 1                  | 0.063s             | 0.063s             | 0.063s             
		 PS Scavenge          | 1                  | 1                  | 1                  | 0.035s             | 0.035s             | 0.035s             

2021-03-29 18:22:32.903 [job-0] INFO  JobContainer - PerfTrace not enable!
2021-03-29 18:22:32.904 [job-0] INFO  StandAloneJobContainerCommunicator - Total 61 records, 5362 bytes | Speed 536B/s, 6 records/s | Error 0 records, 0 bytes |  All Task WaitWriterTime 0.000s |  All Task WaitReaderTime 0.000s | Percentage 100.00%
2021-03-29 18:22:32.906 [job-0] INFO  JobContainer - 
任务启动时刻                    : 2021-03-29 18:22:19
任务结束时刻                    : 2021-03-29 18:22:32
任务总计耗时                    :                 12s
任务平均流量                    :              536B/s
记录写入速度                    :              6rec/s
读出记录总数                    :                  61
读写失败总数                    :                   0

andon_user_statistics表全量同步的结果为0
开始同步一张表
增量配置文件：/software/datax/sync/bin/../conf/jdbc:mysql:192.168.0.124:3306/ziyun-andon.increment
/software/datax/sync/bin/../conf/jdbc:mysql:192.168.0.124:3306/ziyun-andon.increment是文件，进入判断#
maybe_results：
开始全量同步表andon_user_statistics_copy1

DataX (DATAX-OPENSOURCE-3.0), From Alibaba !
Copyright (C) 2010-2017, Alibaba Group. All Rights Reserved.


2021-03-29 18:22:34.119 [main] INFO  VMInfo - VMInfo# operatingSystem class => sun.management.OperatingSystemImpl
2021-03-29 18:22:34.130 [main] INFO  Engine - the machine info  => 

	osInfo:	Oracle Corporation 1.8 25.201-b09
	jvmInfo:	Linux amd64 3.10.0-957.el7.x86_64
	cpu num:	16

	totalPhysicalMemory:	-0.00G
	freePhysicalMemory:	-0.00G
	maxFileDescriptorCount:	-1
	currentOpenFileDescriptorCount:	-1

	GC Names	[PS MarkSweep, PS Scavenge]

	MEMORY_NAME                    | allocation_size                | init_size                      
	PS Eden Space                  | 256.00MB                       | 256.00MB                       
	Code Cache                     | 240.00MB                       | 2.44MB                         
	Compressed Class Space         | 1,024.00MB                     | 0.00MB                         
	PS Survivor Space              | 42.50MB                        | 42.50MB                        
	PS Old Gen                     | 683.00MB                       | 683.00MB                       
	Metaspace                      | -0.00MB                        | 0.00MB                         


2021-03-29 18:22:34.163 [main] INFO  Engine - 
{
	"content":[
		{
			"reader":{
				"name":"mysqlreader",
				"parameter":{
					"column":[
						"`id`",
						"`statistics_date`",
						"`sso_id`",
						"`tag_id`",
						"`average_duration`",
						"`average_duration_value`",
						"`link_relative`",
						"`org_hcode`",
						"`create_dt`",
						"`update_dt`",
						"`status`"
					],
					"connection":[
						{
							"jdbcUrl":[
								"jdbc:mysql://192.168.0.124:3306/ziyun-andon"
							],
							"table":[
								"andon_user_statistics_copy1"
							]
						}
					],
					"password":"********",
					"username":"ziyunIot",
					"where":"1=1"
				}
			},
			"writer":{
				"name":"hdfswriter",
				"parameter":{
					"column":[
						{
							"name":"`id`",
							"type":"BIGINT"
						},
						{
							"name":"`statistics_date`",
							"type":"STRING"
						},
						{
							"name":"`sso_id`",
							"type":"STRING"
						},
						{
							"name":"`tag_id`",
							"type":"BIGINT"
						},
						{
							"name":"`average_duration`",
							"type":"STRING"
						},
						{
							"name":"`average_duration_value`",
							"type":"BIGINT"
						},
						{
							"name":"`link_relative`",
							"type":"STRING"
						},
						{
							"name":"`org_hcode`",
							"type":"STRING"
						},
						{
							"name":"`create_dt`",
							"type":"DATE"
						},
						{
							"name":"`update_dt`",
							"type":"DATE"
						},
						{
							"name":"`status`",
							"type":"STRING"
						}
					],
					"compress":"gzip",
					"defaultFS":"hdfs://nameservice1",
					"fieldDelimiter":"\t",
					"fileName":"andon_user_statistics_copy1",
					"fileType":"text",
					"hadoopConfig":{
						"dfs.client.failover.proxy.provider.nameservice1":"org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider",
						"dfs.ha.namenodes.nameservice1":"nn1,nn2",
						"dfs.namenode.rpc-address.nameservice1.nn1":"ziyunbd01:8020",
						"dfs.namenode.rpc-address.nameservice1.nn2":"ziyunbd02:8020",
						"dfs.nameservices":"nameservice1"
					},
					"path":"/user/hive/warehouse/mysql_ziyun_andon/andon_user_statistics_copy1",
					"writeMode":"append"
				}
			}
		}
	],
	"setting":{
		"speed":{
			"channel":"3"
		}
	}
}

2021-03-29 18:22:34.191 [main] WARN  Engine - prioriy set to 0, because NumberFormatException, the value is: null
2021-03-29 18:22:34.193 [main] INFO  PerfTrace - PerfTrace traceId=job_-1, isEnable=false, priority=0
2021-03-29 18:22:34.194 [main] INFO  JobContainer - DataX jobContainer starts job.
2021-03-29 18:22:34.196 [main] INFO  JobContainer - Set jobId = 0
2021-03-29 18:22:34.739 [job-0] INFO  OriginalConfPretreatmentUtil - Available jdbcUrl:jdbc:mysql://192.168.0.124:3306/ziyun-andon?yearIsDateType=false&zeroDateTimeBehavior=convertToNull&tinyInt1isBit=false&rewriteBatchedStatements=true.
2021-03-29 18:22:34.770 [job-0] INFO  OriginalConfPretreatmentUtil - table:[andon_user_statistics_copy1] has columns:[id,statistics_date,sso_id,tag_id,average_duration,average_duration_value,link_relative,org_hcode,create_dt,update_dt,status].
Mar 29, 2021 6:22:35 PM org.apache.hadoop.util.NativeCodeLoader <clinit>
WARNING: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-03-29 18:22:37.035 [job-0] INFO  JobContainer - jobContainer starts to do prepare ...
2021-03-29 18:22:37.036 [job-0] INFO  JobContainer - DataX Reader.Job [mysqlreader] do prepare work .
2021-03-29 18:22:37.037 [job-0] INFO  JobContainer - DataX Writer.Job [hdfswriter] do prepare work .
2021-03-29 18:22:37.202 [job-0] INFO  HdfsWriter$Job - 由于您配置了writeMode append, 写入前不做清理工作, [/user/hive/warehouse/mysql_ziyun_andon/andon_user_statistics_copy1] 目录下写入相应文件名前缀  [andon_user_statistics_copy1] 的文件
2021-03-29 18:22:37.203 [job-0] INFO  JobContainer - jobContainer starts to do split ...
2021-03-29 18:22:37.204 [job-0] INFO  JobContainer - Job set Channel-Number to 3 channels.
2021-03-29 18:22:37.212 [job-0] INFO  JobContainer - DataX Reader.Job [mysqlreader] splits to [1] tasks.
2021-03-29 18:22:37.212 [job-0] INFO  HdfsWriter$Job - begin do split...
2021-03-29 18:22:37.220 [job-0] INFO  HdfsWriter$Job - splited write file name:[hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_user_statistics_copy1__d8e93931_6fd7_4d50_b8a2_31216712d638/andon_user_statistics_copy1__984cfe3f_ce1a_4376_9786_15875445de5e]
2021-03-29 18:22:37.220 [job-0] INFO  HdfsWriter$Job - end do split.
2021-03-29 18:22:37.220 [job-0] INFO  JobContainer - DataX Writer.Job [hdfswriter] splits to [1] tasks.
2021-03-29 18:22:37.260 [job-0] INFO  JobContainer - jobContainer starts to do schedule ...
2021-03-29 18:22:37.267 [job-0] INFO  JobContainer - Scheduler starts [1] taskGroups.
2021-03-29 18:22:37.272 [job-0] INFO  JobContainer - Running by standalone Mode.
2021-03-29 18:22:37.284 [taskGroup-0] INFO  TaskGroupContainer - taskGroupId=[0] start [1] channels for [1] tasks.
2021-03-29 18:22:37.291 [taskGroup-0] INFO  Channel - Channel set byte_speed_limit to -1, No bps activated.
2021-03-29 18:22:37.292 [taskGroup-0] INFO  Channel - Channel set record_speed_limit to -1, No tps activated.
2021-03-29 18:22:37.309 [taskGroup-0] INFO  TaskGroupContainer - taskGroup[0] taskId[0] attemptCount[1] is started
2021-03-29 18:22:37.317 [0-0-0-reader] INFO  CommonRdbmsReader$Task - Begin to read record by Sql: [select `id`,`statistics_date`,`sso_id`,`tag_id`,`average_duration`,`average_duration_value`,`link_relative`,`org_hcode`,`create_dt`,`update_dt`,`status` from andon_user_statistics_copy1 where (1=1)
] jdbcUrl:[jdbc:mysql://192.168.0.124:3306/ziyun-andon?yearIsDateType=false&zeroDateTimeBehavior=convertToNull&tinyInt1isBit=false&rewriteBatchedStatements=true].
2021-03-29 18:22:37.364 [0-0-0-reader] INFO  CommonRdbmsReader$Task - Finished read record by Sql: [select `id`,`statistics_date`,`sso_id`,`tag_id`,`average_duration`,`average_duration_value`,`link_relative`,`org_hcode`,`create_dt`,`update_dt`,`status` from andon_user_statistics_copy1 where (1=1)
] jdbcUrl:[jdbc:mysql://192.168.0.124:3306/ziyun-andon?yearIsDateType=false&zeroDateTimeBehavior=convertToNull&tinyInt1isBit=false&rewriteBatchedStatements=true].
2021-03-29 18:22:37.374 [0-0-0-writer] INFO  HdfsWriter$Task - begin do write...
2021-03-29 18:22:37.374 [0-0-0-writer] INFO  HdfsWriter$Task - write to file : [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_user_statistics_copy1__d8e93931_6fd7_4d50_b8a2_31216712d638/andon_user_statistics_copy1__984cfe3f_ce1a_4376_9786_15875445de5e]
2021-03-29 18:22:37.750 [0-0-0-writer] INFO  HdfsWriter$Task - end do write
2021-03-29 18:22:37.812 [taskGroup-0] INFO  TaskGroupContainer - taskGroup[0] taskId[0] is successed, used[505]ms
2021-03-29 18:22:37.813 [taskGroup-0] INFO  TaskGroupContainer - taskGroup[0] completed it's tasks.
2021-03-29 18:22:47.306 [job-0] INFO  StandAloneJobContainerCommunicator - Total 52 records, 2896 bytes | Speed 289B/s, 5 records/s | Error 0 records, 0 bytes |  All Task WaitWriterTime 0.000s |  All Task WaitReaderTime 0.000s | Percentage 100.00%
2021-03-29 18:22:47.306 [job-0] INFO  AbstractScheduler - Scheduler accomplished all tasks.
2021-03-29 18:22:47.307 [job-0] INFO  JobContainer - DataX Writer.Job [hdfswriter] do post work.
2021-03-29 18:22:47.309 [job-0] INFO  HdfsWriter$Job - start rename file [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_user_statistics_copy1__d8e93931_6fd7_4d50_b8a2_31216712d638/andon_user_statistics_copy1__984cfe3f_ce1a_4376_9786_15875445de5e.gz] to file [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_user_statistics_copy1/andon_user_statistics_copy1__984cfe3f_ce1a_4376_9786_15875445de5e.gz].
2021-03-29 18:22:47.322 [job-0] INFO  HdfsWriter$Job - finish rename file [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_user_statistics_copy1__d8e93931_6fd7_4d50_b8a2_31216712d638/andon_user_statistics_copy1__984cfe3f_ce1a_4376_9786_15875445de5e.gz] to file [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_user_statistics_copy1/andon_user_statistics_copy1__984cfe3f_ce1a_4376_9786_15875445de5e.gz].
2021-03-29 18:22:47.322 [job-0] INFO  HdfsWriter$Job - start delete tmp dir [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_user_statistics_copy1__d8e93931_6fd7_4d50_b8a2_31216712d638] .
2021-03-29 18:22:47.333 [job-0] INFO  HdfsWriter$Job - finish delete tmp dir [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_user_statistics_copy1__d8e93931_6fd7_4d50_b8a2_31216712d638] .
2021-03-29 18:22:47.333 [job-0] INFO  JobContainer - DataX Reader.Job [mysqlreader] do post work.
2021-03-29 18:22:47.334 [job-0] INFO  JobContainer - DataX jobId [0] completed successfully.
2021-03-29 18:22:47.335 [job-0] INFO  HookInvoker - No hook invoked, because base dir not exists or is a file: /software/datax/hook
2021-03-29 18:22:47.439 [job-0] INFO  JobContainer - 
	 [total cpu info] => 
		averageCpu                     | maxDeltaCpu                    | minDeltaCpu                    
		-1.00%                         | -1.00%                         | -1.00%
                        

	 [total gc info] => 
		 NAME                 | totalGCCount       | maxDeltaGCCount    | minDeltaGCCount    | totalGCTime        | maxDeltaGCTime     | minDeltaGCTime     
		 PS MarkSweep         | 1                  | 1                  | 1                  | 0.083s             | 0.083s             | 0.083s             
		 PS Scavenge          | 1                  | 1                  | 1                  | 0.051s             | 0.051s             | 0.051s             

2021-03-29 18:22:47.440 [job-0] INFO  JobContainer - PerfTrace not enable!
2021-03-29 18:22:47.441 [job-0] INFO  StandAloneJobContainerCommunicator - Total 52 records, 2896 bytes | Speed 289B/s, 5 records/s | Error 0 records, 0 bytes |  All Task WaitWriterTime 0.000s |  All Task WaitReaderTime 0.000s | Percentage 100.00%
2021-03-29 18:22:47.443 [job-0] INFO  JobContainer - 
任务启动时刻                    : 2021-03-29 18:22:34
任务结束时刻                    : 2021-03-29 18:22:47
任务总计耗时                    :                 13s
任务平均流量                    :              289B/s
记录写入速度                    :              5rec/s
读出记录总数                    :                  52
读写失败总数                    :                   0

andon_user_statistics_copy1表全量同步的结果为0
开始同步一张表
增量配置文件：/software/datax/sync/bin/../conf/jdbc:mysql:192.168.0.124:3306/ziyun-andon.increment
/software/datax/sync/bin/../conf/jdbc:mysql:192.168.0.124:3306/ziyun-andon.increment是文件，进入判断#
maybe_results：
开始全量同步表andon_user_wechat_info

DataX (DATAX-OPENSOURCE-3.0), From Alibaba !
Copyright (C) 2010-2017, Alibaba Group. All Rights Reserved.


2021-03-29 18:22:48.595 [main] INFO  VMInfo - VMInfo# operatingSystem class => sun.management.OperatingSystemImpl
2021-03-29 18:22:48.609 [main] INFO  Engine - the machine info  => 

	osInfo:	Oracle Corporation 1.8 25.201-b09
	jvmInfo:	Linux amd64 3.10.0-957.el7.x86_64
	cpu num:	16

	totalPhysicalMemory:	-0.00G
	freePhysicalMemory:	-0.00G
	maxFileDescriptorCount:	-1
	currentOpenFileDescriptorCount:	-1

	GC Names	[PS MarkSweep, PS Scavenge]

	MEMORY_NAME                    | allocation_size                | init_size                      
	PS Eden Space                  | 256.00MB                       | 256.00MB                       
	Code Cache                     | 240.00MB                       | 2.44MB                         
	Compressed Class Space         | 1,024.00MB                     | 0.00MB                         
	PS Survivor Space              | 42.50MB                        | 42.50MB                        
	PS Old Gen                     | 683.00MB                       | 683.00MB                       
	Metaspace                      | -0.00MB                        | 0.00MB                         


2021-03-29 18:22:48.654 [main] INFO  Engine - 
{
	"content":[
		{
			"reader":{
				"name":"mysqlreader",
				"parameter":{
					"column":[
						"`id`",
						"`app_id`",
						"`sso_id`",
						"`open_id`",
						"`whether_open`",
						"`create_dt`",
						"`update_dt`"
					],
					"connection":[
						{
							"jdbcUrl":[
								"jdbc:mysql://192.168.0.124:3306/ziyun-andon"
							],
							"table":[
								"andon_user_wechat_info"
							]
						}
					],
					"password":"********",
					"username":"ziyunIot",
					"where":"1=1"
				}
			},
			"writer":{
				"name":"hdfswriter",
				"parameter":{
					"column":[
						{
							"name":"`id`",
							"type":"BIGINT"
						},
						{
							"name":"`app_id`",
							"type":"STRING"
						},
						{
							"name":"`sso_id`",
							"type":"STRING"
						},
						{
							"name":"`open_id`",
							"type":"STRING"
						},
						{
							"name":"`whether_open`",
							"type":"STRING"
						},
						{
							"name":"`create_dt`",
							"type":"DATE"
						},
						{
							"name":"`update_dt`",
							"type":"DATE"
						}
					],
					"compress":"gzip",
					"defaultFS":"hdfs://nameservice1",
					"fieldDelimiter":"\t",
					"fileName":"andon_user_wechat_info",
					"fileType":"text",
					"hadoopConfig":{
						"dfs.client.failover.proxy.provider.nameservice1":"org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider",
						"dfs.ha.namenodes.nameservice1":"nn1,nn2",
						"dfs.namenode.rpc-address.nameservice1.nn1":"ziyunbd01:8020",
						"dfs.namenode.rpc-address.nameservice1.nn2":"ziyunbd02:8020",
						"dfs.nameservices":"nameservice1"
					},
					"path":"/user/hive/warehouse/mysql_ziyun_andon/andon_user_wechat_info",
					"writeMode":"append"
				}
			}
		}
	],
	"setting":{
		"speed":{
			"channel":"3"
		}
	}
}

2021-03-29 18:22:48.697 [main] WARN  Engine - prioriy set to 0, because NumberFormatException, the value is: null
2021-03-29 18:22:48.702 [main] INFO  PerfTrace - PerfTrace traceId=job_-1, isEnable=false, priority=0
2021-03-29 18:22:48.703 [main] INFO  JobContainer - DataX jobContainer starts job.
2021-03-29 18:22:48.707 [main] INFO  JobContainer - Set jobId = 0
2021-03-29 18:22:49.401 [job-0] INFO  OriginalConfPretreatmentUtil - Available jdbcUrl:jdbc:mysql://192.168.0.124:3306/ziyun-andon?yearIsDateType=false&zeroDateTimeBehavior=convertToNull&tinyInt1isBit=false&rewriteBatchedStatements=true.
2021-03-29 18:22:49.432 [job-0] INFO  OriginalConfPretreatmentUtil - table:[andon_user_wechat_info] has columns:[id,app_id,sso_id,open_id,whether_open,create_dt,update_dt].
Mar 29, 2021 6:22:50 PM org.apache.hadoop.util.NativeCodeLoader <clinit>
WARNING: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-03-29 18:22:51.319 [job-0] INFO  JobContainer - jobContainer starts to do prepare ...
2021-03-29 18:22:51.320 [job-0] INFO  JobContainer - DataX Reader.Job [mysqlreader] do prepare work .
2021-03-29 18:22:51.321 [job-0] INFO  JobContainer - DataX Writer.Job [hdfswriter] do prepare work .
2021-03-29 18:22:51.509 [job-0] INFO  HdfsWriter$Job - 由于您配置了writeMode append, 写入前不做清理工作, [/user/hive/warehouse/mysql_ziyun_andon/andon_user_wechat_info] 目录下写入相应文件名前缀  [andon_user_wechat_info] 的文件
2021-03-29 18:22:51.510 [job-0] INFO  JobContainer - jobContainer starts to do split ...
2021-03-29 18:22:51.510 [job-0] INFO  JobContainer - Job set Channel-Number to 3 channels.
2021-03-29 18:22:51.516 [job-0] INFO  JobContainer - DataX Reader.Job [mysqlreader] splits to [1] tasks.
2021-03-29 18:22:51.517 [job-0] INFO  HdfsWriter$Job - begin do split...
2021-03-29 18:22:51.523 [job-0] INFO  HdfsWriter$Job - splited write file name:[hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_user_wechat_info__68f4a97d_536a_4869_994a_14aa47a3c493/andon_user_wechat_info__fb8b70e9_4142_4820_920d_6718e16421ba]
2021-03-29 18:22:51.524 [job-0] INFO  HdfsWriter$Job - end do split.
2021-03-29 18:22:51.524 [job-0] INFO  JobContainer - DataX Writer.Job [hdfswriter] splits to [1] tasks.
2021-03-29 18:22:51.550 [job-0] INFO  JobContainer - jobContainer starts to do schedule ...
2021-03-29 18:22:51.555 [job-0] INFO  JobContainer - Scheduler starts [1] taskGroups.
2021-03-29 18:22:51.558 [job-0] INFO  JobContainer - Running by standalone Mode.
2021-03-29 18:22:51.567 [taskGroup-0] INFO  TaskGroupContainer - taskGroupId=[0] start [1] channels for [1] tasks.
2021-03-29 18:22:51.575 [taskGroup-0] INFO  Channel - Channel set byte_speed_limit to -1, No bps activated.
2021-03-29 18:22:51.576 [taskGroup-0] INFO  Channel - Channel set record_speed_limit to -1, No tps activated.
2021-03-29 18:22:51.593 [taskGroup-0] INFO  TaskGroupContainer - taskGroup[0] taskId[0] attemptCount[1] is started
2021-03-29 18:22:51.599 [0-0-0-reader] INFO  CommonRdbmsReader$Task - Begin to read record by Sql: [select `id`,`app_id`,`sso_id`,`open_id`,`whether_open`,`create_dt`,`update_dt` from andon_user_wechat_info where (1=1)
] jdbcUrl:[jdbc:mysql://192.168.0.124:3306/ziyun-andon?yearIsDateType=false&zeroDateTimeBehavior=convertToNull&tinyInt1isBit=false&rewriteBatchedStatements=true].
2021-03-29 18:22:51.632 [0-0-0-writer] INFO  HdfsWriter$Task - begin do write...
2021-03-29 18:22:51.633 [0-0-0-writer] INFO  HdfsWriter$Task - write to file : [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_user_wechat_info__68f4a97d_536a_4869_994a_14aa47a3c493/andon_user_wechat_info__fb8b70e9_4142_4820_920d_6718e16421ba]
2021-03-29 18:22:51.644 [0-0-0-reader] INFO  CommonRdbmsReader$Task - Finished read record by Sql: [select `id`,`app_id`,`sso_id`,`open_id`,`whether_open`,`create_dt`,`update_dt` from andon_user_wechat_info where (1=1)
] jdbcUrl:[jdbc:mysql://192.168.0.124:3306/ziyun-andon?yearIsDateType=false&zeroDateTimeBehavior=convertToNull&tinyInt1isBit=false&rewriteBatchedStatements=true].
2021-03-29 18:22:51.898 [0-0-0-writer] INFO  HdfsWriter$Task - end do write
2021-03-29 18:22:51.995 [taskGroup-0] INFO  TaskGroupContainer - taskGroup[0] taskId[0] is successed, used[404]ms
2021-03-29 18:22:51.996 [taskGroup-0] INFO  TaskGroupContainer - taskGroup[0] completed it's tasks.
2021-03-29 18:23:01.584 [job-0] INFO  StandAloneJobContainerCommunicator - Total 23 records, 1815 bytes | Speed 181B/s, 2 records/s | Error 0 records, 0 bytes |  All Task WaitWriterTime 0.000s |  All Task WaitReaderTime 0.000s | Percentage 100.00%
2021-03-29 18:23:01.584 [job-0] INFO  AbstractScheduler - Scheduler accomplished all tasks.
2021-03-29 18:23:01.585 [job-0] INFO  JobContainer - DataX Writer.Job [hdfswriter] do post work.
2021-03-29 18:23:01.586 [job-0] INFO  HdfsWriter$Job - start rename file [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_user_wechat_info__68f4a97d_536a_4869_994a_14aa47a3c493/andon_user_wechat_info__fb8b70e9_4142_4820_920d_6718e16421ba.gz] to file [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_user_wechat_info/andon_user_wechat_info__fb8b70e9_4142_4820_920d_6718e16421ba.gz].
2021-03-29 18:23:01.600 [job-0] INFO  HdfsWriter$Job - finish rename file [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_user_wechat_info__68f4a97d_536a_4869_994a_14aa47a3c493/andon_user_wechat_info__fb8b70e9_4142_4820_920d_6718e16421ba.gz] to file [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_user_wechat_info/andon_user_wechat_info__fb8b70e9_4142_4820_920d_6718e16421ba.gz].
2021-03-29 18:23:01.601 [job-0] INFO  HdfsWriter$Job - start delete tmp dir [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_user_wechat_info__68f4a97d_536a_4869_994a_14aa47a3c493] .
2021-03-29 18:23:01.614 [job-0] INFO  HdfsWriter$Job - finish delete tmp dir [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_user_wechat_info__68f4a97d_536a_4869_994a_14aa47a3c493] .
2021-03-29 18:23:01.614 [job-0] INFO  JobContainer - DataX Reader.Job [mysqlreader] do post work.
2021-03-29 18:23:01.615 [job-0] INFO  JobContainer - DataX jobId [0] completed successfully.
2021-03-29 18:23:01.616 [job-0] INFO  HookInvoker - No hook invoked, because base dir not exists or is a file: /software/datax/hook
2021-03-29 18:23:01.721 [job-0] INFO  JobContainer - 
	 [total cpu info] => 
		averageCpu                     | maxDeltaCpu                    | minDeltaCpu                    
		-1.00%                         | -1.00%                         | -1.00%
                        

	 [total gc info] => 
		 NAME                 | totalGCCount       | maxDeltaGCCount    | minDeltaGCCount    | totalGCTime        | maxDeltaGCTime     | minDeltaGCTime     
		 PS MarkSweep         | 1                  | 1                  | 1                  | 0.081s             | 0.081s             | 0.081s             
		 PS Scavenge          | 1                  | 1                  | 1                  | 0.039s             | 0.039s             | 0.039s             

2021-03-29 18:23:01.721 [job-0] INFO  JobContainer - PerfTrace not enable!
2021-03-29 18:23:01.722 [job-0] INFO  StandAloneJobContainerCommunicator - Total 23 records, 1815 bytes | Speed 181B/s, 2 records/s | Error 0 records, 0 bytes |  All Task WaitWriterTime 0.000s |  All Task WaitReaderTime 0.000s | Percentage 100.00%
2021-03-29 18:23:01.725 [job-0] INFO  JobContainer - 
任务启动时刻                    : 2021-03-29 18:22:48
任务结束时刻                    : 2021-03-29 18:23:01
任务总计耗时                    :                 13s
任务平均流量                    :              181B/s
记录写入速度                    :              2rec/s
读出记录总数                    :                  23
读写失败总数                    :                   0

andon_user_wechat_info表全量同步的结果为0
开始同步一张表
增量配置文件：/software/datax/sync/bin/../conf/jdbc:mysql:192.168.0.124:3306/ziyun-andon.increment
/software/datax/sync/bin/../conf/jdbc:mysql:192.168.0.124:3306/ziyun-andon.increment是文件，进入判断#
maybe_results：
开始全量同步表andon_user_wechat_info_copy1

DataX (DATAX-OPENSOURCE-3.0), From Alibaba !
Copyright (C) 2010-2017, Alibaba Group. All Rights Reserved.


2021-03-29 18:23:02.928 [main] INFO  VMInfo - VMInfo# operatingSystem class => sun.management.OperatingSystemImpl
2021-03-29 18:23:02.942 [main] INFO  Engine - the machine info  => 

	osInfo:	Oracle Corporation 1.8 25.201-b09
	jvmInfo:	Linux amd64 3.10.0-957.el7.x86_64
	cpu num:	16

	totalPhysicalMemory:	-0.00G
	freePhysicalMemory:	-0.00G
	maxFileDescriptorCount:	-1
	currentOpenFileDescriptorCount:	-1

	GC Names	[PS MarkSweep, PS Scavenge]

	MEMORY_NAME                    | allocation_size                | init_size                      
	PS Eden Space                  | 256.00MB                       | 256.00MB                       
	Code Cache                     | 240.00MB                       | 2.44MB                         
	Compressed Class Space         | 1,024.00MB                     | 0.00MB                         
	PS Survivor Space              | 42.50MB                        | 42.50MB                        
	PS Old Gen                     | 683.00MB                       | 683.00MB                       
	Metaspace                      | -0.00MB                        | 0.00MB                         


2021-03-29 18:23:02.989 [main] INFO  Engine - 
{
	"content":[
		{
			"reader":{
				"name":"mysqlreader",
				"parameter":{
					"column":[
						"`id`",
						"`app_id`",
						"`sso_id`",
						"`open_id`",
						"`whether_open`",
						"`create_dt`",
						"`update_dt`"
					],
					"connection":[
						{
							"jdbcUrl":[
								"jdbc:mysql://192.168.0.124:3306/ziyun-andon"
							],
							"table":[
								"andon_user_wechat_info_copy1"
							]
						}
					],
					"password":"********",
					"username":"ziyunIot",
					"where":"1=1"
				}
			},
			"writer":{
				"name":"hdfswriter",
				"parameter":{
					"column":[
						{
							"name":"`id`",
							"type":"BIGINT"
						},
						{
							"name":"`app_id`",
							"type":"STRING"
						},
						{
							"name":"`sso_id`",
							"type":"STRING"
						},
						{
							"name":"`open_id`",
							"type":"STRING"
						},
						{
							"name":"`whether_open`",
							"type":"STRING"
						},
						{
							"name":"`create_dt`",
							"type":"DATE"
						},
						{
							"name":"`update_dt`",
							"type":"DATE"
						}
					],
					"compress":"gzip",
					"defaultFS":"hdfs://nameservice1",
					"fieldDelimiter":"\t",
					"fileName":"andon_user_wechat_info_copy1",
					"fileType":"text",
					"hadoopConfig":{
						"dfs.client.failover.proxy.provider.nameservice1":"org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider",
						"dfs.ha.namenodes.nameservice1":"nn1,nn2",
						"dfs.namenode.rpc-address.nameservice1.nn1":"ziyunbd01:8020",
						"dfs.namenode.rpc-address.nameservice1.nn2":"ziyunbd02:8020",
						"dfs.nameservices":"nameservice1"
					},
					"path":"/user/hive/warehouse/mysql_ziyun_andon/andon_user_wechat_info_copy1",
					"writeMode":"append"
				}
			}
		}
	],
	"setting":{
		"speed":{
			"channel":"3"
		}
	}
}

2021-03-29 18:23:03.016 [main] WARN  Engine - prioriy set to 0, because NumberFormatException, the value is: null
2021-03-29 18:23:03.019 [main] INFO  PerfTrace - PerfTrace traceId=job_-1, isEnable=false, priority=0
2021-03-29 18:23:03.019 [main] INFO  JobContainer - DataX jobContainer starts job.
2021-03-29 18:23:03.022 [main] INFO  JobContainer - Set jobId = 0
2021-03-29 18:23:03.550 [job-0] INFO  OriginalConfPretreatmentUtil - Available jdbcUrl:jdbc:mysql://192.168.0.124:3306/ziyun-andon?yearIsDateType=false&zeroDateTimeBehavior=convertToNull&tinyInt1isBit=false&rewriteBatchedStatements=true.
2021-03-29 18:23:03.579 [job-0] INFO  OriginalConfPretreatmentUtil - table:[andon_user_wechat_info_copy1] has columns:[id,app_id,sso_id,open_id,whether_open,create_dt,update_dt].
Mar 29, 2021 6:23:04 PM org.apache.hadoop.util.NativeCodeLoader <clinit>
WARNING: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-03-29 18:23:05.268 [job-0] INFO  JobContainer - jobContainer starts to do prepare ...
2021-03-29 18:23:05.269 [job-0] INFO  JobContainer - DataX Reader.Job [mysqlreader] do prepare work .
2021-03-29 18:23:05.270 [job-0] INFO  JobContainer - DataX Writer.Job [hdfswriter] do prepare work .
2021-03-29 18:23:05.452 [job-0] INFO  HdfsWriter$Job - 由于您配置了writeMode append, 写入前不做清理工作, [/user/hive/warehouse/mysql_ziyun_andon/andon_user_wechat_info_copy1] 目录下写入相应文件名前缀  [andon_user_wechat_info_copy1] 的文件
2021-03-29 18:23:05.452 [job-0] INFO  JobContainer - jobContainer starts to do split ...
2021-03-29 18:23:05.453 [job-0] INFO  JobContainer - Job set Channel-Number to 3 channels.
2021-03-29 18:23:05.461 [job-0] INFO  JobContainer - DataX Reader.Job [mysqlreader] splits to [1] tasks.
2021-03-29 18:23:05.462 [job-0] INFO  HdfsWriter$Job - begin do split...
2021-03-29 18:23:05.469 [job-0] INFO  HdfsWriter$Job - splited write file name:[hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_user_wechat_info_copy1__345f14fe_9521_42d3_b196_5be9ef47d9e0/andon_user_wechat_info_copy1__cb3df44f_2a60_44a2_bcb6_34fad19d8815]
2021-03-29 18:23:05.469 [job-0] INFO  HdfsWriter$Job - end do split.
2021-03-29 18:23:05.469 [job-0] INFO  JobContainer - DataX Writer.Job [hdfswriter] splits to [1] tasks.
2021-03-29 18:23:05.505 [job-0] INFO  JobContainer - jobContainer starts to do schedule ...
2021-03-29 18:23:05.513 [job-0] INFO  JobContainer - Scheduler starts [1] taskGroups.
2021-03-29 18:23:05.517 [job-0] INFO  JobContainer - Running by standalone Mode.
2021-03-29 18:23:05.529 [taskGroup-0] INFO  TaskGroupContainer - taskGroupId=[0] start [1] channels for [1] tasks.
2021-03-29 18:23:05.536 [taskGroup-0] INFO  Channel - Channel set byte_speed_limit to -1, No bps activated.
2021-03-29 18:23:05.537 [taskGroup-0] INFO  Channel - Channel set record_speed_limit to -1, No tps activated.
2021-03-29 18:23:05.554 [taskGroup-0] INFO  TaskGroupContainer - taskGroup[0] taskId[0] attemptCount[1] is started
2021-03-29 18:23:05.559 [0-0-0-reader] INFO  CommonRdbmsReader$Task - Begin to read record by Sql: [select `id`,`app_id`,`sso_id`,`open_id`,`whether_open`,`create_dt`,`update_dt` from andon_user_wechat_info_copy1 where (1=1)
] jdbcUrl:[jdbc:mysql://192.168.0.124:3306/ziyun-andon?yearIsDateType=false&zeroDateTimeBehavior=convertToNull&tinyInt1isBit=false&rewriteBatchedStatements=true].
2021-03-29 18:23:05.596 [0-0-0-reader] INFO  CommonRdbmsReader$Task - Finished read record by Sql: [select `id`,`app_id`,`sso_id`,`open_id`,`whether_open`,`create_dt`,`update_dt` from andon_user_wechat_info_copy1 where (1=1)
] jdbcUrl:[jdbc:mysql://192.168.0.124:3306/ziyun-andon?yearIsDateType=false&zeroDateTimeBehavior=convertToNull&tinyInt1isBit=false&rewriteBatchedStatements=true].
2021-03-29 18:23:05.602 [0-0-0-writer] INFO  HdfsWriter$Task - begin do write...
2021-03-29 18:23:05.602 [0-0-0-writer] INFO  HdfsWriter$Task - write to file : [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_user_wechat_info_copy1__345f14fe_9521_42d3_b196_5be9ef47d9e0/andon_user_wechat_info_copy1__cb3df44f_2a60_44a2_bcb6_34fad19d8815]
2021-03-29 18:23:05.952 [0-0-0-writer] INFO  HdfsWriter$Task - end do write
2021-03-29 18:23:05.956 [taskGroup-0] INFO  TaskGroupContainer - taskGroup[0] taskId[0] is successed, used[405]ms
2021-03-29 18:23:05.957 [taskGroup-0] INFO  TaskGroupContainer - taskGroup[0] completed it's tasks.
2021-03-29 18:23:15.550 [job-0] INFO  StandAloneJobContainerCommunicator - Total 20 records, 1578 bytes | Speed 157B/s, 2 records/s | Error 0 records, 0 bytes |  All Task WaitWriterTime 0.000s |  All Task WaitReaderTime 0.000s | Percentage 100.00%
2021-03-29 18:23:15.550 [job-0] INFO  AbstractScheduler - Scheduler accomplished all tasks.
2021-03-29 18:23:15.551 [job-0] INFO  JobContainer - DataX Writer.Job [hdfswriter] do post work.
2021-03-29 18:23:15.552 [job-0] INFO  HdfsWriter$Job - start rename file [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_user_wechat_info_copy1__345f14fe_9521_42d3_b196_5be9ef47d9e0/andon_user_wechat_info_copy1__cb3df44f_2a60_44a2_bcb6_34fad19d8815.gz] to file [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_user_wechat_info_copy1/andon_user_wechat_info_copy1__cb3df44f_2a60_44a2_bcb6_34fad19d8815.gz].
2021-03-29 18:23:15.564 [job-0] INFO  HdfsWriter$Job - finish rename file [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_user_wechat_info_copy1__345f14fe_9521_42d3_b196_5be9ef47d9e0/andon_user_wechat_info_copy1__cb3df44f_2a60_44a2_bcb6_34fad19d8815.gz] to file [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_user_wechat_info_copy1/andon_user_wechat_info_copy1__cb3df44f_2a60_44a2_bcb6_34fad19d8815.gz].
2021-03-29 18:23:15.565 [job-0] INFO  HdfsWriter$Job - start delete tmp dir [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_user_wechat_info_copy1__345f14fe_9521_42d3_b196_5be9ef47d9e0] .
2021-03-29 18:23:15.576 [job-0] INFO  HdfsWriter$Job - finish delete tmp dir [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_user_wechat_info_copy1__345f14fe_9521_42d3_b196_5be9ef47d9e0] .
2021-03-29 18:23:15.577 [job-0] INFO  JobContainer - DataX Reader.Job [mysqlreader] do post work.
2021-03-29 18:23:15.577 [job-0] INFO  JobContainer - DataX jobId [0] completed successfully.
2021-03-29 18:23:15.579 [job-0] INFO  HookInvoker - No hook invoked, because base dir not exists or is a file: /software/datax/hook
2021-03-29 18:23:15.682 [job-0] INFO  JobContainer - 
	 [total cpu info] => 
		averageCpu                     | maxDeltaCpu                    | minDeltaCpu                    
		-1.00%                         | -1.00%                         | -1.00%
                        

	 [total gc info] => 
		 NAME                 | totalGCCount       | maxDeltaGCCount    | minDeltaGCCount    | totalGCTime        | maxDeltaGCTime     | minDeltaGCTime     
		 PS MarkSweep         | 1                  | 1                  | 1                  | 0.046s             | 0.046s             | 0.046s             
		 PS Scavenge          | 1                  | 1                  | 1                  | 0.027s             | 0.027s             | 0.027s             

2021-03-29 18:23:15.683 [job-0] INFO  JobContainer - PerfTrace not enable!
2021-03-29 18:23:15.684 [job-0] INFO  StandAloneJobContainerCommunicator - Total 20 records, 1578 bytes | Speed 157B/s, 2 records/s | Error 0 records, 0 bytes |  All Task WaitWriterTime 0.000s |  All Task WaitReaderTime 0.000s | Percentage 100.00%
2021-03-29 18:23:15.686 [job-0] INFO  JobContainer - 
任务启动时刻                    : 2021-03-29 18:23:03
任务结束时刻                    : 2021-03-29 18:23:15
任务总计耗时                    :                 12s
任务平均流量                    :              157B/s
记录写入速度                    :              2rec/s
读出记录总数                    :                  20
读写失败总数                    :                   0

andon_user_wechat_info_copy1表全量同步的结果为0
开始同步一张表
增量配置文件：/software/datax/sync/bin/../conf/jdbc:mysql:192.168.0.124:3306/ziyun-andon.increment
/software/datax/sync/bin/../conf/jdbc:mysql:192.168.0.124:3306/ziyun-andon.increment是文件，进入判断#
maybe_results：
开始全量同步表andon_wechat_app_info

DataX (DATAX-OPENSOURCE-3.0), From Alibaba !
Copyright (C) 2010-2017, Alibaba Group. All Rights Reserved.


2021-03-29 18:23:16.718 [main] INFO  VMInfo - VMInfo# operatingSystem class => sun.management.OperatingSystemImpl
2021-03-29 18:23:16.728 [main] INFO  Engine - the machine info  => 

	osInfo:	Oracle Corporation 1.8 25.201-b09
	jvmInfo:	Linux amd64 3.10.0-957.el7.x86_64
	cpu num:	16

	totalPhysicalMemory:	-0.00G
	freePhysicalMemory:	-0.00G
	maxFileDescriptorCount:	-1
	currentOpenFileDescriptorCount:	-1

	GC Names	[PS MarkSweep, PS Scavenge]

	MEMORY_NAME                    | allocation_size                | init_size                      
	PS Eden Space                  | 256.00MB                       | 256.00MB                       
	Code Cache                     | 240.00MB                       | 2.44MB                         
	Compressed Class Space         | 1,024.00MB                     | 0.00MB                         
	PS Survivor Space              | 42.50MB                        | 42.50MB                        
	PS Old Gen                     | 683.00MB                       | 683.00MB                       
	Metaspace                      | -0.00MB                        | 0.00MB                         


2021-03-29 18:23:16.754 [main] INFO  Engine - 
{
	"content":[
		{
			"reader":{
				"name":"mysqlreader",
				"parameter":{
					"column":[
						"`id`",
						"`app_id`",
						"`app_secret`",
						"`sign_mark`",
						"`description`",
						"`state`",
						"`create_date`"
					],
					"connection":[
						{
							"jdbcUrl":[
								"jdbc:mysql://192.168.0.124:3306/ziyun-andon"
							],
							"table":[
								"andon_wechat_app_info"
							]
						}
					],
					"password":"********",
					"username":"ziyunIot",
					"where":"1=1"
				}
			},
			"writer":{
				"name":"hdfswriter",
				"parameter":{
					"column":[
						{
							"name":"`id`",
							"type":"BIGINT"
						},
						{
							"name":"`app_id`",
							"type":"STRING"
						},
						{
							"name":"`app_secret`",
							"type":"STRING"
						},
						{
							"name":"`sign_mark`",
							"type":"STRING"
						},
						{
							"name":"`description`",
							"type":"STRING"
						},
						{
							"name":"`state`",
							"type":"BIGINT"
						},
						{
							"name":"`create_date`",
							"type":"DATE"
						}
					],
					"compress":"gzip",
					"defaultFS":"hdfs://nameservice1",
					"fieldDelimiter":"\t",
					"fileName":"andon_wechat_app_info",
					"fileType":"text",
					"hadoopConfig":{
						"dfs.client.failover.proxy.provider.nameservice1":"org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider",
						"dfs.ha.namenodes.nameservice1":"nn1,nn2",
						"dfs.namenode.rpc-address.nameservice1.nn1":"ziyunbd01:8020",
						"dfs.namenode.rpc-address.nameservice1.nn2":"ziyunbd02:8020",
						"dfs.nameservices":"nameservice1"
					},
					"path":"/user/hive/warehouse/mysql_ziyun_andon/andon_wechat_app_info",
					"writeMode":"append"
				}
			}
		}
	],
	"setting":{
		"speed":{
			"channel":"3"
		}
	}
}

2021-03-29 18:23:16.777 [main] WARN  Engine - prioriy set to 0, because NumberFormatException, the value is: null
2021-03-29 18:23:16.779 [main] INFO  PerfTrace - PerfTrace traceId=job_-1, isEnable=false, priority=0
2021-03-29 18:23:16.780 [main] INFO  JobContainer - DataX jobContainer starts job.
2021-03-29 18:23:16.782 [main] INFO  JobContainer - Set jobId = 0
2021-03-29 18:23:17.261 [job-0] INFO  OriginalConfPretreatmentUtil - Available jdbcUrl:jdbc:mysql://192.168.0.124:3306/ziyun-andon?yearIsDateType=false&zeroDateTimeBehavior=convertToNull&tinyInt1isBit=false&rewriteBatchedStatements=true.
2021-03-29 18:23:17.291 [job-0] INFO  OriginalConfPretreatmentUtil - table:[andon_wechat_app_info] has columns:[id,app_id,app_secret,sign_mark,description,state,create_date].
Mar 29, 2021 6:23:18 PM org.apache.hadoop.util.NativeCodeLoader <clinit>
WARNING: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-03-29 18:23:19.339 [job-0] INFO  JobContainer - jobContainer starts to do prepare ...
2021-03-29 18:23:19.341 [job-0] INFO  JobContainer - DataX Reader.Job [mysqlreader] do prepare work .
2021-03-29 18:23:19.342 [job-0] INFO  JobContainer - DataX Writer.Job [hdfswriter] do prepare work .
2021-03-29 18:23:19.544 [job-0] INFO  HdfsWriter$Job - 由于您配置了writeMode append, 写入前不做清理工作, [/user/hive/warehouse/mysql_ziyun_andon/andon_wechat_app_info] 目录下写入相应文件名前缀  [andon_wechat_app_info] 的文件
2021-03-29 18:23:19.544 [job-0] INFO  JobContainer - jobContainer starts to do split ...
2021-03-29 18:23:19.545 [job-0] INFO  JobContainer - Job set Channel-Number to 3 channels.
2021-03-29 18:23:19.554 [job-0] INFO  JobContainer - DataX Reader.Job [mysqlreader] splits to [1] tasks.
2021-03-29 18:23:19.555 [job-0] INFO  HdfsWriter$Job - begin do split...
2021-03-29 18:23:19.562 [job-0] INFO  HdfsWriter$Job - splited write file name:[hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_wechat_app_info__42a99670_cf55_442e_8bc0_f0165b4b6471/andon_wechat_app_info__0bdbd577_db92_4282_a748_e528c5dba77b]
2021-03-29 18:23:19.563 [job-0] INFO  HdfsWriter$Job - end do split.
2021-03-29 18:23:19.563 [job-0] INFO  JobContainer - DataX Writer.Job [hdfswriter] splits to [1] tasks.
2021-03-29 18:23:19.601 [job-0] INFO  JobContainer - jobContainer starts to do schedule ...
2021-03-29 18:23:19.610 [job-0] INFO  JobContainer - Scheduler starts [1] taskGroups.
2021-03-29 18:23:19.614 [job-0] INFO  JobContainer - Running by standalone Mode.
2021-03-29 18:23:19.626 [taskGroup-0] INFO  TaskGroupContainer - taskGroupId=[0] start [1] channels for [1] tasks.
2021-03-29 18:23:19.635 [taskGroup-0] INFO  Channel - Channel set byte_speed_limit to -1, No bps activated.
2021-03-29 18:23:19.635 [taskGroup-0] INFO  Channel - Channel set record_speed_limit to -1, No tps activated.
2021-03-29 18:23:19.653 [taskGroup-0] INFO  TaskGroupContainer - taskGroup[0] taskId[0] attemptCount[1] is started
2021-03-29 18:23:19.660 [0-0-0-reader] INFO  CommonRdbmsReader$Task - Begin to read record by Sql: [select `id`,`app_id`,`app_secret`,`sign_mark`,`description`,`state`,`create_date` from andon_wechat_app_info where (1=1)
] jdbcUrl:[jdbc:mysql://192.168.0.124:3306/ziyun-andon?yearIsDateType=false&zeroDateTimeBehavior=convertToNull&tinyInt1isBit=false&rewriteBatchedStatements=true].
2021-03-29 18:23:19.694 [0-0-0-reader] INFO  CommonRdbmsReader$Task - Finished read record by Sql: [select `id`,`app_id`,`app_secret`,`sign_mark`,`description`,`state`,`create_date` from andon_wechat_app_info where (1=1)
] jdbcUrl:[jdbc:mysql://192.168.0.124:3306/ziyun-andon?yearIsDateType=false&zeroDateTimeBehavior=convertToNull&tinyInt1isBit=false&rewriteBatchedStatements=true].
2021-03-29 18:23:19.711 [0-0-0-writer] INFO  HdfsWriter$Task - begin do write...
2021-03-29 18:23:19.712 [0-0-0-writer] INFO  HdfsWriter$Task - write to file : [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_wechat_app_info__42a99670_cf55_442e_8bc0_f0165b4b6471/andon_wechat_app_info__0bdbd577_db92_4282_a748_e528c5dba77b]
2021-03-29 18:23:20.107 [0-0-0-writer] INFO  HdfsWriter$Task - end do write
2021-03-29 18:23:20.156 [taskGroup-0] INFO  TaskGroupContainer - taskGroup[0] taskId[0] is successed, used[505]ms
2021-03-29 18:23:20.157 [taskGroup-0] INFO  TaskGroupContainer - taskGroup[0] completed it's tasks.
2021-03-29 18:23:29.649 [job-0] INFO  StandAloneJobContainerCommunicator - Total 1 records, 72 bytes | Speed 7B/s, 0 records/s | Error 0 records, 0 bytes |  All Task WaitWriterTime 0.000s |  All Task WaitReaderTime 0.000s | Percentage 100.00%
2021-03-29 18:23:29.649 [job-0] INFO  AbstractScheduler - Scheduler accomplished all tasks.
2021-03-29 18:23:29.650 [job-0] INFO  JobContainer - DataX Writer.Job [hdfswriter] do post work.
2021-03-29 18:23:29.651 [job-0] INFO  HdfsWriter$Job - start rename file [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_wechat_app_info__42a99670_cf55_442e_8bc0_f0165b4b6471/andon_wechat_app_info__0bdbd577_db92_4282_a748_e528c5dba77b.gz] to file [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_wechat_app_info/andon_wechat_app_info__0bdbd577_db92_4282_a748_e528c5dba77b.gz].
2021-03-29 18:23:29.664 [job-0] INFO  HdfsWriter$Job - finish rename file [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_wechat_app_info__42a99670_cf55_442e_8bc0_f0165b4b6471/andon_wechat_app_info__0bdbd577_db92_4282_a748_e528c5dba77b.gz] to file [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_wechat_app_info/andon_wechat_app_info__0bdbd577_db92_4282_a748_e528c5dba77b.gz].
2021-03-29 18:23:29.664 [job-0] INFO  HdfsWriter$Job - start delete tmp dir [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_wechat_app_info__42a99670_cf55_442e_8bc0_f0165b4b6471] .
2021-03-29 18:23:29.676 [job-0] INFO  HdfsWriter$Job - finish delete tmp dir [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_wechat_app_info__42a99670_cf55_442e_8bc0_f0165b4b6471] .
2021-03-29 18:23:29.677 [job-0] INFO  JobContainer - DataX Reader.Job [mysqlreader] do post work.
2021-03-29 18:23:29.677 [job-0] INFO  JobContainer - DataX jobId [0] completed successfully.
2021-03-29 18:23:29.679 [job-0] INFO  HookInvoker - No hook invoked, because base dir not exists or is a file: /software/datax/hook
2021-03-29 18:23:29.782 [job-0] INFO  JobContainer - 
	 [total cpu info] => 
		averageCpu                     | maxDeltaCpu                    | minDeltaCpu                    
		-1.00%                         | -1.00%                         | -1.00%
                        

	 [total gc info] => 
		 NAME                 | totalGCCount       | maxDeltaGCCount    | minDeltaGCCount    | totalGCTime        | maxDeltaGCTime     | minDeltaGCTime     
		 PS MarkSweep         | 1                  | 1                  | 1                  | 0.078s             | 0.078s             | 0.078s             
		 PS Scavenge          | 1                  | 1                  | 1                  | 0.047s             | 0.047s             | 0.047s             

2021-03-29 18:23:29.782 [job-0] INFO  JobContainer - PerfTrace not enable!
2021-03-29 18:23:29.783 [job-0] INFO  StandAloneJobContainerCommunicator - Total 1 records, 72 bytes | Speed 7B/s, 0 records/s | Error 0 records, 0 bytes |  All Task WaitWriterTime 0.000s |  All Task WaitReaderTime 0.000s | Percentage 100.00%
2021-03-29 18:23:29.785 [job-0] INFO  JobContainer - 
任务启动时刻                    : 2021-03-29 18:23:16
任务结束时刻                    : 2021-03-29 18:23:29
任务总计耗时                    :                 13s
任务平均流量                    :                7B/s
记录写入速度                    :              0rec/s
读出记录总数                    :                   1
读写失败总数                    :                   0

andon_wechat_app_info表全量同步的结果为0
开始同步一张表
增量配置文件：/software/datax/sync/bin/../conf/jdbc:mysql:192.168.0.124:3306/ziyun-andon.increment
/software/datax/sync/bin/../conf/jdbc:mysql:192.168.0.124:3306/ziyun-andon.increment是文件，进入判断#
maybe_results：
开始全量同步表andon_wechat_app_info_copy1

DataX (DATAX-OPENSOURCE-3.0), From Alibaba !
Copyright (C) 2010-2017, Alibaba Group. All Rights Reserved.


2021-03-29 18:23:30.969 [main] INFO  VMInfo - VMInfo# operatingSystem class => sun.management.OperatingSystemImpl
2021-03-29 18:23:30.982 [main] INFO  Engine - the machine info  => 

	osInfo:	Oracle Corporation 1.8 25.201-b09
	jvmInfo:	Linux amd64 3.10.0-957.el7.x86_64
	cpu num:	16

	totalPhysicalMemory:	-0.00G
	freePhysicalMemory:	-0.00G
	maxFileDescriptorCount:	-1
	currentOpenFileDescriptorCount:	-1

	GC Names	[PS MarkSweep, PS Scavenge]

	MEMORY_NAME                    | allocation_size                | init_size                      
	PS Eden Space                  | 256.00MB                       | 256.00MB                       
	Code Cache                     | 240.00MB                       | 2.44MB                         
	Compressed Class Space         | 1,024.00MB                     | 0.00MB                         
	PS Survivor Space              | 42.50MB                        | 42.50MB                        
	PS Old Gen                     | 683.00MB                       | 683.00MB                       
	Metaspace                      | -0.00MB                        | 0.00MB                         


2021-03-29 18:23:31.024 [main] INFO  Engine - 
{
	"content":[
		{
			"reader":{
				"name":"mysqlreader",
				"parameter":{
					"column":[
						"`id`",
						"`app_id`",
						"`app_secret`",
						"`sign_mark`",
						"`description`",
						"`state`",
						"`create_date`"
					],
					"connection":[
						{
							"jdbcUrl":[
								"jdbc:mysql://192.168.0.124:3306/ziyun-andon"
							],
							"table":[
								"andon_wechat_app_info_copy1"
							]
						}
					],
					"password":"********",
					"username":"ziyunIot",
					"where":"1=1"
				}
			},
			"writer":{
				"name":"hdfswriter",
				"parameter":{
					"column":[
						{
							"name":"`id`",
							"type":"BIGINT"
						},
						{
							"name":"`app_id`",
							"type":"STRING"
						},
						{
							"name":"`app_secret`",
							"type":"STRING"
						},
						{
							"name":"`sign_mark`",
							"type":"STRING"
						},
						{
							"name":"`description`",
							"type":"STRING"
						},
						{
							"name":"`state`",
							"type":"BIGINT"
						},
						{
							"name":"`create_date`",
							"type":"DATE"
						}
					],
					"compress":"gzip",
					"defaultFS":"hdfs://nameservice1",
					"fieldDelimiter":"\t",
					"fileName":"andon_wechat_app_info_copy1",
					"fileType":"text",
					"hadoopConfig":{
						"dfs.client.failover.proxy.provider.nameservice1":"org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider",
						"dfs.ha.namenodes.nameservice1":"nn1,nn2",
						"dfs.namenode.rpc-address.nameservice1.nn1":"ziyunbd01:8020",
						"dfs.namenode.rpc-address.nameservice1.nn2":"ziyunbd02:8020",
						"dfs.nameservices":"nameservice1"
					},
					"path":"/user/hive/warehouse/mysql_ziyun_andon/andon_wechat_app_info_copy1",
					"writeMode":"append"
				}
			}
		}
	],
	"setting":{
		"speed":{
			"channel":"3"
		}
	}
}

2021-03-29 18:23:31.058 [main] WARN  Engine - prioriy set to 0, because NumberFormatException, the value is: null
2021-03-29 18:23:31.062 [main] INFO  PerfTrace - PerfTrace traceId=job_-1, isEnable=false, priority=0
2021-03-29 18:23:31.062 [main] INFO  JobContainer - DataX jobContainer starts job.
2021-03-29 18:23:31.066 [main] INFO  JobContainer - Set jobId = 0
2021-03-29 18:23:31.703 [job-0] INFO  OriginalConfPretreatmentUtil - Available jdbcUrl:jdbc:mysql://192.168.0.124:3306/ziyun-andon?yearIsDateType=false&zeroDateTimeBehavior=convertToNull&tinyInt1isBit=false&rewriteBatchedStatements=true.
2021-03-29 18:23:31.733 [job-0] INFO  OriginalConfPretreatmentUtil - table:[andon_wechat_app_info_copy1] has columns:[id,app_id,app_secret,sign_mark,description,state,create_date].
Mar 29, 2021 6:23:32 PM org.apache.hadoop.util.NativeCodeLoader <clinit>
WARNING: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-03-29 18:23:33.701 [job-0] INFO  JobContainer - jobContainer starts to do prepare ...
2021-03-29 18:23:33.702 [job-0] INFO  JobContainer - DataX Reader.Job [mysqlreader] do prepare work .
2021-03-29 18:23:33.703 [job-0] INFO  JobContainer - DataX Writer.Job [hdfswriter] do prepare work .
2021-03-29 18:23:33.888 [job-0] INFO  HdfsWriter$Job - 由于您配置了writeMode append, 写入前不做清理工作, [/user/hive/warehouse/mysql_ziyun_andon/andon_wechat_app_info_copy1] 目录下写入相应文件名前缀  [andon_wechat_app_info_copy1] 的文件
2021-03-29 18:23:33.888 [job-0] INFO  JobContainer - jobContainer starts to do split ...
2021-03-29 18:23:33.889 [job-0] INFO  JobContainer - Job set Channel-Number to 3 channels.
2021-03-29 18:23:33.897 [job-0] INFO  JobContainer - DataX Reader.Job [mysqlreader] splits to [1] tasks.
2021-03-29 18:23:33.898 [job-0] INFO  HdfsWriter$Job - begin do split...
2021-03-29 18:23:33.905 [job-0] INFO  HdfsWriter$Job - splited write file name:[hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_wechat_app_info_copy1__c7d8fcbd_164d_458e_95c3_c2014907cd46/andon_wechat_app_info_copy1__0d89c058_5896_46f1_8878_f7f2b53e35cd]
2021-03-29 18:23:33.905 [job-0] INFO  HdfsWriter$Job - end do split.
2021-03-29 18:23:33.905 [job-0] INFO  JobContainer - DataX Writer.Job [hdfswriter] splits to [1] tasks.
2021-03-29 18:23:33.941 [job-0] INFO  JobContainer - jobContainer starts to do schedule ...
2021-03-29 18:23:33.949 [job-0] INFO  JobContainer - Scheduler starts [1] taskGroups.
2021-03-29 18:23:33.954 [job-0] INFO  JobContainer - Running by standalone Mode.
2021-03-29 18:23:33.966 [taskGroup-0] INFO  TaskGroupContainer - taskGroupId=[0] start [1] channels for [1] tasks.
2021-03-29 18:23:33.974 [taskGroup-0] INFO  Channel - Channel set byte_speed_limit to -1, No bps activated.
2021-03-29 18:23:33.975 [taskGroup-0] INFO  Channel - Channel set record_speed_limit to -1, No tps activated.
2021-03-29 18:23:33.994 [taskGroup-0] INFO  TaskGroupContainer - taskGroup[0] taskId[0] attemptCount[1] is started
2021-03-29 18:23:34.003 [0-0-0-reader] INFO  CommonRdbmsReader$Task - Begin to read record by Sql: [select `id`,`app_id`,`app_secret`,`sign_mark`,`description`,`state`,`create_date` from andon_wechat_app_info_copy1 where (1=1)
] jdbcUrl:[jdbc:mysql://192.168.0.124:3306/ziyun-andon?yearIsDateType=false&zeroDateTimeBehavior=convertToNull&tinyInt1isBit=false&rewriteBatchedStatements=true].
2021-03-29 18:23:34.035 [0-0-0-reader] INFO  CommonRdbmsReader$Task - Finished read record by Sql: [select `id`,`app_id`,`app_secret`,`sign_mark`,`description`,`state`,`create_date` from andon_wechat_app_info_copy1 where (1=1)
] jdbcUrl:[jdbc:mysql://192.168.0.124:3306/ziyun-andon?yearIsDateType=false&zeroDateTimeBehavior=convertToNull&tinyInt1isBit=false&rewriteBatchedStatements=true].
2021-03-29 18:23:34.054 [0-0-0-writer] INFO  HdfsWriter$Task - begin do write...
2021-03-29 18:23:34.054 [0-0-0-writer] INFO  HdfsWriter$Task - write to file : [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_wechat_app_info_copy1__c7d8fcbd_164d_458e_95c3_c2014907cd46/andon_wechat_app_info_copy1__0d89c058_5896_46f1_8878_f7f2b53e35cd]
2021-03-29 18:23:34.441 [0-0-0-writer] INFO  HdfsWriter$Task - end do write
2021-03-29 18:23:34.497 [taskGroup-0] INFO  TaskGroupContainer - taskGroup[0] taskId[0] is successed, used[505]ms
2021-03-29 18:23:34.498 [taskGroup-0] INFO  TaskGroupContainer - taskGroup[0] completed it's tasks.
2021-03-29 18:23:43.990 [job-0] INFO  StandAloneJobContainerCommunicator - Total 1 records, 72 bytes | Speed 7B/s, 0 records/s | Error 0 records, 0 bytes |  All Task WaitWriterTime 0.000s |  All Task WaitReaderTime 0.000s | Percentage 100.00%
2021-03-29 18:23:43.991 [job-0] INFO  AbstractScheduler - Scheduler accomplished all tasks.
2021-03-29 18:23:43.991 [job-0] INFO  JobContainer - DataX Writer.Job [hdfswriter] do post work.
2021-03-29 18:23:43.992 [job-0] INFO  HdfsWriter$Job - start rename file [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_wechat_app_info_copy1__c7d8fcbd_164d_458e_95c3_c2014907cd46/andon_wechat_app_info_copy1__0d89c058_5896_46f1_8878_f7f2b53e35cd.gz] to file [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_wechat_app_info_copy1/andon_wechat_app_info_copy1__0d89c058_5896_46f1_8878_f7f2b53e35cd.gz].
2021-03-29 18:23:44.008 [job-0] INFO  HdfsWriter$Job - finish rename file [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_wechat_app_info_copy1__c7d8fcbd_164d_458e_95c3_c2014907cd46/andon_wechat_app_info_copy1__0d89c058_5896_46f1_8878_f7f2b53e35cd.gz] to file [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_wechat_app_info_copy1/andon_wechat_app_info_copy1__0d89c058_5896_46f1_8878_f7f2b53e35cd.gz].
2021-03-29 18:23:44.009 [job-0] INFO  HdfsWriter$Job - start delete tmp dir [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_wechat_app_info_copy1__c7d8fcbd_164d_458e_95c3_c2014907cd46] .
2021-03-29 18:23:44.022 [job-0] INFO  HdfsWriter$Job - finish delete tmp dir [hdfs://nameservice1/user/hive/warehouse/mysql_ziyun_andon/andon_wechat_app_info_copy1__c7d8fcbd_164d_458e_95c3_c2014907cd46] .
2021-03-29 18:23:44.022 [job-0] INFO  JobContainer - DataX Reader.Job [mysqlreader] do post work.
2021-03-29 18:23:44.023 [job-0] INFO  JobContainer - DataX jobId [0] completed successfully.
2021-03-29 18:23:44.024 [job-0] INFO  HookInvoker - No hook invoked, because base dir not exists or is a file: /software/datax/hook
2021-03-29 18:23:44.129 [job-0] INFO  JobContainer - 
	 [total cpu info] => 
		averageCpu                     | maxDeltaCpu                    | minDeltaCpu                    
		-1.00%                         | -1.00%                         | -1.00%
                        

	 [total gc info] => 
		 NAME                 | totalGCCount       | maxDeltaGCCount    | minDeltaGCCount    | totalGCTime        | maxDeltaGCTime     | minDeltaGCTime     
		 PS MarkSweep         | 1                  | 1                  | 1                  | 0.064s             | 0.064s             | 0.064s             
		 PS Scavenge          | 1                  | 1                  | 1                  | 0.040s             | 0.040s             | 0.040s             

2021-03-29 18:23:44.129 [job-0] INFO  JobContainer - PerfTrace not enable!
2021-03-29 18:23:44.130 [job-0] INFO  StandAloneJobContainerCommunicator - Total 1 records, 72 bytes | Speed 7B/s, 0 records/s | Error 0 records, 0 bytes |  All Task WaitWriterTime 0.000s |  All Task WaitReaderTime 0.000s | Percentage 100.00%
2021-03-29 18:23:44.132 [job-0] INFO  JobContainer - 
任务启动时刻                    : 2021-03-29 18:23:31
任务结束时刻                    : 2021-03-29 18:23:44
任务总计耗时                    :                 13s
任务平均流量                    :                7B/s
记录写入速度                    :              0rec/s
读出记录总数                    :                   1
读写失败总数                    :                   0

andon_wechat_app_info_copy1表全量同步的结果为0
开始验证数据导入结果
increment_tables：andon_fault_tag_statistics_copy1 andon_fault_tag_statistics
total_tables：andon_wechat_app_info_copy1 andon_wechat_app_info andon_user_wechat_info_copy1 andon_user_wechat_info andon_user_statistics_copy1 andon_user_statistics andon_tag_copy1 andon_tag andon_sso_tag_copy1 andon_sso_tag andon_record_fault_middle_copy1 andon_record_fault_middle andon_org_tag_copy1 andon_org_tag andon_guide_status_copy1 andon_guide_status andon_follow_record_copy1 andon_follow_record andon_fault_type_copy1 andon_fault_type andon_equipment_position_copy1 andon_equipment_position
-rw-r--r--~~~3~root~supergroup~~~~~~~~105~2021-03-29~18:23~/user/hive/warehouse/mysql_ziyun_andon/andon_wechat_app_info_copy1/andon_wechat_app_info_copy1__0d89c058_5896_46f1_8878_f7f2b53e35cd.gz
-rw-r--r--~~~3~root~supergroup~~~~~~~~105~2021-03-29~17:26~/user/hive/warehouse/mysql_ziyun_andon/andon_wechat_app_info_copy1/andon_wechat_app_info_copy1__1e755f0f_8968_4702_a0f3_44fcc0e90ec0.gz
同步成功，删除旧数据
Deleted /user/hive/warehouse/mysql_ziyun_andon/andon_wechat_app_info_copy1/andon_wechat_app_info_copy1__1e755f0f_8968_4702_a0f3_44fcc0e90ec0.gz
-rw-r--r--~~~3~root~supergroup~~~~~~~~105~2021-03-29~18:23~/user/hive/warehouse/mysql_ziyun_andon/andon_wechat_app_info/andon_wechat_app_info__0bdbd577_db92_4282_a748_e528c5dba77b.gz
-rw-r--r--~~~3~root~supergroup~~~~~~~~105~2021-03-29~17:26~/user/hive/warehouse/mysql_ziyun_andon/andon_wechat_app_info/andon_wechat_app_info__45bad2ee_c110_42d9_91ff_a4a513d6c1c5.gz
同步成功，删除旧数据
Deleted /user/hive/warehouse/mysql_ziyun_andon/andon_wechat_app_info/andon_wechat_app_info__45bad2ee_c110_42d9_91ff_a4a513d6c1c5.gz
-rw-r--r--~~~3~root~supergroup~~~~~~~~685~2021-03-29~17:25~/user/hive/warehouse/mysql_ziyun_andon/andon_user_wechat_info_copy1/andon_user_wechat_info_copy1__3b63877f_c941_4dfa_aea5_8341af1de390.gz
-rw-r--r--~~~3~root~supergroup~~~~~~~~685~2021-03-29~18:23~/user/hive/warehouse/mysql_ziyun_andon/andon_user_wechat_info_copy1/andon_user_wechat_info_copy1__cb3df44f_2a60_44a2_bcb6_34fad19d8815.gz
同步成功，删除旧数据
Deleted /user/hive/warehouse/mysql_ziyun_andon/andon_user_wechat_info_copy1/andon_user_wechat_info_copy1__3b63877f_c941_4dfa_aea5_8341af1de390.gz
-rw-r--r--~~~3~root~supergroup~~~~~~~~792~2021-03-29~17:25~/user/hive/warehouse/mysql_ziyun_andon/andon_user_wechat_info/andon_user_wechat_info__13c4bba8_3f9d_41c1_b807_1d975df53ff5.gz
-rw-r--r--~~~3~root~supergroup~~~~~~~~792~2021-03-29~18:22~/user/hive/warehouse/mysql_ziyun_andon/andon_user_wechat_info/andon_user_wechat_info__fb8b70e9_4142_4820_920d_6718e16421ba.gz
同步成功，删除旧数据
Deleted /user/hive/warehouse/mysql_ziyun_andon/andon_user_wechat_info/andon_user_wechat_info__13c4bba8_3f9d_41c1_b807_1d975df53ff5.gz
-rw-r--r--~~~3~root~supergroup~~~~~~~~914~2021-03-29~17:25~/user/hive/warehouse/mysql_ziyun_andon/andon_user_statistics_copy1/andon_user_statistics_copy1__2e0d3caf_818f_4468_a7ec_eff90770b9f5.gz
-rw-r--r--~~~3~root~supergroup~~~~~~~~914~2021-03-29~18:22~/user/hive/warehouse/mysql_ziyun_andon/andon_user_statistics_copy1/andon_user_statistics_copy1__984cfe3f_ce1a_4376_9786_15875445de5e.gz
同步成功，删除旧数据
Deleted /user/hive/warehouse/mysql_ziyun_andon/andon_user_statistics_copy1/andon_user_statistics_copy1__2e0d3caf_818f_4468_a7ec_eff90770b9f5.gz
-rw-r--r--~~~3~root~supergroup~~~~~~~1195~2021-03-29~18:22~/user/hive/warehouse/mysql_ziyun_andon/andon_user_statistics/andon_user_statistics__b5c829b4_2983_40ca_9077_adf004ce7e18.gz
-rw-r--r--~~~3~root~supergroup~~~~~~~1195~2021-03-29~17:25~/user/hive/warehouse/mysql_ziyun_andon/andon_user_statistics/andon_user_statistics__f938dfdb_0b89_432d_a762_77e8d908e714.gz
同步成功，删除旧数据
Deleted /user/hive/warehouse/mysql_ziyun_andon/andon_user_statistics/andon_user_statistics__f938dfdb_0b89_432d_a762_77e8d908e714.gz
-rw-r--r--~~~3~root~supergroup~~~~~~~~117~2021-03-29~17:24~/user/hive/warehouse/mysql_ziyun_andon/andon_tag_copy1/andon_tag_copy1__3afaba2f_ddca_4462_ad3f_69fe1b1dc9f7.gz
-rw-r--r--~~~3~root~supergroup~~~~~~~~117~2021-03-29~18:22~/user/hive/warehouse/mysql_ziyun_andon/andon_tag_copy1/andon_tag_copy1__d599e3cb_e3ed_4533_ae50_17deccaf38d8.gz
同步成功，删除旧数据
Deleted /user/hive/warehouse/mysql_ziyun_andon/andon_tag_copy1/andon_tag_copy1__3afaba2f_ddca_4462_ad3f_69fe1b1dc9f7.gz
-rw-r--r--~~~3~root~supergroup~~~~~~~~271~2021-03-29~18:21~/user/hive/warehouse/mysql_ziyun_andon/andon_tag/andon_tag__5576bcdf_bb9a_46a3_9086_72da1f1edee8.gz
-rw-r--r--~~~3~root~supergroup~~~~~~~~271~2021-03-29~17:24~/user/hive/warehouse/mysql_ziyun_andon/andon_tag/andon_tag__86feb704_0d53_4338_9dec_660f52b7d5a8.gz
同步成功，删除旧数据
Deleted /user/hive/warehouse/mysql_ziyun_andon/andon_tag/andon_tag__86feb704_0d53_4338_9dec_660f52b7d5a8.gz
-rw-r--r--~~~3~root~supergroup~~~~~~~1050~2021-03-29~17:24~/user/hive/warehouse/mysql_ziyun_andon/andon_sso_tag_copy1/andon_sso_tag_copy1__881cfccc_7609_42d8_bf92_3b660f6f4555.gz
-rw-r--r--~~~3~root~supergroup~~~~~~~1050~2021-03-29~18:21~/user/hive/warehouse/mysql_ziyun_andon/andon_sso_tag_copy1/andon_sso_tag_copy1__97e9663a_f8c8_4518_8f18_816c8bdd9fbe.gz
同步成功，删除旧数据
Deleted /user/hive/warehouse/mysql_ziyun_andon/andon_sso_tag_copy1/andon_sso_tag_copy1__881cfccc_7609_42d8_bf92_3b660f6f4555.gz
-rw-r--r--~~~3~root~supergroup~~~~~~~1548~2021-03-29~17:24~/user/hive/warehouse/mysql_ziyun_andon/andon_sso_tag/andon_sso_tag__a4931ba1_a88c_4b94_b3d5_99694e7fffff.gz
-rw-r--r--~~~3~root~supergroup~~~~~~~1548~2021-03-29~18:21~/user/hive/warehouse/mysql_ziyun_andon/andon_sso_tag/andon_sso_tag__bc1a5cac_2bd7_4ce6_9ca4_e97b508eb8ca.gz
同步成功，删除旧数据
Deleted /user/hive/warehouse/mysql_ziyun_andon/andon_sso_tag/andon_sso_tag__a4931ba1_a88c_4b94_b3d5_99694e7fffff.gz
-rw-r--r--~~~3~root~supergroup~~~~~~~1518~2021-03-29~17:24~/user/hive/warehouse/mysql_ziyun_andon/andon_record_fault_middle_copy1/andon_record_fault_middle_copy1__010a5c71_13c0_4d61_bc0c_a5fb275c3f78.gz
-rw-r--r--~~~3~root~supergroup~~~~~~~1518~2021-03-29~18:21~/user/hive/warehouse/mysql_ziyun_andon/andon_record_fault_middle_copy1/andon_record_fault_middle_copy1__ed3d79a4_dc1d_4d32_a4ad_651f3ebb0058.gz
同步成功，删除旧数据
Deleted /user/hive/warehouse/mysql_ziyun_andon/andon_record_fault_middle_copy1/andon_record_fault_middle_copy1__010a5c71_13c0_4d61_bc0c_a5fb275c3f78.gz
-rw-r--r--~~~3~root~supergroup~~~~~~~1659~2021-03-29~18:20~/user/hive/warehouse/mysql_ziyun_andon/andon_record_fault_middle/andon_record_fault_middle__8ee7df1c_13a6_48da_bf1f_47dcb5e4932c.gz
-rw-r--r--~~~3~root~supergroup~~~~~~~1659~2021-03-29~17:23~/user/hive/warehouse/mysql_ziyun_andon/andon_record_fault_middle/andon_record_fault_middle__b29043ee_625b_4186_82ea_9f4326b57096.gz
同步成功，删除旧数据
Deleted /user/hive/warehouse/mysql_ziyun_andon/andon_record_fault_middle/andon_record_fault_middle__b29043ee_625b_4186_82ea_9f4326b57096.gz
-rw-r--r--~~~3~root~supergroup~~~~~~~1196~2021-03-29~17:23~/user/hive/warehouse/mysql_ziyun_andon/andon_org_tag_copy1/andon_org_tag_copy1__a515a7bd_71eb_4318_a7da_5a46a86b5544.gz
-rw-r--r--~~~3~root~supergroup~~~~~~~1196~2021-03-29~18:20~/user/hive/warehouse/mysql_ziyun_andon/andon_org_tag_copy1/andon_org_tag_copy1__ea60f162_2347_4c43_81be_4856a857f7c3.gz
同步成功，删除旧数据
Deleted /user/hive/warehouse/mysql_ziyun_andon/andon_org_tag_copy1/andon_org_tag_copy1__a515a7bd_71eb_4318_a7da_5a46a86b5544.gz
-rw-r--r--~~~3~root~supergroup~~~~~~~1427~2021-03-29~17:23~/user/hive/warehouse/mysql_ziyun_andon/andon_org_tag/andon_org_tag__0534236a_235e_4e8c_ada3_497fa9d66115.gz
-rw-r--r--~~~3~root~supergroup~~~~~~~1427~2021-03-29~18:20~/user/hive/warehouse/mysql_ziyun_andon/andon_org_tag/andon_org_tag__b0dbac5c_561c_49a5_832f_fd9d90ed02dc.gz
同步成功，删除旧数据
Deleted /user/hive/warehouse/mysql_ziyun_andon/andon_org_tag/andon_org_tag__0534236a_235e_4e8c_ada3_497fa9d66115.gz
-rw-r--r--~~~3~root~supergroup~~~~~~~~705~2021-03-29~18:20~/user/hive/warehouse/mysql_ziyun_andon/andon_guide_status_copy1/andon_guide_status_copy1__22eeb6a3_16c9_4c72_988b_3b8faa916f91.gz
-rw-r--r--~~~3~root~supergroup~~~~~~~~705~2021-03-29~17:23~/user/hive/warehouse/mysql_ziyun_andon/andon_guide_status_copy1/andon_guide_status_copy1__740fdd34_0b10_41da_a5d6_73a0e0b77ca4.gz
同步成功，删除旧数据
Deleted /user/hive/warehouse/mysql_ziyun_andon/andon_guide_status_copy1/andon_guide_status_copy1__740fdd34_0b10_41da_a5d6_73a0e0b77ca4.gz
-rw-r--r--~~~3~root~supergroup~~~~~~~1048~2021-03-29~18:20~/user/hive/warehouse/mysql_ziyun_andon/andon_guide_status/andon_guide_status__46c80c45_15d3_4b95_9a11_b6cc4ea28897.gz
-rw-r--r--~~~3~root~supergroup~~~~~~~1048~2021-03-29~17:22~/user/hive/warehouse/mysql_ziyun_andon/andon_guide_status/andon_guide_status__7d04f729_50f3_4557_9970_94e32648c35e.gz
同步成功，删除旧数据
Deleted /user/hive/warehouse/mysql_ziyun_andon/andon_guide_status/andon_guide_status__7d04f729_50f3_4557_9970_94e32648c35e.gz
-rw-r--r--~~~3~root~supergroup~~~~~~~3830~2021-03-29~18:19~/user/hive/warehouse/mysql_ziyun_andon/andon_follow_record_copy1/andon_follow_record_copy1__1774554b_430d_4ebb_88e6_b7ed0274867e.gz
-rw-r--r--~~~3~root~supergroup~~~~~~~3830~2021-03-29~17:22~/user/hive/warehouse/mysql_ziyun_andon/andon_follow_record_copy1/andon_follow_record_copy1__9745fd0f_87b3_4c44_984f_fed52be52ecb.gz
同步成功，删除旧数据
Deleted /user/hive/warehouse/mysql_ziyun_andon/andon_follow_record_copy1/andon_follow_record_copy1__9745fd0f_87b3_4c44_984f_fed52be52ecb.gz
-rw-r--r--~~~3~root~supergroup~~~~~~~4718~2021-03-29~18:19~/user/hive/warehouse/mysql_ziyun_andon/andon_follow_record/andon_follow_record__6ec818bb_610f_4344_bc8d_0bea495c5bd8.gz
-rw-r--r--~~~3~root~supergroup~~~~~~~4718~2021-03-29~17:22~/user/hive/warehouse/mysql_ziyun_andon/andon_follow_record/andon_follow_record__e98ffc37_45df_4094_8b8d_932859e9a2be.gz
同步成功，删除旧数据
Deleted /user/hive/warehouse/mysql_ziyun_andon/andon_follow_record/andon_follow_record__e98ffc37_45df_4094_8b8d_932859e9a2be.gz
-rw-r--r--~~~3~root~supergroup~~~~~~~1104~2021-03-29~17:22~/user/hive/warehouse/mysql_ziyun_andon/andon_fault_type_copy1/andon_fault_type_copy1__6aff5197_894c_483c_84d1_854a17f392f9.gz
-rw-r--r--~~~3~root~supergroup~~~~~~~1104~2021-03-29~18:19~/user/hive/warehouse/mysql_ziyun_andon/andon_fault_type_copy1/andon_fault_type_copy1__ba4789ae_8a4a_4468_9b65_624a30e16f07.gz
同步成功，删除旧数据
Deleted /user/hive/warehouse/mysql_ziyun_andon/andon_fault_type_copy1/andon_fault_type_copy1__6aff5197_894c_483c_84d1_854a17f392f9.gz
-rw-r--r--~~~3~root~supergroup~~~~~~~1852~2021-03-29~18:18~/user/hive/warehouse/mysql_ziyun_andon/andon_fault_type/andon_fault_type__da421f5b_f361_4186_89ec_c1db420dfdfe.gz
-rw-r--r--~~~3~root~supergroup~~~~~~~1852~2021-03-29~17:21~/user/hive/warehouse/mysql_ziyun_andon/andon_fault_type/andon_fault_type__ef801c99_6f6f_43f6_a588_652f8c90aec1.gz
同步成功，删除旧数据
Deleted /user/hive/warehouse/mysql_ziyun_andon/andon_fault_type/andon_fault_type__ef801c99_6f6f_43f6_a588_652f8c90aec1.gz
-rw-r--r--~~~3~root~supergroup~~~~~~~~917~2021-03-29~17:21~/user/hive/warehouse/mysql_ziyun_andon/andon_equipment_position_copy1/andon_equipment_position_copy1__84cb0a0e_9b04_4c2c_939b_8c4dcdf81e3b.gz
-rw-r--r--~~~3~root~supergroup~~~~~~~~917~2021-03-29~18:18~/user/hive/warehouse/mysql_ziyun_andon/andon_equipment_position_copy1/andon_equipment_position_copy1__8d119a28_c39e_4a3a_95c6_18d40dfdbffa.gz
同步成功，删除旧数据
Deleted /user/hive/warehouse/mysql_ziyun_andon/andon_equipment_position_copy1/andon_equipment_position_copy1__84cb0a0e_9b04_4c2c_939b_8c4dcdf81e3b.gz
-rw-r--r--~~~3~root~supergroup~~~~~~~~994~2021-03-29~17:20~/user/hive/warehouse/mysql_ziyun_andon/andon_equipment_position/andon_equipment_position__0c7996b2_2b7a_47a6_9358_ff12ca6a5f96.gz
-rw-r--r--~~~3~root~supergroup~~~~~~~~994~2021-03-29~18:18~/user/hive/warehouse/mysql_ziyun_andon/andon_equipment_position/andon_equipment_position__5e95a6a2_6039_4269_8a8b_7d6088692994.gz
同步成功，删除旧数据
Deleted /user/hive/warehouse/mysql_ziyun_andon/andon_equipment_position/andon_equipment_position__0c7996b2_2b7a_47a6_9358_ff12ca6a5f96.gz
